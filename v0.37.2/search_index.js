var documenterSearchIndex = {"docs":
[{"location":"internals/varinfo/#Design-of-VarInfo","page":"Design of VarInfo","title":"Design of VarInfo","text":"","category":"section"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"VarInfo is a fairly simple structure.","category":"page"},{"location":"internals/varinfo/#DynamicPPL.VarInfo-internals-varinfo","page":"Design of VarInfo","title":"DynamicPPL.VarInfo","text":"struct VarInfo{Tmeta,Accs<:AccumulatorTuple} <: AbstractVarInfo\n    metadata::Tmeta\n    accs::Accs\nend\n\nA light wrapper over some kind of metadata.\n\nThe type of the metadata can be one of a number of options. It may either be a Metadata or a VarNamedVector, or, it may be a NamedTuple which maps symbols to Metadata or VarNamedVector instances. Here, a symbol refers to a Julia variable and may consist of one or more VarNames which appear on the left-hand side of tilde statements. For example, x[1] and x[2] both have the same symbol x.\n\nSeveral type aliases are provided for these forms of VarInfos:\n\nVarInfo{<:Metadata} is UntypedVarInfo\nVarInfo{<:VarNamedVector} is UntypedVectorVarInfo\nVarInfo{<:NamedTuple} is NTVarInfo\n\nThe NamedTuple form, i.e. NTVarInfo, is useful for maintaining type stability of model evaluation. However, the element type of NamedTuples are not contained in its type itself: thus, there is no way to use the type system to determine whether the elements of the NamedTuple are Metadata or VarNamedVector.\n\nNote that for NTVarInfo, it is the user's responsibility to ensure that each symbol is visited at least once during model evaluation, regardless of any stochastic branching.\n\n\n\n\n\n","category":"type"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"It contains","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"a logp field for accumulation of the log-density evaluation, and\na metadata field for storing information about the realizations of the different variables.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Representing logp is fairly straight-forward: we'll just use a Real or an array of Real, depending on the context.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Representing metadata is a bit trickier. This is supposed to contain all the necessary information for each VarName to enable the different executions of the model + extraction of different properties of interest after execution, e.g. the realization / value corresponding to a variable @varname(x).","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"note: Note\nWe want to work with VarName rather than something like Symbol or String as VarName contains additional structural information, e.g. a Symbol(\"x[1]\") can be a result of either var\"x[1]\" ~ Normal() or x[1] ~ Normal(); these scenarios are disambiguated by VarName.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"To ensure that VarInfo is simple and intuitive to work with, we want VarInfo, and hence the underlying metadata, to replicate the following functionality of Dict:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"keys(::Dict): return all the VarNames present in metadata.\nhaskey(::Dict): check if a particular VarName is present in metadata.\ngetindex(::Dict, ::VarName): return the realization corresponding to a particular VarName.\nsetindex!(::Dict, val, ::VarName): set the realization corresponding to a particular VarName.\npush!(::Dict, ::Pair): add a new key-value pair to the container.\ndelete!(::Dict, ::VarName): delete the realization corresponding to a particular VarName.\nempty!(::Dict): delete all realizations in metadata.\nmerge(::Dict, ::Dict): merge two metadata structures according to similar rules as Dict.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"But for general-purpose samplers, we often want to work with a simple flattened structure, typically a Vector{<:Real}. One can access a vectorised version of a variable's value with the following vector-like functions:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"getindex_internal(::VarInfo, ::VarName): get the flattened value of a single variable.\ngetindex_internal(::VarInfo, ::Colon): get the flattened values of all variables.\ngetindex_internal(::VarInfo, i::Int): get ith value of the flattened vector of all values\nsetindex_internal!(::VarInfo, ::AbstractVector, ::VarName): set the flattened value of a variable.\nsetindex_internal!(::VarInfo, val, i::Int): set the ith value of the flattened vector of all values\nlength_internal(::VarInfo): return the length of the flat representation of metadata.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"The functions have _internal in their name because internally VarInfo always stores values as vectorised.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Moreover, a link transformation can be applied to a VarInfo with link!! (and reversed with invlink!!), which applies a reversible transformation to the internal storage format of a variable that makes the range of the random variable cover all of Euclidean space. getindex_internal and setindex_internal! give direct access to the vectorised value after such a transformation, which is what samplers often need to be able sample in unconstrained space. One can also manually set a transformation by giving setindex_internal! a fourth, optional argument, that is a function that maps internally stored value to the actual value of the variable.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Finally, we want want the underlying representation used in metadata to have a few performance-related properties:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Type-stable when possible, but functional when not.\nEfficient storage and iteration when possible, but functional when not.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"The \"but functional when not\" is important as we want to support arbitrary models, which means that we can't always have these performance properties.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"In the following sections, we'll outline how we achieve this in VarInfo.","category":"page"},{"location":"internals/varinfo/#Type-stability","page":"Design of VarInfo","title":"Type-stability","text":"","category":"section"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Ensuring type-stability is somewhat non-trivial to address since we want this to be the case even when models mix continuous (typically Float64) and discrete (typically Int) variables.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Suppose we have an implementation of metadata which implements the functionality outlined in the previous section. The way we approach this in VarInfo is to use a NamedTuple with a separate metadata for each distinct Symbol used. For example, if we have a model of the form","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"using DynamicPPL, Distributions, FillArrays\n\n@model function demo()\n    x ~ product_distribution(Fill(Bernoulli(0.5), 2))\n    y ~ Normal(0, 1)\n    return nothing\nend","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"then we construct a type-stable representation by using a NamedTuple{(:x, :y), Tuple{Vx, Vy}} where","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Vx is a container with eltype Bool, and\nVy is a container with eltype Float64.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Since VarName contains the Symbol used in its type, something like getindex(varinfo, @varname(x)) can be resolved to getindex(varinfo.metadata.x, @varname(x)) at compile-time.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"For example, with the model above we have","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"# Type-unstable `VarInfo`\nvarinfo_untyped = DynamicPPL.untyped_varinfo(demo())\ntypeof(varinfo_untyped.metadata)","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"# Type-stable `VarInfo`\nvarinfo_typed = DynamicPPL.typed_varinfo(demo())\ntypeof(varinfo_typed.metadata)","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"They both work as expected but one results in concrete typing and the other does not:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"varinfo_untyped[@varname(x)], varinfo_untyped[@varname(y)]","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"varinfo_typed[@varname(x)], varinfo_typed[@varname(y)]","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Notice that the untyped VarInfo uses Vector{Real} to store the boolean entries while the typed uses Vector{Bool}. This is because the untyped version needs the underlying container to be able to handle both the Bool for x and the Float64 for y, while the typed version can use a Vector{Bool} for x and a Vector{Float64} for y due to its usage of NamedTuple.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"warning: Warning\nOf course, this NamedTuple approach is not necessarily going to help us in scenarios where the Symbol does not correspond to a unique type, e.g.x[1] ~ Bernoulli(0.5)\nx[2] ~ Normal(0, 1)In this case we'll end up with a NamedTuple((:x,), Tuple{Vx}) where Vx is a container with eltype Union{Bool, Float64} or something worse. This is not type-stable but will still be functional.In practice, we rarely observe such mixing of types, therefore in DynamicPPL, and more widely in Turing.jl, we use a NamedTuple approach for type-stability with great success.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"warning: Warning\nAnother downside with such a NamedTuple approach is that if we have a model with lots of tilde-statements, e.g. a ~ Normal(), b ~ Normal(), ..., z ~ Normal() will result in a NamedTuple with 27 entries, potentially leading to long compilation times.For these scenarios it can be useful to fall back to \"untyped\" representations.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Hence we obtain a \"type-stable when possible\"-representation by wrapping it in a NamedTuple and partially resolving the getindex, setindex!, etc. methods at compile-time. When type-stability is not desired, we can simply use a single metadata for all VarNames instead of a NamedTuple wrapping a collection of metadatas.","category":"page"},{"location":"internals/varinfo/#Efficient-storage-and-iteration","page":"Design of VarInfo","title":"Efficient storage and iteration","text":"","category":"section"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Efficient storage and iteration we achieve through implementation of the metadata. In particular, we do so with DynamicPPL.VarNamedVector:","category":"page"},{"location":"internals/varinfo/#DynamicPPL.VarNamedVector","page":"Design of VarInfo","title":"DynamicPPL.VarNamedVector","text":"VarNamedVector\n\nA container that stores values in a vectorised form, but indexable by variable names.\n\nA VarNamedVector can be thought of as an ordered mapping from VarNames to pairs of (internal_value, transform). Here internal_value is a vectorised value for the variable and transform is a function such that transform(internal_value) is the \"original\" value of the variable, the one that the user sees. For instance, if the variable has a matrix value, internal_value could bea flattened Vector of its elements, and transform would be a reshape call.\n\ntransform may implement simply vectorisation, but it may do more. Most importantly, it may implement linking, where the internal storage of a random variable is in a form where all values in Euclidean space are valid. This is useful for sampling, because the sampler can make changes to internal_value without worrying about constraints on the space of the random variable.\n\nThe way to access this storage format directly is through the functions getindex_internal and setindex_internal. The transform argument for setindex_internal is optional, by default it is either the identity, or the existing transform if a value already exists for this VarName.\n\nVarNamedVector also provides a Dict-like interface that hides away the internal vectorisation. This can be accessed with getindex and setindex!. setindex! only takes the value, the transform is automatically set to be a simple vectorisation. The only notable deviation from the behavior of a Dict is that setindex! will throw an error if one tries to set a new value for a variable that lives in a different \"space\" than the old one (e.g. is of a different type or size). This is because setindex! does not change the transform of a variable, e.g. preserve linking, and thus the new value must be compatible with the old transform.\n\nFor now, a third value is in fact stored for each VarName: a boolean indicating whether the variable has been transformed to unconstrained Euclidean space or not. This is only in place temporarily due to the needs of our old Gibbs sampler.\n\nInternally, VarNamedVector stores the values of all variables in a single contiguous vector. This makes some operations more efficient, and means that one can access the entire contents of the internal storage quickly with getindex_internal(vnv, :). The other fields of VarNamedVector are mostly used to keep track of which part of the internal storage belongs to which VarName.\n\nFields\n\nvarname_to_index: mapping from a VarName to its integer index in varnames, ranges and transforms\n\nvarnames: vector of VarNames for the variables, where varnames[varname_to_index[vn]] == vn\n\nranges: vector of index ranges in vals corresponding to varnames; each VarName vn has a single index or a set of contiguous indices, such that the values of vn can be found at vals[ranges[varname_to_index[vn]]]\n\nvals: vector of values of all variables; the value(s) of vn is/are vals[ranges[varname_to_index[vn]]]\n\ntransforms: vector of transformations, so that transforms[varname_to_index[vn]] is a callable that transforms the value of vn back to its original space, undoing any linking and vectorisation\n\nis_unconstrained: vector of booleans indicating whether a variable has been explicitly transformed to unconstrained Euclidean space, i.e. whether its domain is all of ℝ^ⁿ. If is_unconstrained[varname_to_index[vn]] is true, it guarantees that the variable vn is not constrained. However, the converse does not hold: if is_unconstrained is false, the variable vn may still happen to be unconstrained, e.g. if its original distribution is itself unconstrained (like a normal distribution).\n\nnum_inactive: mapping from a variable index to the number of inactive entries for that variable. Inactive entries are elements in vals that are not part of the value of any variable. They arise when a variable is set to a new value with a different dimension, in-place. Inactive entries always come after the last active entry for the given variable. See the extended help with ??VarNamedVector for more details.\n\nExtended help\n\nThe values for different variables are internally all stored in a single vector. For instance,\n\njulia> using DynamicPPL: ReshapeTransform, VarNamedVector, @varname, setindex!, update!, getindex_internal\n\njulia> vnv = VarNamedVector();\n\njulia> setindex!(vnv, [0.0, 0.0, 0.0, 0.0], @varname(x));\n\njulia> setindex!(vnv, reshape(1:6, (2,3)), @varname(y));\n\njulia> vnv.vals\n10-element Vector{Real}:\n 0.0\n 0.0\n 0.0\n 0.0\n 1\n 2\n 3\n 4\n 5\n 6\n\nThe varnames, ranges, and varname_to_index fields keep track of which value belongs to which variable. The transforms field stores the transformations that needed to transform the vectorised internal storage back to its original form:\n\njulia> vnv.transforms[vnv.varname_to_index[@varname(y)]] == DynamicPPL.ReshapeTransform((6,), (2,3))\ntrue\n\nIf a variable is updated with a new value that is of a smaller dimension than the old value, rather than resizing vnv.vals, some elements in vnv.vals are marked as inactive.\n\njulia> update!(vnv, [46.0, 48.0], @varname(x))\n\njulia> vnv.vals\n10-element Vector{Real}:\n 46.0\n 48.0\n  0.0\n  0.0\n  1\n  2\n  3\n  4\n  5\n  6\n\njulia> println(vnv.num_inactive);\nOrderedDict(1 => 2)\n\nThis helps avoid unnecessary memory allocations for values that repeatedly change dimension. The user does not have to worry about the inactive entries as long as they use functions like setindex! and getindex! rather than directly accessing vnv.vals.\n\njulia> vnv[@varname(x)]\n2-element Vector{Real}:\n 46.0\n 48.0\n\njulia> getindex_internal(vnv, :)\n8-element Vector{Real}:\n 46.0\n 48.0\n  1\n  2\n  3\n  4\n  5\n  6\n\n\n\n\n\n","category":"type"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"In a DynamicPPL.VarNamedVector{<:VarName,T}, we achieve the desiderata by storing the values for different VarNames contiguously in a Vector{T} and keeping track of which ranges correspond to which VarNames.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"This does require a bit of book-keeping, in particular when it comes to insertions and deletions. Internally, this is handled by assigning each VarName a unique Int index in the varname_to_index field, which is then used to index into the following fields:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"varnames::Vector{<:VarName}: the VarNames in the order they appear in the Vector{T}.\nranges::Vector{UnitRange{Int}}: the ranges of indices in the Vector{T} that correspond to each VarName.\ntransforms::Vector: the transforms associated with each VarName.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Mutating functions, e.g. setindex_internal!(vnv::VarNamedVector, val, vn::VarName), are then treated according to the following rules:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"If vn is not already present: add it to the end of vnv.varnames, add the val to the underlying vnv.vals, etc.\nIf vn is already present in vnv:\nIf val has the same length as the existing value for vn: replace existing value.\nIf val has a smaller length than the existing value for vn: replace existing value and mark the remaining indices as \"inactive\" by increasing the entry in vnv.num_inactive field.\nIf val has a larger length than the existing value for vn: expand the underlying vnv.vals to accommodate the new value, update all VarNames occuring after vn, and update the vnv.ranges to point to the new range for vn.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"This means that VarNamedVector is allowed to grow as needed, while \"shrinking\" (i.e. insertion of smaller elements) is handled by simply marking the redundant indices as \"inactive\". This turns out to be efficient for use-cases that we are generally interested in.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"For example, we want to optimize code-paths which effectively boil down to inner-loop in the following example:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"# Construct a `VarInfo` with types inferred from `model`.\nvarinfo = VarInfo(model)\n\n# Repeatedly sample from `model`.\nfor _ in 1:num_samples\n    rand!(rng, model, varinfo)\n\n    # Do something with `varinfo`.\n    # ...\nend","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"There are typically a few scenarios where we encounter changing representation sizes of a random variable x:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"We're working with a transformed version x which is represented in a lower-dimensional space, e.g. transforming a x ~ LKJ(2, 1) to unconstrained y = f(x) takes us from 2-by-2 Matrix{Float64} to a 1-length Vector{Float64}.\nx has a random size, e.g. in a mixture model with a prior on the number of components. Here the size of x can vary widly between every realization of the Model.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"In scenario (1), we're usually shrinking the representation of x, and so we end up not making any allocations for the underlying Vector{T} but instead just marking the redundant part as \"inactive\".","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"In scenario (2), we  end up increasing the allocated memory for the randomly sized x, eventually leading to a vector that is large enough to hold realizations without needing to reallocate. But this can still lead to unnecessary memory usage, which might be undesirable. Hence one has to make a decision regarding the trade-off between memory usage and performance for the use-case at hand.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"To help with this, we have the following functions:","category":"page"},{"location":"internals/varinfo/#DynamicPPL.has_inactive","page":"Design of VarInfo","title":"DynamicPPL.has_inactive","text":"has_inactive(vnv::VarNamedVector)\n\nReturns true if vnv has inactive entries.\n\nSee also: num_inactive\n\n\n\n\n\n","category":"function"},{"location":"internals/varinfo/#DynamicPPL.num_inactive","page":"Design of VarInfo","title":"DynamicPPL.num_inactive","text":"num_inactive(vnv::VarNamedVector)\n\nReturn the number of inactive entries in vnv.\n\nSee also: has_inactive, num_allocated\n\n\n\n\n\nnum_inactive(vnv::VarNamedVector, vn::VarName)\n\nReturns the number of inactive entries for vn in vnv.\n\n\n\n\n\n","category":"function"},{"location":"internals/varinfo/#DynamicPPL.num_allocated","page":"Design of VarInfo","title":"DynamicPPL.num_allocated","text":"num_allocated(vnv::VarNamedVector)\nnum_allocated(vnv::VarNamedVector[, vn::VarName])\nnum_allocated(vnv::VarNamedVector[, idx::Int])\n\nReturn the number of allocated entries in vnv, both active and inactive.\n\nIf either a VarName or an Int index is specified, only count entries allocated for that variable.\n\nAllocated entries take up memory in vnv.vals, but, if inactive, may not currently hold any meaningful data. One can remove them with contiguify!, but doing so may cause more memory allocations in the future if variables change dimension.\n\n\n\n\n\n","category":"function"},{"location":"internals/varinfo/#DynamicPPL.is_contiguous","page":"Design of VarInfo","title":"DynamicPPL.is_contiguous","text":"is_contiguous(vnv::VarNamedVector)\n\nReturns true if the underlying data of vnv is stored in a contiguous array.\n\nThis is equivalent to negating has_inactive(vnv).\n\n\n\n\n\n","category":"function"},{"location":"internals/varinfo/#DynamicPPL.contiguify!","page":"Design of VarInfo","title":"DynamicPPL.contiguify!","text":"contiguify!(vnv::VarNamedVector)\n\nRe-contiguify the underlying vector and shrink if possible.\n\nExamples\n\njulia> using DynamicPPL: VarNamedVector, @varname, contiguify!, update!, has_inactive\n\njulia> vnv = VarNamedVector(@varname(x) => [1.0, 2.0, 3.0], @varname(y) => [3.0]);\n\njulia> update!(vnv, [23.0, 24.0], @varname(x));\n\njulia> has_inactive(vnv)\ntrue\n\njulia> length(vnv.vals)\n4\n\njulia> contiguify!(vnv);\n\njulia> has_inactive(vnv)\nfalse\n\njulia> length(vnv.vals)\n3\n\njulia> vnv[@varname(x)]  # All the values are still there.\n2-element Vector{Float64}:\n 23.0\n 24.0\n\n\n\n\n\n","category":"function"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"For example, one might encounter the following scenario:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"vnv = DynamicPPL.VarNamedVector(@varname(x) => [true])\nprintln(\"Before insertion: number of allocated entries  $(DynamicPPL.num_allocated(vnv))\")\n\nfor i in 1:5\n    x = fill(true, rand(1:100))\n    DynamicPPL.update!(vnv, x, @varname(x))\n    println(\n        \"After insertion #$(i) of length $(length(x)): number of allocated entries  $(DynamicPPL.num_allocated(vnv))\",\n    )\nend","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"We can then insert a call to DynamicPPL.contiguify! after every insertion whenever the allocation grows too large to reduce overall memory usage:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"vnv = DynamicPPL.VarNamedVector(@varname(x) => [true])\nprintln(\"Before insertion: number of allocated entries  $(DynamicPPL.num_allocated(vnv))\")\n\nfor i in 1:5\n    x = fill(true, rand(1:100))\n    DynamicPPL.update!(vnv, x, @varname(x))\n    if DynamicPPL.num_allocated(vnv) > 10\n        DynamicPPL.contiguify!(vnv)\n    end\n    println(\n        \"After insertion #$(i) of length $(length(x)): number of allocated entries  $(DynamicPPL.num_allocated(vnv))\",\n    )\nend","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"This does incur a runtime cost as it requires re-allocation of the ranges in addition to a resize! of the underlying Vector{T}. However, this also ensures that the the underlying Vector{T} is contiguous, which is important for performance. Hence, if we're about to do a lot of work with the VarNamedVector without insertions, etc., it can be worth it to do a sweep to ensure that the underlying Vector{T} is contiguous.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"note: Note\nHigher-dimensional arrays, e.g. Matrix, are handled by simply vectorizing them before storing them in the Vector{T}, and composing the VarName's transformation with a DynamicPPL.ReshapeTransform.","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Continuing from the example from the previous section, we can use a VarInfo with a VarNamedVector as the metadata field:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"# Type-unstable\nvarinfo_untyped_vnv = DynamicPPL.untyped_vector_varinfo(varinfo_untyped)\nvarinfo_untyped_vnv[@varname(x)], varinfo_untyped_vnv[@varname(y)]","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"# Type-stable\nvarinfo_typed_vnv = DynamicPPL.typed_vector_varinfo(varinfo_typed)\nvarinfo_typed_vnv[@varname(x)], varinfo_typed_vnv[@varname(y)]","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"If we now try to delete! @varname(x)","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"haskey(varinfo_untyped_vnv, @varname(x))","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"DynamicPPL.has_inactive(varinfo_untyped_vnv.metadata)","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"# `delete!`\nDynamicPPL.delete!(varinfo_untyped_vnv.metadata, @varname(x))\nDynamicPPL.has_inactive(varinfo_untyped_vnv.metadata)","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"haskey(varinfo_untyped_vnv, @varname(x))","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Or insert a differently-sized value for @varname(x)","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"DynamicPPL.insert!(varinfo_untyped_vnv.metadata, fill(true, 1), @varname(x))\nvarinfo_untyped_vnv[@varname(x)]","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"DynamicPPL.num_allocated(varinfo_untyped_vnv.metadata, @varname(x))","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"DynamicPPL.update!(varinfo_untyped_vnv.metadata, fill(true, 4), @varname(x))\nvarinfo_untyped_vnv[@varname(x)]","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"DynamicPPL.num_allocated(varinfo_untyped_vnv.metadata, @varname(x))","category":"page"},{"location":"internals/varinfo/#Performance-summary","page":"Design of VarInfo","title":"Performance summary","text":"","category":"section"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"In the end, we have the following \"rough\" performance characteristics for VarNamedVector:","category":"page"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"Method Is blazingly fast?\ngetindex colorgreen checkmark\nsetindex! on a new VarName colorgreen checkmark\ndelete! colorred times\nupdate! on existing VarName colorgreen checkmark if smaller or same size / colorred times if larger size\nvalues_as(::VarNamedVector, Vector{T}) colorgreen checkmark if contiguous / colororange div otherwise","category":"page"},{"location":"internals/varinfo/#Other-methods","page":"Design of VarInfo","title":"Other methods","text":"","category":"section"},{"location":"internals/varinfo/#DynamicPPL.replace_raw_storage-Tuple{DynamicPPL.VarNamedVector, AbstractVector}","page":"Design of VarInfo","title":"DynamicPPL.replace_raw_storage","text":"replace_raw_storage(vnv::VarNamedVector, vals::AbstractVector)\n\nReplace the values in vnv with vals, as they are stored internally.\n\nThis is useful when we want to update the entire underlying vector of values in one go or if we want to change the how the values are stored, e.g. alter the eltype.\n\nwarning: Warning\nThis replaces the raw underlying values, and so care should be taken when using this function. For example, if vnv has any inactive entries, then the provided vals should also contain the inactive entries to avoid unexpected behavior.\n\nExamples\n\njulia> using DynamicPPL: VarNamedVector, replace_raw_storage\n\njulia> vnv = VarNamedVector(@varname(x) => [1.0]);\n\njulia> replace_raw_storage(vnv, [2.0])[@varname(x)] == [2.0]\ntrue\n\nThis is also useful when we want to differentiate wrt. the values using automatic differentiation, e.g. ForwardDiff.jl.\n\njulia> using ForwardDiff: ForwardDiff\n\njulia> f(x) = sum(abs2, replace_raw_storage(vnv, x)[@varname(x)])\nf (generic function with 1 method)\n\njulia> ForwardDiff.gradient(f, [1.0])\n1-element Vector{Float64}:\n 2.0\n\n\n\n\n\n","category":"method"},{"location":"internals/varinfo/#DynamicPPL.values_as-Tuple{DynamicPPL.VarNamedVector}-internals-varinfo","page":"Design of VarInfo","title":"DynamicPPL.values_as","text":"values_as(vnv::VarNamedVector[, T])\n\nReturn the values/realizations in vnv as type T, if implemented.\n\nIf no type T is provided, return values as stored in vnv.\n\nExamples\n\njulia> using DynamicPPL: VarNamedVector\n\njulia> vnv = VarNamedVector(@varname(x) => 1, @varname(y) => [2.0]);\n\njulia> values_as(vnv) == [1.0, 2.0]\ntrue\n\njulia> values_as(vnv, Vector{Float32}) == Vector{Float32}([1.0, 2.0])\ntrue\n\njulia> values_as(vnv, OrderedDict) == OrderedDict(@varname(x) => 1.0, @varname(y) => [2.0])\ntrue\n\njulia> values_as(vnv, NamedTuple) == (x = 1.0, y = [2.0])\ntrue\n\n\n\n\n\n","category":"method"},{"location":"internals/varinfo/","page":"Design of VarInfo","title":"Design of VarInfo","text":"","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Part of the API of DynamicPPL is defined in the more lightweight interface package AbstractPPL.jl and reexported here.","category":"page"},{"location":"api/#Model","page":"API","title":"Model","text":"","category":"section"},{"location":"api/#Macros","page":"API","title":"Macros","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"A core component of DynamicPPL is the @model macro. It can be used to define probabilistic models in an intuitive way by specifying random variables and their distributions with ~ statements. These statements are rewritten by @model as calls of internal functions for sampling the variables and computing their log densities.","category":"page"},{"location":"api/#DynamicPPL.@model","page":"API","title":"DynamicPPL.@model","text":"@model(expr[, warn = false])\n\nMacro to specify a probabilistic model.\n\nIf warn is true, a warning is displayed if internal variable names are used in the model definition.\n\nExamples\n\nModel definition:\n\n@model function model(x, y = 42)\n    ...\nend\n\nTo generate a Model, call model(xvalue) or model(xvalue, yvalue).\n\n\n\n\n\n","category":"macro"},{"location":"api/#Type","page":"API","title":"Type","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"A Model can be created by calling the model function, as defined by @model.","category":"page"},{"location":"api/#DynamicPPL.Model","page":"API","title":"DynamicPPL.Model","text":"struct Model{F,argnames,defaultnames,missings,Targs,Tdefaults,Ctx<:AbstractContext}\n    f::F\n    args::NamedTuple{argnames,Targs}\n    defaults::NamedTuple{defaultnames,Tdefaults}\n    context::Ctx=DefaultContext()\nend\n\nA Model struct with model evaluation function of type F, arguments of names argnames types Targs, default arguments of names defaultnames with types Tdefaults, missing arguments missings, and evaluation context of type Ctx.\n\nHere argnames, defaultargnames, and missings are tuples of symbols, e.g. (:a, :b). context is by default DefaultContext().\n\nAn argument with a type of Missing will be in missings by default. However, in non-traditional use-cases missings can be defined differently. All variables in missings are treated as random variables rather than observations.\n\nThe default arguments are used internally when constructing instances of the same model with different arguments.\n\nExamples\n\njulia> Model(f, (x = 1.0, y = 2.0))\nModel{typeof(f),(:x, :y),(),(),Tuple{Float64,Float64},Tuple{}}(f, (x = 1.0, y = 2.0), NamedTuple())\n\njulia> Model(f, (x = 1.0, y = 2.0), (x = 42,))\nModel{typeof(f),(:x, :y),(:x,),(),Tuple{Float64,Float64},Tuple{Int64}}(f, (x = 1.0, y = 2.0), (x = 42,))\n\njulia> Model{(:y,)}(f, (x = 1.0, y = 2.0), (x = 42,)) # with special definition of missings\nModel{typeof(f),(:x, :y),(:x,),(:y,),Tuple{Float64,Float64},Tuple{Int64}}(f, (x = 1.0, y = 2.0), (x = 42,))\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"Models are callable structs.","category":"page"},{"location":"api/#DynamicPPL.Model-Tuple{}","page":"API","title":"DynamicPPL.Model","text":"(model::Model)([rng, varinfo])\n\nSample from the prior of the model with random number generator rng.\n\nReturns the model's return value.\n\nNote that calling this with an existing varinfo object will mutate it.\n\n\n\n\n\n","category":"method"},{"location":"api/","page":"API","title":"API","text":"Basic properties of a model can be accessed with getargnames, getmissings, and nameof.","category":"page"},{"location":"api/#Base.nameof-Tuple{Model}","page":"API","title":"Base.nameof","text":"nameof(model::Model)\n\nGet the name of the model as Symbol.\n\n\n\n\n\n","category":"method"},{"location":"api/#DynamicPPL.getargnames","page":"API","title":"DynamicPPL.getargnames","text":"getargnames(model::Model)\n\nGet a tuple of the argument names of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getmissings","page":"API","title":"DynamicPPL.getmissings","text":"getmissings(model::Model)\n\nGet a tuple of the names of the missing arguments of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"The context of a model can be set using contextualize:","category":"page"},{"location":"api/#DynamicPPL.contextualize","page":"API","title":"DynamicPPL.contextualize","text":"contextualize(model::Model, context::AbstractContext)\n\nReturn a new Model with the same evaluation function and other arguments, but with its underlying context set to context.\n\n\n\n\n\n","category":"function"},{"location":"api/#Evaluation","page":"API","title":"Evaluation","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"With rand one can draw samples from the prior distribution of a Model.","category":"page"},{"location":"api/#Base.rand","page":"API","title":"Base.rand","text":"rand([rng=Random.default_rng()], [T=NamedTuple], model::Model)\n\nGenerate a sample of type T from the prior distribution of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"One can also evaluate the log prior, log likelihood, and log joint probability.","category":"page"},{"location":"api/#DynamicPPL.logprior","page":"API","title":"DynamicPPL.logprior","text":"logprior(model::Model, varinfo::AbstractVarInfo)\n\nReturn the log prior probability of variables varinfo for the probabilistic model.\n\nNote that this probability always refers to the parameters in unlinked space, i.e., the return value of logprior does not depend on whether VarInfo has been linked or not.\n\nSee also logjoint and loglikelihood.\n\n\n\n\n\nlogprior(model::Model, chain::AbstractMCMC.AbstractChains)\n\nReturn an array of log prior probabilities evaluated at each sample in an MCMC chain.\n\nExamples\n\njulia> using MCMCChains, Distributions\n\njulia> @model function demo_model(x)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, sqrt(s))\n           for i in eachindex(x)\n               x[i] ~ Normal(m, sqrt(s))\n           end\n       end;\n\njulia> # construct a chain of samples using MCMCChains\n       chain = Chains(rand(10, 2, 3), [:s, :m]);\n\njulia> logprior(demo_model([1., 2.]), chain);\n\n\n\n\n\nlogprior(model::Model, θ)\n\nReturn the log prior probability of variables θ for the probabilistic model.\n\nSee also logjoint and loglikelihood.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       logprior(demo([1.0]), (m = 100.0, ))\n-5000.918938533205\n\njulia> # Using a `OrderedDict`.\n       logprior(demo([1.0]), OrderedDict(@varname(m) => 100.0))\n-5000.918938533205\n\njulia> # Truth.\n       logpdf(Normal(), 100.0)\n-5000.918938533205\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.loglikelihood","page":"API","title":"StatsAPI.loglikelihood","text":"loglikelihood(model::Model, varinfo::AbstractVarInfo)\n\nReturn the log likelihood of variables varinfo for the probabilistic model.\n\nSee also logjoint and logprior.\n\n\n\n\n\nloglikelihood(model::Model, chain::AbstractMCMC.AbstractChains)\n\nReturn an array of log likelihoods evaluated at each sample in an MCMC chain.\n\nExamples\n\njulia> using MCMCChains, Distributions\n\njulia> @model function demo_model(x)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, sqrt(s))\n           for i in eachindex(x)\n               x[i] ~ Normal(m, sqrt(s))\n           end\n       end;\n\njulia> # construct a chain of samples using MCMCChains\n       chain = Chains(rand(10, 2, 3), [:s, :m]);\n\njulia> loglikelihood(demo_model([1., 2.]), chain);\n\n\n\n\n\nloglikelihood(model::Model, θ)\n\nReturn the log likelihood of variables θ for the probabilistic model.\n\nSee also logjoint and logprior.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       loglikelihood(demo([1.0]), (m = 100.0, ))\n-4901.418938533205\n\njulia> # Using a `OrderedDict`.\n       loglikelihood(demo([1.0]), OrderedDict(@varname(m) => 100.0))\n-4901.418938533205\n\njulia> # Truth.\n       logpdf(Normal(100.0, 1.0), 1.0)\n-4901.418938533205\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.logjoint","page":"API","title":"DynamicPPL.logjoint","text":"logjoint(model::Model, varinfo::AbstractVarInfo)\n\nReturn the log joint probability of variables varinfo for the probabilistic model.\n\nNote that this probability always refers to the parameters in unlinked space, i.e., the return value of logjoint does not depend on whether VarInfo has been linked or not.\n\nSee logprior and loglikelihood.\n\n\n\n\n\nlogjoint(model::Model, chain::AbstractMCMC.AbstractChains)\n\nReturn an array of log joint probabilities evaluated at each sample in an MCMC chain.\n\nExamples\n\njulia> using MCMCChains, Distributions\n\njulia> @model function demo_model(x)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, sqrt(s))\n           for i in eachindex(x)\n               x[i] ~ Normal(m, sqrt(s))\n           end\n       end;\n\njulia> # construct a chain of samples using MCMCChains\n       chain = Chains(rand(10, 2, 3), [:s, :m]);\n\njulia> logjoint(demo_model([1., 2.]), chain);\n\n\n\n\n\nlogjoint(model::Model, θ)\n\nReturn the log joint probability of variables θ for the probabilistic model.\n\nSee logprior and loglikelihood.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       logjoint(demo([1.0]), (m = 100.0, ))\n-9902.33787706641\n\njulia> # Using a `OrderedDict`.\n       logjoint(demo([1.0]), OrderedDict(@varname(m) => 100.0))\n-9902.33787706641\n\njulia> # Truth.\n       logpdf(Normal(100.0, 1.0), 1.0) + logpdf(Normal(), 100.0)\n-9902.33787706641\n\n\n\n\n\n","category":"function"},{"location":"api/#LogDensityProblems.jl-interface","page":"API","title":"LogDensityProblems.jl interface","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The LogDensityProblems.jl interface is also supported by wrapping a Model in a DynamicPPL.LogDensityFunction.","category":"page"},{"location":"api/#DynamicPPL.LogDensityFunction","page":"API","title":"DynamicPPL.LogDensityFunction","text":"LogDensityFunction(\n    model::Model,\n    getlogdensity::Function=getlogjoint_internal,\n    varinfo::AbstractVarInfo=ldf_default_varinfo(model, getlogdensity);\n    adtype::Union{ADTypes.AbstractADType,Nothing}=nothing\n)\n\nA struct which contains a model, along with all the information necessary to:\n\ncalculate its log density at a given point;\nand if adtype is provided, calculate the gradient of the log density at\n\nthat point.\n\nThis information can be extracted using the LogDensityProblems.jl interface, specifically, using LogDensityProblems.logdensity and LogDensityProblems.logdensity_and_gradient. If adtype is nothing, then only logdensity is implemented. If adtype is a concrete AD backend type, then logdensity_and_gradient is also implemented.\n\nThere are several options for getlogdensity that are 'supported' out of the box:\n\ngetlogjoint_internal: calculate the log joint, including the log-Jacobian term for any variables that have been linked in the provided VarInfo.\ngetlogprior_internal: calculate the log prior, including the log-Jacobian term for any variables that have been linked in the provided VarInfo.\ngetlogjoint: calculate the log joint in the model space, ignoring any effects of linking\ngetlogprior: calculate the log prior in the model space, ignoring any effects of linking\ngetloglikelihood: calculate the log likelihood (this is unaffected by linking, since transforms are only applied to random variables) \n\nnote: Note\nBy default, LogDensityFunction uses getlogjoint_internal, i.e., the result of LogDensityProblems.logdensity(f, x) will depend on whether the LogDensityFunction was created with a linked or unlinked VarInfo. This is done primarily to ease interoperability with MCMC samplers.\n\nIf you provide one of these functions, a VarInfo will be automatically created for you. If you provide a different function, you have to manually create a VarInfo and pass it as the third argument.\n\nIf the adtype keyword argument is provided, then this struct will also store the adtype along with other information for efficient calculation of the gradient of the log density. Note that preparing a LogDensityFunction with an AD type AutoBackend() requires the AD backend itself to have been loaded (e.g. with import Backend).\n\nFields\n\nmodel: model used for evaluation\ngetlogdensity: function to be called on varinfo to extract the log density. By default getlogjoint_internal.\nvarinfo: varinfo used for evaluation. If not specified, generated with ldf_default_varinfo.\nadtype: AD type used for evaluation of log density gradient. If nothing, no gradient can be calculated\nprep: (internal use only) gradient preparation object for the model\n\nExamples\n\njulia> using Distributions\n\njulia> using DynamicPPL: LogDensityFunction, setaccs!!\n\njulia> @model function demo(x)\n           m ~ Normal()\n           x ~ Normal(m, 1)\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo(1.0);\n\njulia> f = LogDensityFunction(model);\n\njulia> # It implements the interface of LogDensityProblems.jl.\n       using LogDensityProblems\n\njulia> LogDensityProblems.logdensity(f, [0.0])\n-2.3378770664093453\n\njulia> LogDensityProblems.dimension(f)\n1\n\njulia> # By default it uses `VarInfo` under the hood, but this is not necessary.\n       f = LogDensityFunction(model, getlogjoint_internal, SimpleVarInfo(model));\n\njulia> LogDensityProblems.logdensity(f, [0.0])\n-2.3378770664093453\n\njulia> # One can also specify evaluating e.g. the log prior only:\n       f_prior = LogDensityFunction(model, getlogprior);\n\njulia> LogDensityProblems.logdensity(f_prior, [0.0]) == logpdf(Normal(), 0.0)\ntrue\n\njulia> # If we also need to calculate the gradient, we can specify an AD backend.\n       import ForwardDiff, ADTypes\n\njulia> f = LogDensityFunction(model, adtype=ADTypes.AutoForwardDiff());\n\njulia> LogDensityProblems.logdensity_and_gradient(f, [0.0])\n(-2.3378770664093453, [1.0])\n\n\n\n\n\n","category":"type"},{"location":"api/#Condition-and-decondition","page":"API","title":"Condition and decondition","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"A Model can be conditioned on a set of observations with AbstractPPL.condition or its alias |.","category":"page"},{"location":"api/#Base.:|-Tuple{Model, Union{Tuple, AbstractDict{<:VarName}, NamedTuple}}","page":"API","title":"Base.:|","text":"model | (x = 1.0, ...)\n\nReturn a Model which now treats variables on the right-hand side as observations.\n\nSee condition for more information and examples.\n\n\n\n\n\n","category":"method"},{"location":"api/#AbstractPPL.condition","page":"API","title":"AbstractPPL.condition","text":"condition(model::Model; values...)\ncondition(model::Model, values::NamedTuple)\n\nReturn a Model which now treats the variables in values as observations.\n\nSee also: decondition, conditioned\n\nLimitations\n\nThis does currently not work with variables that are provided to the model as arguments, e.g. @model function demo(x) ... end means that condition will not affect the variable x.\n\nTherefore if one wants to make use of condition and decondition one should not be specifying any random variables as arguments.\n\nThis is done for the sake of backwards compatibility.\n\nExamples\n\nSimple univariate model\n\njulia> using Distributions\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo();\n\njulia> m, x = model(); (m ≠ 1.0 && x ≠ 100.0)\ntrue\n\njulia> # Create a new instance which treats `x` as observed\n       # with value `100.0`, and similarly for `m=1.0`.\n       conditioned_model = condition(model, x=100.0, m=1.0);\n\njulia> m, x = conditioned_model(); (m == 1.0 && x == 100.0)\ntrue\n\njulia> # Let's only condition on `x = 100.0`.\n       conditioned_model = condition(model, x = 100.0);\n\njulia> m, x =conditioned_model(); (m ≠ 1.0 && x == 100.0)\ntrue\n\njulia> # We can also use the nicer `|` syntax.\n       conditioned_model = model | (x = 100.0, );\n\njulia> m, x = conditioned_model(); (m ≠ 1.0 && x == 100.0)\ntrue\n\nThe above uses a NamedTuple to hold the conditioning variables, which allows us to perform some additional optimizations; in many cases, the above has zero runtime-overhead.\n\nBut we can also use a Dict, which offers more flexibility in the conditioning (see examples further below) but generally has worse performance than the NamedTuple approach:\n\njulia> conditioned_model_dict = condition(model, Dict(@varname(x) => 100.0));\n\njulia> m, x = conditioned_model_dict(); (m ≠ 1.0 && x == 100.0)\ntrue\n\njulia> # There's also an option using `|` by letting the right-hand side be a tuple\n       # with elements of type `Pair{<:VarName}`, i.e. `vn => value` with `vn isa VarName`.\n       conditioned_model_dict = model | (@varname(x) => 100.0, );\n\njulia> m, x = conditioned_model_dict(); (m ≠ 1.0 && x == 100.0)\ntrue\n\nCondition only a part of a multivariate variable\n\nNot only can be condition on multivariate random variables, but we can also use the standard mechanism of setting something to missing in the call to condition to only condition on a part of the variable.\n\njulia> @model function demo_mv(::Type{TV}=Float64) where {TV}\n           m = Vector{TV}(undef, 2)\n           m[1] ~ Normal()\n           m[2] ~ Normal()\n           return m\n       end\ndemo_mv (generic function with 4 methods)\n\njulia> model = demo_mv();\n\njulia> conditioned_model = condition(model, m = [missing, 1.0]);\n\njulia> # (✓) `m[1]` sampled while `m[2]` is fixed\n       m = conditioned_model(); (m[1] ≠ 1.0 && m[2] == 1.0)\ntrue\n\nIntuitively one might also expect to be able to write model | (m[1] = 1.0, ). Unfortunately this is not supported as it has the potential of increasing compilation times but without offering any benefit with respect to runtime:\n\njulia> # (×) `m[2]` is not set to 1.0.\n       m = condition(model, var\"m[2]\" = 1.0)(); m[2] == 1.0\nfalse\n\nBut you can do this if you use a Dict as the underlying storage instead:\n\njulia> # Alternatives:\n       # - `model | (@varname(m[2]) => 1.0,)`\n       # - `condition(model, Dict(@varname(m[2] => 1.0)))`\n       # (✓) `m[2]` is set to 1.0.\n       m = condition(model, @varname(m[2]) => 1.0)(); (m[1] ≠ 1.0 && m[2] == 1.0)\ntrue\n\nNested models\n\ncondition of course also supports the use of nested models through the use of to_submodel.\n\njulia> @model demo_inner() = m ~ Normal()\ndemo_inner (generic function with 2 methods)\n\njulia> @model function demo_outer()\n           # By default, `to_submodel` prefixes the variables using the left-hand side of `~`.\n           inner ~ to_submodel(demo_inner())\n           return inner\n       end\ndemo_outer (generic function with 2 methods)\n\njulia> model = demo_outer();\n\njulia> model() ≠ 1.0\ntrue\n\njulia> # To condition the variable inside `demo_inner` we need to refer to it as `inner.m`.\n       conditioned_model = model | (@varname(inner.m) => 1.0, );\n\njulia> conditioned_model()\n1.0\n\njulia> # However, it's not possible to condition `inner` directly.\n       conditioned_model_fail = model | (inner = 1.0, );\n\njulia> conditioned_model_fail()\nERROR: ArgumentError: `x ~ to_submodel(...)` is not supported when `x` is observed\n[...]\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.conditioned","page":"API","title":"DynamicPPL.conditioned","text":"conditioned(model::Model)\n\nReturn the conditioned values in model.\n\nExamples\n\njulia> using Distributions\n\njulia> using DynamicPPL: conditioned, contextualize\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n       end\ndemo (generic function with 2 methods)\n\njulia> m = demo();\n\njulia> # Returns all the variables we have conditioned on + their values.\n       conditioned(condition(m, x=100.0, m=1.0))\n(x = 100.0, m = 1.0)\n\njulia> # Nested ones also work.\n       # (Note that `PrefixContext` also prefixes the variables of any\n       # ConditionContext that is _inside_ it; because of this, the type of the\n       # container has to be broadened to a `Dict`.)\n       cm = condition(contextualize(m, PrefixContext(@varname(a), ConditionContext((m=1.0,)))), x=100.0);\n\njulia> Set(keys(conditioned(cm))) == Set([@varname(a.m), @varname(x)])\ntrue\n\njulia> # Since we conditioned on `a.m`, it is not treated as a random variable.\n       # However, `a.x` will still be a random variable.\n       keys(VarInfo(cm))\n1-element Vector{VarName{:a, Accessors.PropertyLens{:x}}}:\n a.x\n\njulia> # We can also condition on `a.m` _outside_ of the PrefixContext:\n       cm = condition(contextualize(m, PrefixContext(@varname(a))), (@varname(a.m) => 1.0));\n\njulia> conditioned(cm)\nDict{VarName{:a, Accessors.PropertyLens{:m}}, Float64} with 1 entry:\n  a.m => 1.0\n\njulia> # Now `a.x` will be sampled.\n       keys(VarInfo(cm))\n1-element Vector{VarName{:a, Accessors.PropertyLens{:x}}}:\n a.x\n\n\n\n\n\nconditioned(context::AbstractContext)\n\nReturn NamedTuple of values that are conditioned on under context`.\n\nNote that this will recursively traverse the context stack and return a merged version of the condition values.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"Similarly, one can specify with AbstractPPL.decondition that certain, or all, random variables are not observed.","category":"page"},{"location":"api/#AbstractPPL.decondition","page":"API","title":"AbstractPPL.decondition","text":"decondition(model::Model)\ndecondition(model::Model, variables...)\n\nReturn a Model for which variables... are not considered observations. If no variables are provided, then all variables currently considered observations will no longer be.\n\nThis is essentially the inverse of condition. This also means that it suffers from the same limitiations.\n\nNote that currently we only support variables to take on explicit values provided to condition.\n\nExamples\n\njulia> using Distributions\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> conditioned_model = condition(demo(), m = 1.0, x = 10.0);\n\njulia> conditioned_model()\n(m = 1.0, x = 10.0)\n\njulia> # By specifying the `VarName` to `decondition`.\n       model = decondition(conditioned_model, @varname(m));\n\njulia> (m, x) = model(); (m ≠ 1.0 && x == 10.0)\ntrue\n\njulia> # When `NamedTuple` is used as the underlying, you can also provide\n       # the symbol directly (though the `@varname` approach is preferable if\n       # if the variable is known at compile-time).\n       model = decondition(conditioned_model, :m);\n\njulia> (m, x) = model(); (m ≠ 1.0 && x == 10.0)\ntrue\n\njulia> # `decondition` multiple at once:\n       (m, x) = decondition(model, :m, :x)(); (m ≠ 1.0 && x ≠ 10.0)\ntrue\n\njulia> # `decondition` without any symbols will `decondition` all variables.\n       (m, x) = decondition(model)(); (m ≠ 1.0 && x ≠ 10.0)\ntrue\n\njulia> # Usage of `Val` to perform `decondition` at compile-time if possible\n       # is also supported.\n       model = decondition(conditioned_model, Val{:m}());\n\njulia> (m, x) = model(); (m ≠ 1.0 && x == 10.0)\ntrue\n\nSimilarly when using a Dict:\n\njulia> conditioned_model_dict = condition(demo(), @varname(m) => 1.0, @varname(x) => 10.0);\n\njulia> conditioned_model_dict()\n(m = 1.0, x = 10.0)\n\njulia> deconditioned_model_dict = decondition(conditioned_model_dict, @varname(m));\n\njulia> (m, x) = deconditioned_model_dict(); m ≠ 1.0 && x == 10.0\ntrue\n\nBut, as mentioned, decondition is only supported for variables explicitly provided to condition earlier;\n\njulia> @model function demo_mv(::Type{TV}=Float64) where {TV}\n           m = Vector{TV}(undef, 2)\n           m[1] ~ Normal()\n           m[2] ~ Normal()\n           return m\n       end\ndemo_mv (generic function with 4 methods)\n\njulia> model = demo_mv();\n\njulia> conditioned_model = condition(model, @varname(m) => [1.0, 2.0]);\n\njulia> conditioned_model()\n2-element Vector{Float64}:\n 1.0\n 2.0\n\njulia> deconditioned_model = decondition(conditioned_model, @varname(m[1]));\n\njulia> deconditioned_model()  # (×) `m[1]` is still conditioned\n2-element Vector{Float64}:\n 1.0\n 2.0\n\njulia> # (✓) this works though\n       deconditioned_model_2 = deconditioned_model | (@varname(m[1]) => missing);\n\njulia> m = deconditioned_model_2(); (m[1] ≠ 1.0 && m[2] == 2.0)\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#Fixing-and-unfixing","page":"API","title":"Fixing and unfixing","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"We can also fix a collection of variables in a Model to certain values using DynamicPPL.fix.","category":"page"},{"location":"api/","page":"API","title":"API","text":"This is quite similar to the aforementioned condition and its siblings, but they are indeed different operations:","category":"page"},{"location":"api/","page":"API","title":"API","text":"conditioned variables are considered to be observations, and are thus included in the computation logjoint and loglikelihood, but not in logprior.\nfixed variables are considered to be constant, and are thus not included in any log-probability computations.","category":"page"},{"location":"api/","page":"API","title":"API","text":"The differences are more clearly spelled out in the docstring of DynamicPPL.fix below.","category":"page"},{"location":"api/#DynamicPPL.fix","page":"API","title":"DynamicPPL.fix","text":"fix(model::Model; values...)\nfix(model::Model, values::NamedTuple)\n\nReturn a Model which now treats the variables in values as fixed.\n\nSee also: unfix, fixed\n\nExamples\n\nSimple univariate model\n\njulia> using Distributions\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo();\n\njulia> m, x = model(); (m ≠ 1.0 && x ≠ 100.0)\ntrue\n\njulia> # Create a new instance which treats `x` as observed\n       # with value `100.0`, and similarly for `m=1.0`.\n       fixed_model = fix(model, x=100.0, m=1.0);\n\njulia> m, x = fixed_model(); (m == 1.0 && x == 100.0)\ntrue\n\njulia> # Let's only fix on `x = 100.0`.\n       fixed_model = fix(model, x = 100.0);\n\njulia> m, x = fixed_model(); (m ≠ 1.0 && x == 100.0)\ntrue\n\nThe above uses a NamedTuple to hold the fixed variables, which allows us to perform some additional optimizations; in many cases, the above has zero runtime-overhead.\n\nBut we can also use a Dict, which offers more flexibility in the fixing (see examples further below) but generally has worse performance than the NamedTuple approach:\n\njulia> fixed_model_dict = fix(model, Dict(@varname(x) => 100.0));\n\njulia> m, x = fixed_model_dict(); (m ≠ 1.0 && x == 100.0)\ntrue\n\njulia> # Alternative: pass `Pair{<:VarName}` as positional argument.\n       fixed_model_dict = fix(model, @varname(x) => 100.0, );\n\njulia> m, x = fixed_model_dict(); (m ≠ 1.0 && x == 100.0)\ntrue\n\nFix only a part of a multivariate variable\n\nWe can not only fix multivariate random variables, but we can also use the standard mechanism of setting something to missing in the call to fix to only fix a part of the variable.\n\njulia> @model function demo_mv(::Type{TV}=Float64) where {TV}\n           m = Vector{TV}(undef, 2)\n           m[1] ~ Normal()\n           m[2] ~ Normal()\n           return m\n       end\ndemo_mv (generic function with 4 methods)\n\njulia> model = demo_mv();\n\njulia> fixed_model = fix(model, m = [missing, 1.0]);\n\njulia> # (✓) `m[1]` sampled while `m[2]` is fixed\n       m = fixed_model(); (m[1] ≠ 1.0 && m[2] == 1.0)\ntrue\n\nIntuitively one might also expect to be able to write something like fix(model, var\"m[1]\" = 1.0, ). Unfortunately this is not supported as it has the potential of increasing compilation times but without offering any benefit with respect to runtime:\n\njulia> # (×) `m[2]` is not set to 1.0.\n       m = fix(model, var\"m[2]\" = 1.0)(); m[2] == 1.0\nfalse\n\nBut you can do this if you use a Dict as the underlying storage instead:\n\njulia> # Alternative: `fix(model, Dict(@varname(m[2] => 1.0)))`\n       # (✓) `m[2]` is set to 1.0.\n       m = fix(model, @varname(m[2]) => 1.0)(); (m[1] ≠ 1.0 && m[2] == 1.0)\ntrue\n\nNested models\n\nfix of course also supports the use of nested models through the use of to_submodel, similar to condition.\n\njulia> @model demo_inner() = m ~ Normal()\ndemo_inner (generic function with 2 methods)\n\njulia> @model function demo_outer()\n           inner ~ to_submodel(demo_inner())\n           return inner\n       end\ndemo_outer (generic function with 2 methods)\n\njulia> model = demo_outer();\n\njulia> model() ≠ 1.0\ntrue\n\njulia> fixed_model = fix(model, (@varname(inner.m) => 1.0, ));\n\njulia> fixed_model()\n1.0\n\nHowever, unlike condition, fix can also be used to fix the return-value of the submodel:\n\njulia> fixed_model = fix(model, inner = 2.0,);\n\njulia> fixed_model()\n2.0\n\nDifference from condition\n\nA very similar functionality is also provided by condition. The only difference between fixing and conditioning is as follows:\n\nconditioned variables are considered to be observations, and are thus included in the computation logjoint and loglikelihood, but not in logprior.\nfixed variables are considered to be constant, and are thus not included in any log-probability computations.\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo();\n\njulia> model_fixed = fix(model, m = 1.0);\n\njulia> model_conditioned = condition(model, m = 1.0);\n\njulia> logjoint(model_fixed, (x=1.0,))\n-0.9189385332046728\n\njulia> # Different!\n       logjoint(model_conditioned, (x=1.0,))\n-2.3378770664093453\n\njulia> # And the difference is the missing log-probability of `m`:\n       logjoint(model_fixed, (x=1.0,)) + logpdf(Normal(), 1.0) == logjoint(model_conditioned, (x=1.0,))\ntrue\n\n\n\n\n\nfix([context::AbstractContext,] values::NamedTuple)\nfix([context::AbstractContext]; values...)\n\nReturn FixedContext with values and context if values is non-empty, otherwise return context which is DefaultContext by default.\n\nSee also: unfix\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.fixed","page":"API","title":"DynamicPPL.fixed","text":"fixed(model::Model)\n\nReturn the fixed values in model.\n\nExamples\n\njulia> using Distributions\n\njulia> using DynamicPPL: fixed, contextualize\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n       end\ndemo (generic function with 2 methods)\n\njulia> m = demo();\n\njulia> # Returns all the variables we have fixed on + their values.\n       fixed(fix(m, x=100.0, m=1.0))\n(x = 100.0, m = 1.0)\n\njulia> # The rest of this is the same as the `condition` example above.\n       cm = fix(contextualize(m, PrefixContext(@varname(a), fix(m=1.0))), x=100.0);\n\njulia> Set(keys(fixed(cm))) == Set([@varname(a.m), @varname(x)])\ntrue\n\njulia> keys(VarInfo(cm))\n1-element Vector{VarName{:a, Accessors.PropertyLens{:x}}}:\n a.x\n\njulia> # We can also condition on `a.m` _outside_ of the PrefixContext:\n       cm = fix(contextualize(m, PrefixContext(@varname(a))), (@varname(a.m) => 1.0));\n\njulia> fixed(cm)\nDict{VarName{:a, Accessors.PropertyLens{:m}}, Float64} with 1 entry:\n  a.m => 1.0\n\njulia> # Now `a.x` will be sampled.\n       keys(VarInfo(cm))\n1-element Vector{VarName{:a, Accessors.PropertyLens{:x}}}:\n a.x\n\n\n\n\n\nfixed(context::AbstractContext)\n\nReturn the values that are fixed under context.\n\nNote that this will recursively traverse the context stack and return a merged version of the fix values.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"The difference between DynamicPPL.fix and DynamicPPL.condition is described in the docstring of DynamicPPL.fix above.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Similarly, we can revert this with DynamicPPL.unfix, i.e. return the variables to their original meaning:","category":"page"},{"location":"api/#DynamicPPL.unfix","page":"API","title":"DynamicPPL.unfix","text":"unfix(model::Model)\nunfix(model::Model, variables...)\n\nReturn a Model for which variables... are not considered fixed. If no variables are provided, then all variables currently considered fixed will no longer be.\n\nThis is essentially the inverse of fix. This also means that it suffers from the same limitiations.\n\nNote that currently we only support variables to take on explicit values provided to fix.\n\nExamples\n\njulia> using Distributions\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> fixed_model = fix(demo(), m = 1.0, x = 10.0);\n\njulia> fixed_model()\n(m = 1.0, x = 10.0)\n\njulia> # By specifying the `VarName` to `unfix`.\n       model = unfix(fixed_model, @varname(m));\n\njulia> (m, x) = model(); (m ≠ 1.0 && x == 10.0)\ntrue\n\njulia> # When `NamedTuple` is used as the underlying, you can also provide\n       # the symbol directly (though the `@varname` approach is preferable if\n       # if the variable is known at compile-time).\n       model = unfix(fixed_model, :m);\n\njulia> (m, x) = model(); (m ≠ 1.0 && x == 10.0)\ntrue\n\njulia> # `unfix` multiple at once:\n       (m, x) = unfix(model, :m, :x)(); (m ≠ 1.0 && x ≠ 10.0)\ntrue\n\njulia> # `unfix` without any symbols will `unfix` all variables.\n       (m, x) = unfix(model)(); (m ≠ 1.0 && x ≠ 10.0)\ntrue\n\njulia> # Usage of `Val` to perform `unfix` at compile-time if possible\n       # is also supported.\n       model = unfix(fixed_model, Val{:m}());\n\njulia> (m, x) = model(); (m ≠ 1.0 && x == 10.0)\ntrue\n\nSimilarly when using a Dict:\n\njulia> fixed_model_dict = fix(demo(), @varname(m) => 1.0, @varname(x) => 10.0);\n\njulia> fixed_model_dict()\n(m = 1.0, x = 10.0)\n\njulia> unfixed_model_dict = unfix(fixed_model_dict, @varname(m));\n\njulia> (m, x) = unfixed_model_dict(); m ≠ 1.0 && x == 10.0\ntrue\n\nBut, as mentioned, unfix is only supported for variables explicitly provided to fix earlier:\n\njulia> @model function demo_mv(::Type{TV}=Float64) where {TV}\n           m = Vector{TV}(undef, 2)\n           m[1] ~ Normal()\n           m[2] ~ Normal()\n           return m\n       end\ndemo_mv (generic function with 4 methods)\n\njulia> model = demo_mv();\n\njulia> fixed_model = fix(model, @varname(m) => [1.0, 2.0]);\n\njulia> fixed_model()\n2-element Vector{Float64}:\n 1.0\n 2.0\n\njulia> unfixed_model = unfix(fixed_model, @varname(m[1]));\n\njulia> unfixed_model()  # (×) `m[1]` is still fixed\n2-element Vector{Float64}:\n 1.0\n 2.0\n\njulia> # (✓) this works though\n       unfixed_model_2 = fix(unfixed_model, @varname(m[1]) => missing);\n\njulia> m = unfixed_model_2(); (m[1] ≠ 1.0 && m[2] == 2.0)\ntrue\n\n\n\n\n\nunfix(context::AbstractContext, syms...)\n\nReturn context but with syms no longer fixed.\n\nNote that this recursively traverses contexts, unfixing all along the way.\n\nSee also: fix\n\n\n\n\n\n","category":"function"},{"location":"api/#Predicting","page":"API","title":"Predicting","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"DynamicPPL provides functionality for generating samples from the posterior predictive distribution through the predict function. This allows you to use posterior parameter samples to generate predictions for unobserved data points.","category":"page"},{"location":"api/","page":"API","title":"API","text":"The predict function has two main methods:","category":"page"},{"location":"api/","page":"API","title":"API","text":"For AbstractVector{<:AbstractVarInfo} - useful when you have a collection of VarInfo objects representing posterior samples.\nFor MCMCChains.Chains (only available when MCMCChains.jl is loaded) - useful when you have posterior samples in the form of an MCMCChains.Chains object.","category":"page"},{"location":"api/#StatsAPI.predict","page":"API","title":"StatsAPI.predict","text":"predict([rng::Random.AbstractRNG,] model::Model, chain::AbstractVector{<:AbstractVarInfo})\n\nGenerate samples from the posterior predictive distribution by evaluating model at each set of parameter values provided in chain. The number of posterior predictive samples matches the length of chain. The returned AbstractVarInfos will contain both the posterior parameter values and the predicted values.\n\n\n\n\n\npredict([rng::AbstractRNG,] model::Model, chain::MCMCChains.Chains; include_all=false)\n\nSample from the posterior predictive distribution by executing model with parameters fixed to each sample in chain, and return the resulting Chains.\n\nThe model passed to predict is often different from the one used to generate chain. Typically, the model from which chain originated treats certain variables as observed (i.e., data points), while the model you pass to predict may mark these same variables as missing or unobserved. Calling predict then leverages the previously inferred parameter values to simulate what new, unobserved data might look like, given your posterior beliefs.\n\nFor each parameter configuration in chain:\n\nAll random variables present in chain are fixed to their sampled values.\nAny variables not included in chain are sampled from their prior distributions.\n\nIf include_all is false, the returned Chains will contain only those variables that were not fixed by the samples in chain. This is useful when you want to sample only new variables from the posterior predictive distribution.\n\nExamples\n\nusing AbstractMCMC, Distributions, DynamicPPL, Random\n\n@model function linear_reg(x, y, σ = 0.1)\n    β ~ Normal(0, 1)\n    for i in eachindex(y)\n        y[i] ~ Normal(β * x[i], σ)\n    end\nend\n\n# Generate synthetic chain using known ground truth parameter\nground_truth_β = 2.0\n\n# Create chain of samples from a normal distribution centered on ground truth\nβ_chain = MCMCChains.Chains(\n    rand(Normal(ground_truth_β, 0.002), 1000), [:β,]\n)\n\n# Generate predictions for two test points\nxs_test = [10.1, 10.2]\n\nm_train = linear_reg(xs_test, fill(missing, length(xs_test)))\n\npredictions = DynamicPPL.AbstractPPL.predict(\n    Random.default_rng(), m_train, β_chain\n)\n\nys_pred = vec(mean(Array(predictions); dims=1))\n\n# Check if predictions match expected values within tolerance\n(\n    isapprox(ys_pred[1], ground_truth_β * xs_test[1], atol = 0.01),\n    isapprox(ys_pred[2], ground_truth_β * xs_test[2], atol = 0.01)\n)\n\n# output\n\n(true, true)\n\n\n\n\n\n","category":"function"},{"location":"api/#Basic-Usage","page":"API","title":"Basic Usage","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The typical workflow for posterior prediction involves:","category":"page"},{"location":"api/","page":"API","title":"API","text":"Fitting a model to observed data to obtain posterior samples\nCreating a new model instance with some variables marked as missing (unobserved)\nUsing predict to generate samples for these missing variables based on the posterior parameter samples","category":"page"},{"location":"api/","page":"API","title":"API","text":"When using predict with MCMCChains.Chains, you can control which variables are included in the output with the include_all parameter:","category":"page"},{"location":"api/","page":"API","title":"API","text":"include_all=false (default): Include only newly predicted variables\ninclude_all=true: Include both parameters from the original chain and predicted variables","category":"page"},{"location":"api/#Models-within-models","page":"API","title":"Models within models","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"One can include models and call another model inside the model function with left ~ to_submodel(model).","category":"page"},{"location":"api/#DynamicPPL.to_submodel","page":"API","title":"DynamicPPL.to_submodel","text":"to_submodel(model::Model[, auto_prefix::Bool])\n\nReturn a model wrapper indicating that it is a sampleable model over the return-values.\n\nThis is mainly meant to be used on the right-hand side of a ~ operator to indicate that the model can be sampled from but not necessarily evaluated for its log density.\n\nwarning: Warning\nNote that some other operations that one typically associate with expressions of the form left ~ right such as condition, will also not work with to_submodel.\n\nwarning: Warning\nTo avoid variable names clashing between models, it is recommended to leave the argument auto_prefix equal to true. If one does not use automatic prefixing, then it's recommended to use prefix(::Model, input) explicitly, i.e. to_submodel(prefix(model, @varname(my_prefix)))\n\nArguments\n\nmodel::Model: the model to wrap.\nauto_prefix::Bool: whether to automatically prefix the variables in the model using the left-hand   side of the ~ statement. Default: true.\n\nExamples\n\nSimple example\n\njulia> @model function demo1(x)\n           x ~ Normal()\n           return 1 + abs(x)\n       end;\n\njulia> @model function demo2(x, y)\n            a ~ to_submodel(demo1(x))\n            return y ~ Uniform(0, a)\n       end;\n\nWhen we sample from the model demo2(missing, 0.4) random variable x will be sampled:\n\njulia> vi = VarInfo(demo2(missing, 0.4));\n\njulia> @varname(a.x) in keys(vi)\ntrue\n\nThe variable a is not tracked. However, it will be assigned the return value of demo1, and can be used in subsequent lines of the model, as shown above.\n\njulia> @varname(a) in keys(vi)\nfalse\n\nWe can check that the log joint probability of the model accumulated in vi is correct:\n\njulia> x = vi[@varname(a.x)];\n\njulia> getlogjoint(vi) ≈ logpdf(Normal(), x) + logpdf(Uniform(0, 1 + abs(x)), 0.4)\ntrue\n\nWithout automatic prefixing\n\nAs mentioned earlier, by default, the auto_prefix argument specifies whether to automatically prefix the variables in the submodel. If auto_prefix=false, then the variables in the submodel will not be prefixed.\n\njulia> @model function demo1(x)\n           x ~ Normal()\n           return 1 + abs(x)\n       end;\n\njulia> @model function demo2_no_prefix(x, z)\n            a ~ to_submodel(demo1(x), false)\n            return z ~ Uniform(-a, 1)\n       end;\n\njulia> vi = VarInfo(demo2_no_prefix(missing, 0.4));\n\njulia> @varname(x) in keys(vi)  # here we just use `x` instead of `a.x`\ntrue\n\nHowever, not using prefixing is generally not recommended as it can lead to variable name clashes unless one is careful. For example, if we're re-using the same model twice in a model, not using prefixing will lead to variable name clashes: However, one can manually prefix using the prefix(::Model, input):\n\njulia> @model function demo2(x, y, z)\n            a ~ to_submodel(prefix(demo1(x), :sub1), false)\n            b ~ to_submodel(prefix(demo1(y), :sub2), false)\n            return z ~ Uniform(-a, b)\n       end;\n\njulia> vi = VarInfo(demo2(missing, missing, 0.4));\n\njulia> @varname(sub1.x) in keys(vi)\ntrue\n\njulia> @varname(sub2.x) in keys(vi)\ntrue\n\nVariables a and b are not tracked, but are assigned the return values of the respective calls to demo1:\n\njulia> @varname(a) in keys(vi)\nfalse\n\njulia> @varname(b) in keys(vi)\nfalse\n\nWe can check that the log joint probability of the model accumulated in vi is correct:\n\njulia> sub1_x = vi[@varname(sub1.x)];\n\njulia> sub2_x = vi[@varname(sub2.x)];\n\njulia> logprior = logpdf(Normal(), sub1_x) + logpdf(Normal(), sub2_x);\n\njulia> loglikelihood = logpdf(Uniform(-1 - abs(sub1_x), 1 + abs(sub2_x)), 0.4);\n\njulia> getlogjoint(vi) ≈ logprior + loglikelihood\ntrue\n\nUsage as likelihood is illegal\n\nNote that it is illegal to use a to_submodel model as a likelihood in another model:\n\njulia> @model inner() = x ~ Normal()\ninner (generic function with 2 methods)\n\njulia> @model illegal_likelihood() = a ~ to_submodel(inner())\nillegal_likelihood (generic function with 2 methods)\n\njulia> model = illegal_likelihood() | (a = 1.0,);\n\njulia> model()\nERROR: ArgumentError: `x ~ to_submodel(...)` is not supported when `x` is observed\n[...]\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"Note that a [to_submodel](@ref) is only sampleable; one cannot compute logpdf for its realizations.","category":"page"},{"location":"api/","page":"API","title":"API","text":"In the context of including models within models, it's also useful to prefix the variables in sub-models to avoid variable names clashing:","category":"page"},{"location":"api/#DynamicPPL.prefix","page":"API","title":"DynamicPPL.prefix","text":"prefix(ctx::AbstractContext, vn::VarName)\n\nApply the prefixes in the context ctx to the variable name vn.\n\n\n\n\n\nprefix(model::Model, x::VarName)\nprefix(model::Model, x::Val{sym})\nprefix(model::Model, x::Any)\n\nReturn model but with all random variables prefixed by x, where x is either:\n\na VarName (e.g. @varname(a)),\na Val{sym} (e.g. Val(:a)), or\nfor any other type, x is converted to a Symbol and then to a VarName. Note that this will introduce runtime overheads so is not recommended unless absolutely necessary.\n\nExamples\n\njulia> using DynamicPPL: prefix\n\njulia> @model demo() = x ~ Dirac(1)\ndemo (generic function with 2 methods)\n\njulia> rand(prefix(demo(), @varname(my_prefix)))\n(var\"my_prefix.x\" = 1,)\n\njulia> rand(prefix(demo(), Val(:my_prefix)))\n(var\"my_prefix.x\" = 1,)\n\n\n\n\n\n","category":"function"},{"location":"api/#Utilities","page":"API","title":"Utilities","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"It is possible to manually increase (or decrease) the accumulated log likelihood or prior from within a model function.","category":"page"},{"location":"api/#DynamicPPL.@addlogprob!","page":"API","title":"DynamicPPL.@addlogprob!","text":"@addlogprob!(ex)\n\nAdd a term to the log joint.\n\nIf ex evaluates to a NamedTuple with keys :loglikelihood and/or :logprior, the values are added to the log likelihood and log prior respectively.\n\nIf ex evaluates to a number it is added to the log likelihood.\n\nExamples\n\njulia> mylogjoint(x, μ) = (; loglikelihood=loglikelihood(Normal(μ, 1), x), logprior=1.0);\n\njulia> @model function demo(x)\n           μ ~ Normal()\n           @addlogprob! mylogjoint(x, μ)\n       end;\n\njulia> x = [1.3, -2.1];\n\njulia> loglikelihood(demo(x), (μ=0.2,)) ≈ mylogjoint(x, 0.2).loglikelihood\ntrue\n\njulia> logprior(demo(x), (μ=0.2,)) ≈ logpdf(Normal(), 0.2) + mylogjoint(x, 0.2).logprior\ntrue\n\nand to reject samples:\n\njulia> @model function demo(x)\n           m ~ MvNormal(zero(x), I)\n           if dot(m, x) < 0\n               @addlogprob! (; loglikelihood=-Inf)\n               # Exit the model evaluation early\n               return\n           end\n           x ~ MvNormal(m, I)\n           return\n       end;\n\njulia> logjoint(demo([-2.1]), (m=[0.2],)) == -Inf\ntrue\n\n\n\n\n\n","category":"macro"},{"location":"api/","page":"API","title":"API","text":"Return values of the model function can be obtained with returned(model, sample), where sample is either a MCMCChains.Chains object (which represents a collection of samples) or a single sample represented as a NamedTuple.","category":"page"},{"location":"api/#DynamicPPL.returned-Tuple{Model, Chains}","page":"API","title":"DynamicPPL.returned","text":"returned(model::Model, chain::MCMCChains.Chains)\n\nExecute model for each of the samples in chain and return an array of the values returned by the model for each sample.\n\nExamples\n\nGeneral\n\nOften you might have additional quantities computed inside the model that you want to inspect, e.g.\n\n@model function demo(x)\n    # sample and observe\n    θ ~ Prior()\n    x ~ Likelihood()\n    return interesting_quantity(θ, x)\nend\nm = demo(data)\nchain = sample(m, alg, n)\n# To inspect the `interesting_quantity(θ, x)` where `θ` is replaced by samples\n# from the posterior/`chain`:\nreturned(m, chain) # <= results in a `Vector` of returned values\n                               #    from `interesting_quantity(θ, x)`\n\nConcrete (and simple)\n\njulia> using Turing\n\njulia> @model function demo(xs)\n           s ~ InverseGamma(2, 3)\n           m_shifted ~ Normal(10, √s)\n           m = m_shifted - 10\n\n           for i in eachindex(xs)\n               xs[i] ~ Normal(m, √s)\n           end\n\n           return (m, )\n       end\ndemo (generic function with 1 method)\n\njulia> model = demo(randn(10));\n\njulia> chain = sample(model, MH(), 10);\n\njulia> returned(model, chain)\n10×1 Array{Tuple{Float64},2}:\n (2.1964758025119338,)\n (2.1964758025119338,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.043088571494005024,)\n (-0.16489786710222099,)\n (-0.16489786710222099,)\n\n\n\n\n\n","category":"method"},{"location":"api/#DynamicPPL.returned-Tuple{Model, NamedTuple}","page":"API","title":"DynamicPPL.returned","text":"returned(model::Model, parameters::NamedTuple)\nreturned(model::Model, values, keys)\nreturned(model::Model, values, keys)\n\nExecute model with variables keys set to values and return the values returned by the model.\n\nIf a NamedTuple is given, keys=keys(parameters) and values=values(parameters).\n\nExample\n\njulia> using DynamicPPL, Distributions\n\njulia> @model function demo(xs)\n           s ~ InverseGamma(2, 3)\n           m_shifted ~ Normal(10, √s)\n           m = m_shifted - 10\n           for i in eachindex(xs)\n               xs[i] ~ Normal(m, √s)\n           end\n           return (m, )\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo(randn(10));\n\njulia> parameters = (; s = 1.0, m_shifted=10.0);\n\njulia> returned(model, parameters)\n(0.0,)\n\njulia> returned(model, values(parameters), keys(parameters))\n(0.0,)\n\n\n\n\n\n","category":"method"},{"location":"api/","page":"API","title":"API","text":"For a chain of samples, one can compute the pointwise log-likelihoods of each observed random variable with pointwise_loglikelihoods. Similarly, the log-densities of the priors using pointwise_prior_logdensities or both, i.e. all variables, using pointwise_logdensities.","category":"page"},{"location":"api/#DynamicPPL.pointwise_logdensities","page":"API","title":"DynamicPPL.pointwise_logdensities","text":"pointwise_logdensities(\n    model::Model,\n    chain::Chains,\n    keytype=String,\n    ::Val{whichlogprob}=Val(:both),\n)\n\nRuns model on each sample in chain returning a OrderedDict{String, Matrix{Float64}} with keys corresponding to symbols of the variables, and values being matrices of shape (num_chains, num_samples).\n\nkeytype specifies what the type of the keys used in the returned OrderedDict are. Currently, only String and VarName are supported. whichlogprob specifies which log-probabilities to compute. It can be :both, :prior, or :likelihood.\n\nSee also: pointwise_loglikelihoods, pointwise_loglikelihoods.\n\nNotes\n\nSay y is a Vector of n i.i.d. Normal(μ, σ) variables, with μ and σ both being <:Real. Then the observe (i.e. when the left-hand side is an observation) statements can be implemented in three ways:\n\nusing a for loop:\n\nfor i in eachindex(y)\n    y[i] ~ Normal(μ, σ)\nend\n\nusing .~:\n\ny .~ Normal(μ, σ)\n\nusing MvNormal:\n\ny ~ MvNormal(fill(μ, n), σ^2 * I)\n\nIn (1) and (2), y will be treated as a collection of n i.i.d. 1-dimensional variables, while in (3) y will be treated as a single n-dimensional observation.\n\nThis is important to keep in mind, in particular if the computation is used for downstream computations.\n\nExamples\n\nFrom chain\n\njulia> using MCMCChains\n\njulia> @model function demo(xs, y)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, √s)\n           for i in eachindex(xs)\n               xs[i] ~ Normal(m, √s)\n           end\n           y ~ Normal(m, √s)\n       end\ndemo (generic function with 2 methods)\n\njulia> # Example observations.\n       model = demo([1.0, 2.0, 3.0], [4.0]);\n\njulia> # A chain with 3 iterations.\n       chain = Chains(\n           reshape(1.:6., 3, 2),\n           [:s, :m]\n       );\n\njulia> pointwise_logdensities(model, chain)\nOrderedDict{String, Matrix{Float64}} with 6 entries:\n  \"s\"     => [-0.802775; -1.38222; -2.09861;;]\n  \"m\"     => [-8.91894; -7.51551; -7.46824;;]\n  \"xs[1]\" => [-5.41894; -5.26551; -5.63491;;]\n  \"xs[2]\" => [-2.91894; -3.51551; -4.13491;;]\n  \"xs[3]\" => [-1.41894; -2.26551; -2.96824;;]\n  \"y\"     => [-0.918939; -1.51551; -2.13491;;]\n\njulia> pointwise_logdensities(model, chain, String)\nOrderedDict{String, Matrix{Float64}} with 6 entries:\n  \"s\"     => [-0.802775; -1.38222; -2.09861;;]\n  \"m\"     => [-8.91894; -7.51551; -7.46824;;]\n  \"xs[1]\" => [-5.41894; -5.26551; -5.63491;;]\n  \"xs[2]\" => [-2.91894; -3.51551; -4.13491;;]\n  \"xs[3]\" => [-1.41894; -2.26551; -2.96824;;]\n  \"y\"     => [-0.918939; -1.51551; -2.13491;;]\n\njulia> pointwise_logdensities(model, chain, VarName)\nOrderedDict{VarName, Matrix{Float64}} with 6 entries:\n  s     => [-0.802775; -1.38222; -2.09861;;]\n  m     => [-8.91894; -7.51551; -7.46824;;]\n  xs[1] => [-5.41894; -5.26551; -5.63491;;]\n  xs[2] => [-2.91894; -3.51551; -4.13491;;]\n  xs[3] => [-1.41894; -2.26551; -2.96824;;]\n  y     => [-0.918939; -1.51551; -2.13491;;]\n\nBroadcasting\n\nNote that x .~ Dist() will treat x as a collection of independent observations rather than as a single observation.\n\njulia> @model function demo(x)\n           x .~ Normal()\n       end;\n\njulia> m = demo([1.0, ]);\n\njulia> ℓ = pointwise_logdensities(m, VarInfo(m)); first(ℓ[@varname(x[1])])\n-1.4189385332046727\n\njulia> m = demo([1.0; 1.0]);\n\njulia> ℓ = pointwise_logdensities(m, VarInfo(m)); first.((ℓ[@varname(x[1])], ℓ[@varname(x[2])]))\n(-1.4189385332046727, -1.4189385332046727)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.pointwise_loglikelihoods","page":"API","title":"DynamicPPL.pointwise_loglikelihoods","text":"pointwise_loglikelihoods(model, chain[, keytype])\n\nCompute the pointwise log-likelihoods of the model given the chain. This is the same as pointwise_logdensities(model, chain), but only including the likelihood terms.\n\nSee also: pointwise_logdensities, pointwise_prior_logdensities.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.pointwise_prior_logdensities","page":"API","title":"DynamicPPL.pointwise_prior_logdensities","text":"pointwise_prior_logdensities(model, chain[, keytype])\n\nCompute the pointwise log-prior-densities of the model given the chain. This is the same as pointwise_logdensities(model, chain), but only including the prior terms.\n\nSee also: pointwise_logdensities, pointwise_loglikelihoods.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"For converting a chain into a format that can more easily be fed into a Model again, for example using condition, you can use value_iterator_from_chain.","category":"page"},{"location":"api/#DynamicPPL.value_iterator_from_chain","page":"API","title":"DynamicPPL.value_iterator_from_chain","text":"value_iterator_from_chain(model::Model, chain)\nvalue_iterator_from_chain(varinfo::AbstractVarInfo, chain)\n\nReturn an iterator over the values in chain for each variable in model/varinfo.\n\nExample\n\njulia> using MCMCChains, DynamicPPL, Distributions, StableRNGs\n\njulia> rng = StableRNG(42);\n\njulia> @model function demo_model(x)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, sqrt(s))\n           for i in eachindex(x)\n               x[i] ~ Normal(m, sqrt(s))\n           end\n\n           return s, m\n       end\ndemo_model (generic function with 2 methods)\n\njulia> model = demo_model([1.0, 2.0]);\n\njulia> chain = Chains(rand(rng, 10, 2, 3), [:s, :m]);\n\njulia> iter = value_iterator_from_chain(model, chain);\n\njulia> first(iter)\nOrderedDict{VarName, Any} with 2 entries:\n  s => 0.580515\n  m => 0.739328\n\njulia> collect(iter)\n10×3 Matrix{OrderedDict{VarName, Any}}:\n OrderedDict(s=>0.580515, m=>0.739328)  …  OrderedDict(s=>0.186047, m=>0.402423)\n OrderedDict(s=>0.191241, m=>0.627342)     OrderedDict(s=>0.776277, m=>0.166342)\n OrderedDict(s=>0.971133, m=>0.637584)     OrderedDict(s=>0.651655, m=>0.712044)\n OrderedDict(s=>0.74345, m=>0.110359)      OrderedDict(s=>0.469214, m=>0.104502)\n OrderedDict(s=>0.170969, m=>0.598514)     OrderedDict(s=>0.853546, m=>0.185399)\n OrderedDict(s=>0.704776, m=>0.322111)  …  OrderedDict(s=>0.638301, m=>0.853802)\n OrderedDict(s=>0.441044, m=>0.162285)     OrderedDict(s=>0.852959, m=>0.0956922)\n OrderedDict(s=>0.803972, m=>0.643369)     OrderedDict(s=>0.245049, m=>0.871985)\n OrderedDict(s=>0.772384, m=>0.646323)     OrderedDict(s=>0.906603, m=>0.385502)\n OrderedDict(s=>0.70882, m=>0.253105)      OrderedDict(s=>0.413222, m=>0.953288)\n\njulia> # This can be used to `condition` a `Model`.\n       conditioned_model = model | first(iter);\n\njulia> conditioned_model()  # <= results in same values as the `first(iter)` above\n(0.5805148626851955, 0.7393275279160691)\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"Sometimes it can be useful to extract the priors of a model. This is the possible using extract_priors.","category":"page"},{"location":"api/#DynamicPPL.extract_priors","page":"API","title":"DynamicPPL.extract_priors","text":"extract_priors([rng::Random.AbstractRNG, ]model::Model)\n\nExtract the priors from a model.\n\nThis is done by sampling from the model and recording the distributions that are used to generate the samples.\n\nwarning: Warning\nBecause the extraction is done by execution of the model, there are several caveats:If one variable, say, y ~ Normal(0, x), where x ~ Normal() is also a random variable, then the extracted prior will have different parameters in every extraction!\nIf the model does not have static support, say, n ~ Categorical(1:10); x ~ MvNormmal(zeros(n), I), then the extracted priors themselves will be different between extractions, not just their parameters.Both of these caveats are demonstrated below.\n\nExamples\n\nChanging parameters\n\njulia> using Distributions, StableRNGs\n\njulia> rng = StableRNG(42);\n\njulia> @model function model_dynamic_parameters()\n           x ~ Normal(0, 1)\n           y ~ Normal(x, 1)\n       end;\n\njulia> model = model_dynamic_parameters();\n\njulia> extract_priors(rng, model)[@varname(y)]\nNormal{Float64}(μ=-0.6702516921145671, σ=1.0)\n\njulia> extract_priors(rng, model)[@varname(y)]\nNormal{Float64}(μ=1.3736306979834252, σ=1.0)\n\nChanging support\n\njulia> using LinearAlgebra, Distributions, StableRNGs\n\njulia> rng = StableRNG(42);\n\njulia> @model function model_dynamic_support()\n           n ~ Categorical(ones(10) ./ 10)\n           x ~ MvNormal(zeros(n), I)\n       end;\n\njulia> model = model_dynamic_support();\n\njulia> length(extract_priors(rng, model)[@varname(x)])\n6\n\njulia> length(extract_priors(rng, model)[@varname(x)])\n9\n\n\n\n\n\nextract_priors(model::Model, varinfo::AbstractVarInfo)\n\nExtract the priors from a model.\n\nThis is done by evaluating the model at the values present in varinfo and recording the distributions that are present at each tilde statement.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"Safe extraction of values from a given AbstractVarInfo as they are seen in the model can be done using values_as_in_model.","category":"page"},{"location":"api/#DynamicPPL.values_as_in_model","page":"API","title":"DynamicPPL.values_as_in_model","text":"values_as_in_model(model::Model, include_colon_eq::Bool, varinfo::AbstractVarInfo)\n\nGet the values of varinfo as they would be seen in the model.\n\nMore specifically, this method attempts to extract the realization as seen in the model. For example, x[1] ~ truncated(Normal(); lower=0) will result in a realization that is compatible with truncated(Normal(); lower=0) – i.e. one where the value of x[1] is positive – regardless of whether varinfo is working in unconstrained space.\n\nHence this method is a \"safe\" way of obtaining realizations in constrained space at the cost of additional model evaluations.\n\nArguments\n\nmodel::Model: model to extract realizations from.\ninclude_colon_eq::Bool: whether to also include variables on the LHS of :=.\nvarinfo::AbstractVarInfo: variable information to use for the extraction.\n\nExamples\n\nWhen VarInfo fails\n\nThe following demonstrates a common pitfall when working with VarInfo and constrained variables.\n\njulia> using Distributions, StableRNGs\n\njulia> rng = StableRNG(42);\n\njulia> @model function model_changing_support()\n           x ~ Bernoulli(0.5)\n           y ~ x == 1 ? Uniform(0, 1) : Uniform(11, 12)\n       end;\n\njulia> model = model_changing_support();\n\njulia> # Construct initial type-stable `VarInfo`.\n       varinfo = VarInfo(rng, model);\n\njulia> # Link it so it works in unconstrained space.\n       varinfo_linked = DynamicPPL.link(varinfo, model);\n\njulia> # Perform computations in unconstrained space, e.g. changing the values of `θ`.\n       # Flip `x` so we hit the other support of `y`.\n       θ = [!varinfo[@varname(x)], rand(rng)];\n\njulia> # Update the `VarInfo` with the new values.\n       varinfo_linked = DynamicPPL.unflatten(varinfo_linked, θ);\n\njulia> # Determine the expected support of `y`.\n       lb, ub = θ[1] == 1 ? (0, 1) : (11, 12)\n(0, 1)\n\njulia> # Approach 1: Convert back to constrained space using `invlink` and extract.\n       varinfo_invlinked = DynamicPPL.invlink(varinfo_linked, model);\n\njulia> # (×) Fails! Because `VarInfo` _saves_ the original distributions\n       # used in the very first model evaluation, hence the support of `y`\n       # is not updated even though `x` has changed.\n       lb ≤ first(varinfo_invlinked[@varname(y)]) ≤ ub\nfalse\n\njulia> # Approach 2: Extract realizations using `values_as_in_model`.\n       # (✓) `values_as_in_model` will re-run the model and extract\n       # the correct realization of `y` given the new values of `x`.\n       lb ≤ values_as_in_model(model, true, varinfo_linked)[@varname(y)] ≤ ub\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.NamedDist","page":"API","title":"DynamicPPL.NamedDist","text":"A named distribution that carries the name of the random variable with it.\n\n\n\n\n\n","category":"type"},{"location":"api/#AD-testing-and-benchmarking-utilities","page":"API","title":"AD testing and benchmarking utilities","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"To test and/or benchmark the performance of an AD backend on a model, DynamicPPL provides the following utilities:","category":"page"},{"location":"api/#DynamicPPL.TestUtils.AD.run_ad","page":"API","title":"DynamicPPL.TestUtils.AD.run_ad","text":"run_ad(\n    model::Model,\n    adtype::ADTypes.AbstractADType;\n    test::Union{AbstractADCorrectnessTestSetting,Bool}=WithBackend(),\n    benchmark=false,\n    atol::AbstractFloat=1e-8,\n    rtol::AbstractFloat=sqrt(eps()),\n    getlogdensity::Function=getlogjoint_internal,\n    rng::Random.AbstractRNG=Random.default_rng(),\n    varinfo::AbstractVarInfo=link(VarInfo(model), model),\n    params::Union{Nothing,Vector{<:AbstractFloat}}=nothing,\n    verbose=true,\n)::ADResult\n\nDescription\n\nTest the correctness and/or benchmark the AD backend adtype for the model model.\n\nWhether to test and benchmark is controlled by the test and benchmark keyword arguments. By default, test is true and benchmark is false.\n\nNote that to run AD successfully you will need to import the AD backend itself. For example, to test with AutoReverseDiff() you will need to run import ReverseDiff.\n\nArguments\n\nThere are two positional arguments, which absolutely must be provided:\n\nmodel - The model being tested.\nadtype - The AD backend being tested.\n\nEverything else is optional, and can be categorised into several groups:\n\nHow to specify the VarInfo.\nDynamicPPL contains several different types of VarInfo objects which change the way model evaluation occurs. If you want to use a specific type of VarInfo, pass it as the varinfo argument. Otherwise, it will default to using a linked TypedVarInfo generated from the model. Here, linked means that the parameters in the VarInfo have been transformed to unconstrained Euclidean space if they aren't already in that space.\nHow to specify the parameters.\nFor maximum control over this, generate a vector of parameters yourself and pass this as the params argument. If you don't specify this, it will be taken from the contents of the VarInfo.\nNote that if the VarInfo is not specified (and thus automatically generated) the parameters in it will have been sampled from the prior of the model. If you want to seed the parameter generation for the VarInfo, you can pass the rng keyword argument, which will then be used to create the VarInfo.\nFinally, note that these only reflect the parameters used for evaluating the gradient. If you also want to control the parameters used for preparing the gradient, then you need to manually set these parameters in the VarInfo object, for example using vi = DynamicPPL.unflatten(vi, prep_params). You could then evaluate the gradient at a different set of parameters using the params keyword argument.\nWhich type of logp is being calculated.\nBy default, run_ad evaluates the 'internal log joint density' of the model, i.e., the log joint density in the unconstrained space. Thus, for example, in\n@model f() = x ~ LogNormal()\nthe internal log joint density is logpdf(Normal(), log(x)). This is the relevant log density for e.g. Hamiltonian Monte Carlo samplers and is therefore the most useful to test.\nIf you want the log joint density in the original model parameterisation, you can use getlogjoint. Likewise, if you want only the prior or likelihood, you can use getlogprior or getloglikelihood, respectively.\nHow to specify the results to compare against.\nOnce logp and its gradient has been calculated with the specified adtype, it can optionally be tested for correctness. The exact way this is tested  is specified in the test parameter.\nThere are several options for this:\nYou can explicitly specify the correct value using WithExpectedResult().\nYou can compare against the result obtained with a different AD backend using WithBackend(adtype).\nYou can disable testing by passing NoTest().\nThe default is to compare against the result obtained with ForwardDiff, i.e. WithBackend(AutoForwardDiff()).\ntest=false and test=true are synonyms for NoTest() and WithBackend(AutoForwardDiff()), respectively.\nHow to specify the tolerances. (Only if testing is enabled.)\nBoth absolute and relative tolerances can be specified using the atol and rtol keyword arguments respectively. The behaviour of these is similar to isapprox(), i.e. the value and gradient are considered correct if either atol or rtol is satisfied. The default values are 100*eps() for atol and sqrt(eps()) for rtol.\nFor the most part, it is the rtol check that is more meaningful, because we cannot know the magnitude of logp and its gradient a priori. The atol value is supplied to handle the case where gradients are equal to zero.\nWhether to output extra logging information.\nBy default, this function prints messages when it runs. To silence it, set verbose=false.\n\nReturns / Throws\n\nReturns an ADResult object, which contains the results of the test and/or benchmark.\n\nIf test is true and the AD backend returns an incorrect value or gradient, an ADIncorrectException is thrown. If a different error occurs, it will be thrown as-is.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"The default test setting is to compare against ForwardDiff. You can have more fine-grained control over how to test the AD backend using the following types:","category":"page"},{"location":"api/#DynamicPPL.TestUtils.AD.AbstractADCorrectnessTestSetting","page":"API","title":"DynamicPPL.TestUtils.AD.AbstractADCorrectnessTestSetting","text":"AbstractADCorrectnessTestSetting\n\nDifferent ways of testing the correctness of an AD backend.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.AD.WithBackend","page":"API","title":"DynamicPPL.TestUtils.AD.WithBackend","text":"WithBackend(adtype::AbstractADType=AutoForwardDiff()) <: AbstractADCorrectnessTestSetting\n\nTest correctness by comparing it against the result obtained with adtype.\n\nadtype defaults to ForwardDiff.jl, since it's the default AD backend used in Turing.jl.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.AD.WithExpectedResult","page":"API","title":"DynamicPPL.TestUtils.AD.WithExpectedResult","text":"WithExpectedResult(\n    value::T,\n    grad::AbstractVector{T}\n) where {T <: AbstractFloat}\n<: AbstractADCorrectnessTestSetting\n\nTest correctness by comparing it against a known result (e.g. one obtained analytically, or one obtained with a different backend previously). Both the value of the primal (i.e. the log-density) as well as its gradient must be supplied.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.AD.NoTest","page":"API","title":"DynamicPPL.TestUtils.AD.NoTest","text":"NoTest() <: AbstractADCorrectnessTestSetting\n\nDisable correctness testing.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"These are returned / thrown by the run_ad function:","category":"page"},{"location":"api/#DynamicPPL.TestUtils.AD.ADResult","page":"API","title":"DynamicPPL.TestUtils.AD.ADResult","text":"ADResult{Tparams<:AbstractFloat,Tresult<:AbstractFloat,Ttol<:AbstractFloat}\n\nData structure to store the results of the AD correctness test.\n\nThe type parameter Tparams is the numeric type of the parameters passed in; Tresult is the type of the value and the gradient; and Ttol is the type of the absolute and relative tolerances used for correctness testing.\n\nFields\n\nmodel::Model: The DynamicPPL model that was tested\ngetlogdensity::Function: The function used to extract the log density from the model\nvarinfo::AbstractVarInfo: The VarInfo that was used\nparams::Vector{Tparams} where Tparams<:AbstractFloat: The values at which the model was evaluated\nadtype::ADTypes.AbstractADType: The AD backend that was tested\natol::AbstractFloat: Absolute tolerance used for correctness test\nrtol::AbstractFloat: Relative tolerance used for correctness test\nvalue_expected::Union{Nothing, Tresult} where Tresult<:AbstractFloat: The expected value of logp\ngrad_expected::Union{Nothing, Vector{Tresult}} where Tresult<:AbstractFloat: The expected gradient of logp\nvalue_actual::AbstractFloat: The value of logp (calculated using adtype)\ngrad_actual::Vector{Tresult} where Tresult<:AbstractFloat: The gradient of logp (calculated using adtype)\ngrad_time::Union{Nothing, Tresult} where Tresult<:AbstractFloat: If benchmarking was requested, the time taken by the AD backend to evaluate the gradient      of logp\nprimal_time::Union{Nothing, Tresult} where Tresult<:AbstractFloat: If benchmarking was requested, the time taken by the AD backend to evaluate logp\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.AD.ADIncorrectException","page":"API","title":"DynamicPPL.TestUtils.AD.ADIncorrectException","text":"ADIncorrectException{T<:AbstractFloat}\n\nException thrown when an AD backend returns an incorrect value or gradient.\n\nThe type parameter T is the numeric type of the value and gradient.\n\nFields\n\nvalue_expected::AbstractFloat\nvalue_actual::AbstractFloat\ngrad_expected::Vector{T} where T<:AbstractFloat\ngrad_actual::Vector{T} where T<:AbstractFloat\n\n\n\n\n\n","category":"type"},{"location":"api/#Demo-models","page":"API","title":"Demo models","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"DynamicPPL provides several demo models and helpers for testing samplers in the DynamicPPL.TestUtils submodule.","category":"page"},{"location":"api/#DynamicPPL.TestUtils.test_sampler","page":"API","title":"DynamicPPL.TestUtils.test_sampler","text":"test_sampler(models, sampler, args...; kwargs...)\n\nTest that sampler produces correct marginal posterior means on each model in models.\n\nIn short, this method iterates through models, calls AbstractMCMC.sample on the model and sampler to produce a chain, and then checks marginal_mean_of_samples(chain, vn) for every (leaf) varname vn against the corresponding value returned by posterior_mean for each model.\n\nTo change how comparison is done for a particular chain type, one can overload marginal_mean_of_samples for the corresponding type.\n\nArguments\n\nmodels: A collection of instaces of DynamicPPL.Model to test on.\nsampler: The AbstractMCMC.AbstractSampler to test.\nargs...: Arguments forwarded to sample.\n\nKeyword arguments\n\nvarnames_filter: A filter to apply to varnames(model), allowing comparison for only   a subset of the varnames.\natol=1e-1: Absolute tolerance used in @test.\nrtol=1e-3: Relative tolerance used in @test.\nkwargs...: Keyword arguments forwarded to sample.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.test_sampler_on_demo_models","page":"API","title":"DynamicPPL.TestUtils.test_sampler_on_demo_models","text":"test_sampler_on_demo_models(meanfunction, sampler, args...; kwargs...)\n\nTest sampler on every model in DEMO_MODELS.\n\nThis is just a proxy for test_sampler(meanfunction, DEMO_MODELS, sampler, args...; kwargs...).\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.test_sampler_continuous","page":"API","title":"DynamicPPL.TestUtils.test_sampler_continuous","text":"test_sampler_continuous(sampler, args...; kwargs...)\n\nTest that sampler produces the correct marginal posterior means on all models in demo_models.\n\nAs of right now, this is just an alias for test_sampler_on_demo_models.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.marginal_mean_of_samples","page":"API","title":"DynamicPPL.TestUtils.marginal_mean_of_samples","text":"marginal_mean_of_samples(chain, varname)\n\nReturn the mean of variable represented by varname in chain.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.DEMO_MODELS","page":"API","title":"DynamicPPL.TestUtils.DEMO_MODELS","text":"A collection of models corresponding to the posterior distribution defined by the generative process\n\ns ~ InverseGamma(2, 3)\nm ~ Normal(0, √s)\n1.5 ~ Normal(m, √s)\n2.0 ~ Normal(m, √s)\n\nor by\n\ns[1] ~ InverseGamma(2, 3)\ns[2] ~ InverseGamma(2, 3)\nm[1] ~ Normal(0, √s)\nm[2] ~ Normal(0, √s)\n1.5 ~ Normal(m[1], √s[1])\n2.0 ~ Normal(m[2], √s[2])\n\nThese are examples of a Normal-InverseGamma conjugate prior with Normal likelihood, for which the posterior is known in closed form.\n\nIn particular, for the univariate model (the former one):\n\nmean(s) == 49 / 24\nmean(m) == 7 / 6\n\nAnd for the multivariate one (the latter one):\n\nmean(s[1]) == 19 / 8\nmean(m[1]) == 3 / 4\nmean(s[2]) == 8 / 3\nmean(m[2]) == 1\n\n\n\n\n\n","category":"constant"},{"location":"api/","page":"API","title":"API","text":"For every demo model, one can define the true log prior, log likelihood, and log joint probabilities.","category":"page"},{"location":"api/#DynamicPPL.TestUtils.logprior_true","page":"API","title":"DynamicPPL.TestUtils.logprior_true","text":"logprior_true(model, args...)\n\nReturn the logprior of model for args.\n\nThis should generally be implemented by hand for every specific model.\n\nSee also: logjoint_true, loglikelihood_true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.loglikelihood_true","page":"API","title":"DynamicPPL.TestUtils.loglikelihood_true","text":"loglikelihood_true(model, args...)\n\nReturn the loglikelihood of model for args.\n\nThis should generally be implemented by hand for every specific model.\n\nSee also: logjoint_true, logprior_true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.logjoint_true","page":"API","title":"DynamicPPL.TestUtils.logjoint_true","text":"logjoint_true(model, args...)\n\nReturn the logjoint of model for args.\n\nDefaults to logprior_true(model, args...) + loglikelihood_true(model, args..).\n\nThis should generally be implemented by hand for every specific model so that the returned value can be used as a ground-truth for testing things like:\n\nValidity of evaluation of model using a particular implementation of AbstractVarInfo.\nValidity of a sampler when combined with DynamicPPL by running the sampler twice: once targeting ground-truth functions, e.g. logjoint_true, and once targeting model.\n\nAnd more.\n\nSee also: logprior_true, loglikelihood_true.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"And in the case where the model includes constrained variables, it can also be useful to define","category":"page"},{"location":"api/#DynamicPPL.TestUtils.logprior_true_with_logabsdet_jacobian","page":"API","title":"DynamicPPL.TestUtils.logprior_true_with_logabsdet_jacobian","text":"logprior_true_with_logabsdet_jacobian(model::Model, args...)\n\nReturn a tuple (args_unconstrained, logprior_unconstrained) of model for args....\n\nUnlike logprior_true, the returned logprior computation includes the log-absdet-jacobian adjustment, thus computing logprior for the unconstrained variables.\n\nNote that args are assumed be in the support of model, while args_unconstrained will be unconstrained.\n\nSee also: logprior_true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.logjoint_true_with_logabsdet_jacobian","page":"API","title":"DynamicPPL.TestUtils.logjoint_true_with_logabsdet_jacobian","text":"logjoint_true_with_logabsdet_jacobian(model::Model, args...)\n\nReturn a tuple (args_unconstrained, logjoint) of model for args.\n\nUnlike logjoint_true, the returned logjoint computation includes the log-absdet-jacobian adjustment, thus computing logjoint for the unconstrained variables.\n\nNote that args are assumed be in the support of model, while args_unconstrained will be unconstrained.\n\nThis should generally not be implemented directly, instead one should implement logprior_true_with_logabsdet_jacobian for a given model.\n\nSee also: logjoint_true, logprior_true_with_logabsdet_jacobian.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"Finally, the following methods can also be of use:","category":"page"},{"location":"api/#DynamicPPL.TestUtils.varnames","page":"API","title":"DynamicPPL.TestUtils.varnames","text":"varnames(model::Model)\n\nReturn a collection of VarName as they are expected to appear in the model.\n\nEven though it is recommended to implement this by hand for a particular Model, a default implementation using SimpleVarInfo{<:Dict} is provided.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.posterior_mean","page":"API","title":"DynamicPPL.TestUtils.posterior_mean","text":"posterior_mean(model::Model)\n\nReturn a NamedTuple compatible with varnames(model) where the values represent the posterior mean under model.\n\n\"Compatible\" means that a varname from varnames(model) can be used to extract the corresponding value using get, e.g. get(posterior_mean(model), varname).\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.setup_varinfos","page":"API","title":"DynamicPPL.TestUtils.setup_varinfos","text":"setup_varinfos(model::Model, example_values::NamedTuple, varnames; include_threadsafe::Bool=false)\n\nReturn a tuple of instances for different implementations of AbstractVarInfo with each vi, supposedly, satisfying vi[vn] == get(example_values, vn) for vn in varnames.\n\nIf include_threadsafe is true, then the returned tuple will also include thread-safe versions of the varinfo instances.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.update_values!!","page":"API","title":"DynamicPPL.update_values!!","text":"update_values!!(vi::AbstractVarInfo, vals::NamedTuple, vns)\n\nReturn instance similar to vi but with vns set to values from vals.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.test_values","page":"API","title":"DynamicPPL.TestUtils.test_values","text":"test_values(vi::AbstractVarInfo, vals::NamedTuple, vns)\n\nTest that vi[vn] corresponds to the correct value in vals for every vn in vns.\n\n\n\n\n\n","category":"function"},{"location":"api/#Debugging-Utilities","page":"API","title":"Debugging Utilities","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"DynamicPPL provides a few methods for checking validity of a model-definition.","category":"page"},{"location":"api/#DynamicPPL.DebugUtils.check_model","page":"API","title":"DynamicPPL.DebugUtils.check_model","text":"check_model(model::Model, varinfo::AbstractVarInfo; error_on_failure=false)\n\nCheck that model is valid, warning about any potential issues (or erroring if error_on_failure is true).\n\nReturns\n\nissuccess::Bool: Whether the model check succeeded.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.DebugUtils.check_model_and_trace","page":"API","title":"DynamicPPL.DebugUtils.check_model_and_trace","text":"check_model_and_trace(model::Model, varinfo::AbstractVarInfo; error_on_failure=false)\n\nCheck that evaluating model with the given varinfo is valid, warning about any potential issues.\n\nThis will check the model for the following issues:\n\nRepeated usage of the same varname in a model.\nNaN on the left-hand side of observe statements.\n\nArguments\n\nmodel::Model: The model to check.\nvarinfo::AbstractVarInfo: The varinfo to use when evaluating the model.\n\nKeyword Argument\n\nerror_on_failure::Bool: Whether to throw an error if the model check fails. Default: false.\n\nReturns\n\nissuccess::Bool: Whether the model check succeeded.\ntrace::Vector{Stmt}: The trace of statements executed during the model check.\n\nExamples\n\nCorrect model\n\njulia> using StableRNGs\n\njulia> rng = StableRNG(42);\n\njulia> @model demo_correct() = x ~ Normal()\ndemo_correct (generic function with 2 methods)\n\njulia> model = demo_correct(); varinfo = VarInfo(rng, model);\n\njulia> issuccess, trace = check_model_and_trace(model, varinfo);\n\njulia> issuccess\ntrue\n\njulia> print(trace)\n assume: x ~ Normal{Float64}(μ=0.0, σ=1.0) ⟼ -0.670252\n\njulia> cond_model = model | (x = 1.0,);\n\njulia> issuccess, trace = check_model_and_trace(cond_model, VarInfo(cond_model));\n┌ Warning: The model does not contain any parameters.\n└ @ DynamicPPL.DebugUtils DynamicPPL.jl/src/debug_utils.jl:342\n\njulia> issuccess\ntrue\n\njulia> print(trace)\n observe: x (= 1.0) ~ Normal{Float64}(μ=0.0, σ=1.0)\n\nIncorrect model\n\njulia> @model function demo_incorrect()\n           # (×) Sampling `x` twice will lead to incorrect log-probabilities!\n           x ~ Normal()\n           x ~ Exponential()\n       end\ndemo_incorrect (generic function with 2 methods)\n\njulia> # Notice that VarInfo(model_incorrect) evaluates the model, but doesn't actually \n       # alert us to the issue of `x` being sampled twice.\n       model = demo_incorrect(); varinfo = VarInfo(model);\n\njulia> issuccess, trace = check_model_and_trace(model, varinfo; error_on_failure=true);\nERROR: varname x used multiple times in model\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"And some which might be useful to determine certain properties of the model based on the debug trace.","category":"page"},{"location":"api/#DynamicPPL.DebugUtils.has_static_constraints","page":"API","title":"DynamicPPL.DebugUtils.has_static_constraints","text":"has_static_constraints([rng, ]model::Model; num_evals=5, error_on_failure=false)\n\nReturn true if the model has static constraints, false otherwise.\n\nNote that this is a heuristic check based on sampling from the model multiple times and checking if the model is consistent across runs.\n\nArguments\n\nrng::Random.AbstractRNG: The random number generator to use when evaluating the model.\nmodel::Model: The model to check.\n\nKeyword Arguments\n\nnum_evals::Int: The number of evaluations to perform. Default: 5.\nerror_on_failure::Bool: Whether to throw an error if any of the num_evals model checks fail. Default: false.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"For determining whether one might have type instabilities in the model, the following can be useful","category":"page"},{"location":"api/#DynamicPPL.DebugUtils.model_warntype","page":"API","title":"DynamicPPL.DebugUtils.model_warntype","text":"model_warntype(model[, varinfo]; optimize=true)\n\nCheck the type stability of the model's evaluator, warning about any potential issues.\n\nThis simply calls @code_warntype on the model's evaluator, filling in internal arguments where needed.\n\nArguments\n\nmodel::Model: The model to check.\nvarinfo::AbstractVarInfo: The varinfo to use when evaluating the model. Default: VarInfo(model).\n\nKeyword Arguments\n\noptimize::Bool: Whether to generate optimized code. Default: false.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.DebugUtils.model_typed","page":"API","title":"DynamicPPL.DebugUtils.model_typed","text":"model_typed(model[, varinfo]; optimize=true)\n\nReturn the type inference for the model's evaluator.\n\nThis simply calls @code_typed on the model's evaluator, filling in internal arguments where needed.\n\nArguments\n\nmodel::Model: The model to check.\nvarinfo::AbstractVarInfo: The varinfo to use when evaluating the model. Default: VarInfo(model).\n\nKeyword Arguments\n\noptimize::Bool: Whether to generate optimized code. Default: true.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"Interally, the type-checking methods make use of the following method for construction of the call with the argument types:","category":"page"},{"location":"api/#DynamicPPL.DebugUtils.gen_evaluator_call_with_types","page":"API","title":"DynamicPPL.DebugUtils.gen_evaluator_call_with_types","text":"gen_evaluator_call_with_types(model[, varinfo])\n\nGenerate the evaluator call and the types of the arguments.\n\nArguments\n\nmodel::Model: The model whose evaluator is of interest.\nvarinfo::AbstractVarInfo: The varinfo to use when evaluating the model. Default: VarInfo(model).\n\nReturns\n\nA 2-tuple with the following elements:\n\nf: This is either model.f or Core.kwcall, depending on whether   the model has keyword arguments.\nargtypes::Type{<:Tuple}: The types of the arguments for the evaluator.\n\n\n\n\n\n","category":"function"},{"location":"api/#Advanced","page":"API","title":"Advanced","text":"","category":"section"},{"location":"api/#Variable-names","page":"API","title":"Variable names","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Names and possibly nested indices of variables are described with AbstractPPL.VarName. They can be defined with AbstractPPL.@varname. Please see the documentation of AbstractPPL.jl for further information.","category":"page"},{"location":"api/#Data-Structures-of-Variables","page":"API","title":"Data Structures of Variables","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"DynamicPPL provides different data structures used in for storing samples and accumulation of the log-probabilities, all of which are subtypes of AbstractVarInfo.","category":"page"},{"location":"api/#DynamicPPL.AbstractVarInfo","page":"API","title":"DynamicPPL.AbstractVarInfo","text":"AbstractVarInfo\n\nAbstract supertype for data structures that capture random variables when executing a probabilistic model and accumulate log densities such as the log likelihood or the log joint probability of the model.\n\nSee also: VarInfo, SimpleVarInfo.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"But exactly how a AbstractVarInfo stores this information can vary.","category":"page"},{"location":"api/#VarInfo","page":"API","title":"VarInfo","text":"","category":"section"},{"location":"api/#DynamicPPL.VarInfo","page":"API","title":"DynamicPPL.VarInfo","text":"struct VarInfo{Tmeta,Accs<:AccumulatorTuple} <: AbstractVarInfo\n    metadata::Tmeta\n    accs::Accs\nend\n\nA light wrapper over some kind of metadata.\n\nThe type of the metadata can be one of a number of options. It may either be a Metadata or a VarNamedVector, or, it may be a NamedTuple which maps symbols to Metadata or VarNamedVector instances. Here, a symbol refers to a Julia variable and may consist of one or more VarNames which appear on the left-hand side of tilde statements. For example, x[1] and x[2] both have the same symbol x.\n\nSeveral type aliases are provided for these forms of VarInfos:\n\nVarInfo{<:Metadata} is UntypedVarInfo\nVarInfo{<:VarNamedVector} is UntypedVectorVarInfo\nVarInfo{<:NamedTuple} is NTVarInfo\n\nThe NamedTuple form, i.e. NTVarInfo, is useful for maintaining type stability of model evaluation. However, the element type of NamedTuples are not contained in its type itself: thus, there is no way to use the type system to determine whether the elements of the NamedTuple are Metadata or VarNamedVector.\n\nNote that for NTVarInfo, it is the user's responsibility to ensure that each symbol is visited at least once during model evaluation, regardless of any stochastic branching.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.untyped_varinfo","page":"API","title":"DynamicPPL.untyped_varinfo","text":"untyped_varinfo([rng, ]model[, sampler])\n\nConstruct a VarInfo object for the given model, which has just a single Metadata as its metadata field.\n\nArguments\n\nrng::Random.AbstractRNG: The random number generator to use during model evaluation\nmodel::Model: The model for which to create the varinfo object\nsampler::AbstractSampler: The sampler to use for the model. Defaults to SampleFromPrior().\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.typed_varinfo","page":"API","title":"DynamicPPL.typed_varinfo","text":"typed_varinfo(vi::UntypedVarInfo)\n\nThis function finds all the unique syms from the instances of VarName{sym} found in vi.metadata.vns. It then extracts the metadata associated with each symbol from the global vi.metadata field. Finally, a new VarInfo is created with a new metadata as a NamedTuple mapping from symbols to type-stable Metadata instances, one for each symbol.\n\n\n\n\n\ntyped_varinfo([rng, ]model[, sampler])\n\nReturn a VarInfo object for the given model, which has a NamedTuple of Metadata structs as its metadata field.\n\nArguments\n\nrng::Random.AbstractRNG: The random number generator to use during model evaluation\nmodel::Model: The model for which to create the varinfo object\nsampler::AbstractSampler: The sampler to use for the model. Defaults to SampleFromPrior().\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.untyped_vector_varinfo","page":"API","title":"DynamicPPL.untyped_vector_varinfo","text":"untyped_vector_varinfo([rng, ]model[, sampler])\n\nReturn a VarInfo object for the given model, which has just a single VarNamedVector as its metadata field.\n\nArguments\n\nrng::Random.AbstractRNG: The random number generator to use during model evaluation\nmodel::Model: The model for which to create the varinfo object\nsampler::AbstractSampler: The sampler to use for the model. Defaults to SampleFromPrior().\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.typed_vector_varinfo","page":"API","title":"DynamicPPL.typed_vector_varinfo","text":"typed_vector_varinfo([rng, ]model[, sampler])\n\nReturn a VarInfo object for the given model, which has a NamedTuple of VarNamedVectors as its metadata field.\n\nArguments\n\nrng::Random.AbstractRNG: The random number generator to use during model evaluation\nmodel::Model: The model for which to create the varinfo object\nsampler::AbstractSampler: The sampler to use for the model. Defaults to SampleFromPrior().\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"One main characteristic of VarInfo is that samples are transformed to unconstrained Euclidean space and stored in a linearized form, as described in the main Turing documentation. The Transformations section below describes the methods used for this. In the specific case of VarInfo, it keeps track of whether samples have been transformed by setting flags on them, using the following functions.","category":"page"},{"location":"api/#DynamicPPL.set_flag!","page":"API","title":"DynamicPPL.set_flag!","text":"set_flag!(vi::VarInfo, vn::VarName, flag::String)\n\nSet vn's value for flag to true in vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.unset_flag!","page":"API","title":"DynamicPPL.unset_flag!","text":"unset_flag!(vi::VarInfo, vn::VarName, flag::String, ignorable::Bool=false\n\nSet vn's value for flag to false in vi.\n\nSetting some flags for some VarInfo types is not possible, and by default attempting to do so will error. If ignorable is set to true then this will silently be ignored instead.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.is_flagged","page":"API","title":"DynamicPPL.is_flagged","text":"is_flagged(vi::VarInfo, vn::VarName, flag::String)\n\nCheck whether vn has a true value for flag in vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.empty!","page":"API","title":"Base.empty!","text":"empty!(meta::Metadata)\n\nEmpty the fields of meta.\n\nThis is useful when using a sampling algorithm that assumes an empty meta, e.g. SMC.\n\n\n\n\n\n","category":"function"},{"location":"api/#SimpleVarInfo","page":"API","title":"SimpleVarInfo","text":"","category":"section"},{"location":"api/#DynamicPPL.SimpleVarInfo","page":"API","title":"DynamicPPL.SimpleVarInfo","text":"struct SimpleVarInfo{NT, Accs<:DynamicPPL.AccumulatorTuple, C<:DynamicPPL.AbstractTransformation} <: AbstractVarInfo\n\nA simple wrapper of the parameters with a logp field for accumulation of the logdensity.\n\nCurrently only implemented for NT<:NamedTuple and NT<:AbstractDict.\n\nFields\n\nvalues: underlying representation of the realization represented\naccs: tuple of accumulators for things like log prior and log likelihood\ntransformation: represents whether it assumes variables to be transformed\n\nNotes\n\nThe major differences between this and NTVarInfo are:\n\nSimpleVarInfo does not require linearization.\nSimpleVarInfo can use more efficient bijectors.\nSimpleVarInfo is only type-stable if NT<:NamedTuple and either a) no indexing is used in tilde-statements, or b) the values have been specified with the correct shapes.\n\nExamples\n\nGeneral usage\n\njulia> using StableRNGs\n\njulia> @model function demo()\n           m ~ Normal()\n           x = Vector{Float64}(undef, 2)\n           for i in eachindex(x)\n               x[i] ~ Normal()\n           end\n           return x\n       end\ndemo (generic function with 2 methods)\n\njulia> m = demo();\n\njulia> rng = StableRNG(42);\n\njulia> # In the `NamedTuple` version we need to provide the place-holder values for\n       # the variables which are using \"containers\", e.g. `Array`.\n       # In this case, this means that we need to specify `x` but not `m`.\n       _, vi = DynamicPPL.evaluate_and_sample!!(rng, m, SimpleVarInfo((x = ones(2), )));\n\njulia> # (✓) Vroom, vroom! FAST!!!\n       vi[@varname(x[1])]\n0.4471218424633827\n\njulia> # We can also access arbitrary varnames pointing to `x`, e.g.\n       vi[@varname(x)]\n2-element Vector{Float64}:\n 0.4471218424633827\n 1.3736306979834252\n\njulia> vi[@varname(x[1:2])]\n2-element Vector{Float64}:\n 0.4471218424633827\n 1.3736306979834252\n\njulia> # (×) If we don't provide the container...\n       _, vi = DynamicPPL.evaluate_and_sample!!(rng, m, SimpleVarInfo()); vi\nERROR: type NamedTuple has no field x\n[...]\n\njulia> # If one does not know the varnames, we can use a `OrderedDict` instead.\n       _, vi = DynamicPPL.evaluate_and_sample!!(rng, m, SimpleVarInfo{Float64}(OrderedDict{VarName,Any}()));\n\njulia> # (✓) Sort of fast, but only possible at runtime.\n       vi[@varname(x[1])]\n-1.019202452456547\n\njulia> # In addtion, we can only access varnames as they appear in the model!\n       vi[@varname(x)]\nERROR: x was not found in the dictionary provided\n[...]\n\njulia> vi[@varname(x[1:2])]\nERROR: x[1:2] was not found in the dictionary provided\n[...]\n\nTechnically, it's possible to use any implementation of AbstractDict in place of OrderedDict, but OrderedDict ensures that certain operations, e.g. linearization/flattening of the values in the varinfo, are consistent between evaluations. Hence OrderedDict is the preferred implementation of AbstractDict to use here.\n\nYou can also sample in transformed space:\n\njulia> @model demo_constrained() = x ~ Exponential()\ndemo_constrained (generic function with 2 methods)\n\njulia> m = demo_constrained();\n\njulia> _, vi = DynamicPPL.evaluate_and_sample!!(rng, m, SimpleVarInfo());\n\njulia> vi[@varname(x)] # (✓) 0 ≤ x < ∞\n1.8632965762164932\n\njulia> _, vi = DynamicPPL.evaluate_and_sample!!(rng, m, DynamicPPL.settrans!!(SimpleVarInfo(), true));\n\njulia> vi[@varname(x)] # (✓) -∞ < x < ∞\n-0.21080155351918753\n\njulia> xs = [last(DynamicPPL.evaluate_and_sample!!(rng, m, DynamicPPL.settrans!!(SimpleVarInfo(), true)))[@varname(x)] for i = 1:10];\n\njulia> any(xs .< 0)  # (✓) Positive probability mass on negative numbers!\ntrue\n\njulia> # And with `OrderedDict` of course!\n       _, vi = DynamicPPL.evaluate_and_sample!!(rng, m, DynamicPPL.settrans!!(SimpleVarInfo(OrderedDict{VarName,Any}()), true));\n\njulia> vi[@varname(x)] # (✓) -∞ < x < ∞\n0.6225185067787314\n\njulia> xs = [last(DynamicPPL.evaluate_and_sample!!(rng, m, DynamicPPL.settrans!!(SimpleVarInfo(), true)))[@varname(x)] for i = 1:10];\n\njulia> any(xs .< 0) # (✓) Positive probability mass on negative numbers!\ntrue\n\nEvaluation in transformed space of course also works:\n\njulia> vi = DynamicPPL.settrans!!(SimpleVarInfo((x = -1.0,)), true)\nTransformed SimpleVarInfo((x = -1.0,), (LogPrior = LogPriorAccumulator(0.0), LogJacobian = LogJacobianAccumulator(0.0), LogLikelihood = LogLikelihoodAccumulator(0.0)))\n\njulia> # (✓) Positive probability mass on negative numbers!\n       getlogjoint_internal(last(DynamicPPL.evaluate!!(m, vi)))\n-1.3678794411714423\n\njulia> # While if we forget to indicate that it's transformed:\n       vi = DynamicPPL.settrans!!(SimpleVarInfo((x = -1.0,)), false)\nSimpleVarInfo((x = -1.0,), (LogPrior = LogPriorAccumulator(0.0), LogJacobian = LogJacobianAccumulator(0.0), LogLikelihood = LogLikelihoodAccumulator(0.0)))\n\njulia> # (✓) No probability mass on negative numbers!\n       getlogjoint_internal(last(DynamicPPL.evaluate!!(m, vi)))\n-Inf\n\nIndexing\n\nUsing NamedTuple as underlying storage.\n\njulia> svi_nt = SimpleVarInfo((m = (a = [1.0], ), ));\n\njulia> svi_nt[@varname(m)]\n(a = [1.0],)\n\njulia> svi_nt[@varname(m.a)]\n1-element Vector{Float64}:\n 1.0\n\njulia> svi_nt[@varname(m.a[1])]\n1.0\n\njulia> svi_nt[@varname(m.a[2])]\nERROR: BoundsError: attempt to access 1-element Vector{Float64} at index [2]\n[...]\n\njulia> svi_nt[@varname(m.b)]\nERROR: type NamedTuple has no field b\n[...]\n\nUsing OrderedDict as underlying storage.\n\njulia> svi_dict = SimpleVarInfo(OrderedDict(@varname(m) => (a = [1.0], )));\n\njulia> svi_dict[@varname(m)]\n(a = [1.0],)\n\njulia> svi_dict[@varname(m.a)]\n1-element Vector{Float64}:\n 1.0\n\njulia> svi_dict[@varname(m.a[1])]\n1.0\n\njulia> svi_dict[@varname(m.a[2])]\nERROR: m.a[2] was not found in the dictionary provided\n[...]\n\njulia> svi_dict[@varname(m.b)]\nERROR: m.b was not found in the dictionary provided\n[...]\n\n\n\n\n\n","category":"type"},{"location":"api/#Accumulators","page":"API","title":"Accumulators","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The subtypes of AbstractVarInfo store the cumulative log prior and log likelihood, and sometimes other variables that change during executing, in what are called accumulators.","category":"page"},{"location":"api/#DynamicPPL.AbstractAccumulator","page":"API","title":"DynamicPPL.AbstractAccumulator","text":"AbstractAccumulator\n\nAn abstract type for accumulators.\n\nAn accumulator is an object that may change its value at every tildeassume!! or tildeobserve!! call based on the random variable in question. The obvious examples of accumulators are the log prior and log likelihood. Other examples might be a variable that counts the number of observations in a trace, or a list of the names of random variables seen so far.\n\nAn accumulator type T <: AbstractAccumulator must implement the following methods:\n\naccumulator_name(acc::T) or accumulator_name(::Type{T})\naccumulate_observe!!(acc::T, dist, val, vn)\naccumulate_assume!!(acc::T, val, logjac, vn, dist)\nreset(acc::T)\nBase.copy(acc::T)\n\nIn these functions:\n\nval is the new value of the random variable sampled from a distribution (always in the original unlinked space), or the value on the left-hand side of an observe statement.\ndist is the distribution on the RHS of the tilde statement.\nvn is the VarName that is on the left-hand side of the tilde-statement. If the tilde-statement is a literal observation like 0.0 ~ Normal(), then vn is nothing.\nlogjac is the log determinant of the Jacobian of the link transformation, if the variable is stored as a linked value in the VarInfo. If the variable is stored in its original, unlinked form, then logjac is zero.\n\nTo be able to work with multi-threading, it should also implement:\n\nsplit(acc::T)\ncombine(acc::T, acc2::T)\n\nSee the documentation for each of these functions for more details.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"DynamicPPL provides the following default accumulators.","category":"page"},{"location":"api/#DynamicPPL.LogPriorAccumulator","page":"API","title":"DynamicPPL.LogPriorAccumulator","text":"LogPriorAccumulator{T<:Real} <: LogProbAccumulator{T}\n\nAn accumulator that tracks the cumulative log prior during model execution.\n\nNote that the log prior stored in here is always calculated based on unlinked parameters, i.e., the value of logp is independent of whether tha VarInfo is linked or not.\n\nFields\n\nlogp::Real: the scalar log prior value\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.LogJacobianAccumulator","page":"API","title":"DynamicPPL.LogJacobianAccumulator","text":"LogJacobianAccumulator{T<:Real} <: LogProbAccumulator{T}\n\nAn accumulator that tracks the cumulative log Jacobian (technically, log(abs(det(J)))) during model execution. Specifically, J refers to the Jacobian of the link transform, i.e., from the space of the original distribution to unconstrained space.\n\nnote: Note\nThis accumulator is only incremented if the variable is transformed by a link function, i.e., if the VarInfo is linked (for the particular variable that is currently being accumulated). If the variable is not linked, the log Jacobian term will be 0.In general, for the forward Jacobian mathbfJ corresponding to the function mathbfy = f(mathbfx),log(q(mathbfy)) = log(p(mathbfx)) - log (mathbfJ)and correspondingly:getlogjoint_internal(vi) = getlogjoint(vi) - getlogjac(vi)\n\nFields\n\nlogjac::Real: the logabsdet of the link transform Jacobian\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.LogLikelihoodAccumulator","page":"API","title":"DynamicPPL.LogLikelihoodAccumulator","text":"LogLikelihoodAccumulator{T<:Real} <: LogProbAccumulator{T}\n\nAn accumulator that tracks the cumulative log likelihood during model execution.\n\nFields\n\nlogp::Real: the scalar log likelihood value\n\n\n\n\n\n","category":"type"},{"location":"api/#Common-API","page":"API","title":"Common API","text":"","category":"section"},{"location":"api/#Accumulation-of-log-probabilities","page":"API","title":"Accumulation of log-probabilities","text":"","category":"section"},{"location":"api/#DynamicPPL.getlogp","page":"API","title":"DynamicPPL.getlogp","text":"getlogp(vi::AbstractVarInfo)\n\nReturn a NamedTuple of the log prior, log Jacobian, and log likelihood probabilities.\n\nThe keys are called logprior, logjac, and loglikelihood. If any of them are not present in vi an error will be thrown.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setlogp!!","page":"API","title":"DynamicPPL.setlogp!!","text":"setlogp!!(vi::AbstractVarInfo, logp::NamedTuple)\n\nSet both the log prior and the log likelihood probabilities in vi.\n\nlogp should have fields logprior and loglikelihood and no other fields.\n\nSee also: setlogprior!!, setloglikelihood!!, getlogp.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.acclogp!!","page":"API","title":"DynamicPPL.acclogp!!","text":"acclogp!!(vi::AbstractVarInfo, logp::NamedTuple; ignore_missing_accumulator::Bool=false)\n\nAdd to both the log prior and the log likelihood probabilities in vi.\n\nlogp should have fields logprior and/or loglikelihood, and no other fields.\n\nBy default if the necessary accumulators are not in vi an error is thrown. If ignore_missing_accumulator is set to true then this is silently ignored instead.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getlogjoint","page":"API","title":"DynamicPPL.getlogjoint","text":"getlogjoint(vi::AbstractVarInfo)\n\nReturn the log of the joint probability of the observed data and parameters in vi.\n\nSee also: getlogprior, getloglikelihood.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getlogjoint_internal","page":"API","title":"DynamicPPL.getlogjoint_internal","text":"getlogjoint_internal(vi::AbstractVarInfo)\n\nReturn the log of the joint probability of the observed data and parameters as they are stored internally in vi, including the log-Jacobian for any linked parameters.\n\nIn general, we have that:\n\ngetlogjoint_internal(vi) == getlogjoint(vi) - getlogjac(vi)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getlogjac","page":"API","title":"DynamicPPL.getlogjac","text":"getlogjac(vi::AbstractVarInfo)\n\nReturn the accumulated log-Jacobian term for any linked parameters in vi. The Jacobian here is taken with respect to the forward (link) transform.\n\nSee also: setlogjac!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setlogjac!!","page":"API","title":"DynamicPPL.setlogjac!!","text":"setlogjac!!(vi::AbstractVarInfo, logjac)\n\nSet the accumulated log-Jacobian term for any linked parameters in vi. The Jacobian here is taken with respect to the forward (link) transform.\n\nSee also: getlogjac, acclogjac!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.acclogjac!!","page":"API","title":"DynamicPPL.acclogjac!!","text":"acclogjac!!(vi::AbstractVarInfo, logjac)\n\nAdd logjac to the value of the log Jacobian in vi.\n\nSee also: getlogjac, setlogjac!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getlogprior","page":"API","title":"DynamicPPL.getlogprior","text":"getlogprior(vi::AbstractVarInfo)\n\nReturn the log of the prior probability of the parameters in vi.\n\nSee also: getlogjoint, getloglikelihood, setlogprior!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getlogprior_internal","page":"API","title":"DynamicPPL.getlogprior_internal","text":"getlogprior_internal(vi::AbstractVarInfo)\n\nReturn the log of the prior probability of the parameters as stored internally in vi. This includes the log-Jacobian for any linked parameters.\n\nIn general, we have that:\n\ngetlogprior_internal(vi) == getlogprior(vi) - getlogjac(vi)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setlogprior!!","page":"API","title":"DynamicPPL.setlogprior!!","text":"setlogprior!!(vi::AbstractVarInfo, logp)\n\nSet the log of the prior probability of the parameters sampled in vi to logp.\n\nSee also: setloglikelihood!!, setlogp!!, getlogprior.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.acclogprior!!","page":"API","title":"DynamicPPL.acclogprior!!","text":"acclogprior!!(vi::AbstractVarInfo, logp)\n\nAdd logp to the value of the log of the prior probability in vi.\n\nSee also: accloglikelihood!!, acclogp!!, getlogprior, setlogprior!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getloglikelihood","page":"API","title":"DynamicPPL.getloglikelihood","text":"getloglikelihood(vi::AbstractVarInfo)\n\nReturn the log of the likelihood probability of the observed data in vi.\n\nSee also: getlogjoint, getlogprior, setloglikelihood!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setloglikelihood!!","page":"API","title":"DynamicPPL.setloglikelihood!!","text":"setloglikelihood!!(vi::AbstractVarInfo, logp)\n\nSet the log of the likelihood probability of the observed data sampled in vi to logp.\n\nSee also: setlogprior!!, setlogp!!, getloglikelihood.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.accloglikelihood!!","page":"API","title":"DynamicPPL.accloglikelihood!!","text":"accloglikelihood!!(vi::AbstractVarInfo, logp)\n\nAdd logp to the value of the log of the likelihood in vi.\n\nSee also: accloglikelihood!!, acclogp!!, getloglikelihood, setloglikelihood!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Variables-and-their-realizations","page":"API","title":"Variables and their realizations","text":"","category":"section"},{"location":"api/#Base.keys","page":"API","title":"Base.keys","text":"keys(vi::AbstractVarInfo)\n\nReturn an iterator over all vns in vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.getindex","page":"API","title":"Base.getindex","text":"getindex(vi::AbstractVarInfo, vn::VarName[, dist::Distribution])\ngetindex(vi::AbstractVarInfo, vns::Vector{<:VarName}[, dist::Distribution])\n\nReturn the current value(s) of vn (vns) in vi in the support of its (their) distribution(s).\n\nIf dist is specified, the value(s) will be massaged into the representation expected by dist.\n\n\n\n\n\n","category":"function"},{"location":"api/#BangBang.push!!","page":"API","title":"BangBang.push!!","text":"push!!(vi::VarInfo, vn::VarName, r, dist::Distribution)\n\nPush a new random variable vn with a sampled value r from a distribution dist to the VarInfo vi, mutating if it makes sense.\n\n\n\n\n\n","category":"function"},{"location":"api/#BangBang.empty!!","page":"API","title":"BangBang.empty!!","text":"empty!!(vi::AbstractVarInfo)\n\nEmpty vi of variables and reset all accumulators.\n\nThis is useful when using a sampling algorithm that assumes an empty vi, e.g. SMC.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.isempty","page":"API","title":"Base.isempty","text":"isempty(vi::AbstractVarInfo)\n\nReturn true if vi is empty and false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getindex_internal","page":"API","title":"DynamicPPL.getindex_internal","text":"getindex_internal(vi::AbstractVarInfo, vn::VarName)\ngetindex_internal(vi::AbstractVarInfo, vns::Vector{<:VarName})\ngetindex_internal(vi::AbstractVarInfo, ::Colon)\n\nReturn the internal value of the varname vn, varnames vns, or all varnames in vi respectively. The internal value is the value of the variables that is stored in the varinfo object; this may be the actual realisation of the random variable (i.e. the value sampled from the distribution), or it may have been transformed to Euclidean space, depending on whether the varinfo was linked.\n\nSee https://turinglang.org/docs/developers/transforms/dynamicppl/ for more information on how transformed variables are stored in DynamicPPL.\n\nSee also: getindex(vi::AbstractVarInfo, vn::VarName, dist::Distribution)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setindex_internal!","page":"API","title":"DynamicPPL.setindex_internal!","text":"setindex_internal!(vnv::VarNamedVector, val, i::Int)\n\nSets the ith element of the internal storage vector, ignoring inactive entries.\n\n\n\n\n\nsetindex_internal!(vnv::VarNamedVector, val, vn::VarName[, transform])\n\nLike setindex!, but sets the values as they are stored internally in vnv.\n\nOptionally can set the transformation, such that transform(val) is the original value of the variable. By default, the transform is the identity if creating a new entry in vnv, or the existing transform if updating an existing entry.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.update_internal!","page":"API","title":"DynamicPPL.update_internal!","text":"update_internal!(vnv::VarNamedVector, vn::VarName, val::AbstractVector[, transform])\n\nUpdate an existing entry for vn in vnv with the value val.\n\nLike setindex_internal!, but errors if the key vn doesn't exist.\n\ntransform should be a function that converts val to the original representation. By default it's the same as the old transform for vn.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.insert_internal!","page":"API","title":"DynamicPPL.insert_internal!","text":"insert_internal!(vnv::VarNamedVector, val::AbstractVector, vn::VarName[, transform])\n\nAdd a variable with given value to vnv.\n\nLike setindex_internal!, but errors if the key vn already exists.\n\ntransform should be a function that converts val to the original representation. By default it's identity.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.length_internal","page":"API","title":"DynamicPPL.length_internal","text":"length_internal(vnv::VarNamedVector)\n\nReturn the length of the internal storage vector of vnv, ignoring inactive entries.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.reset!","page":"API","title":"DynamicPPL.reset!","text":"reset!(vnv::VarNamedVector, val, vn::VarName)\n\nReset the value of vn in vnv to val.\n\nThis differs from setindex! in that it will always change the transform of the variable to be the default vectorisation transform. This undoes any possible linking.\n\nExamples\n\njulia> using DynamicPPL: VarNamedVector, @varname, reset!\n\njulia> vnv = VarNamedVector();\n\njulia> vnv[@varname(x)] = reshape(1:9, (3, 3));\n\njulia> setindex!(vnv, 2.0, @varname(x))\nERROR: An error occurred while assigning the value 2.0 to variable x. If you are changing the type or size of a variable you'll need to call reset!\n[...]\n\njulia> reset!(vnv, 2.0, @varname(x));\n\njulia> vnv[@varname(x)]\n2.0\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.update!","page":"API","title":"DynamicPPL.update!","text":"update!(vnv::VarNamedVector, val, vn::VarName)\n\nUpdate the value of vn in vnv to val.\n\nLike setindex!, but errors if the key vn doesn't exist.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.insert!","page":"API","title":"Base.insert!","text":"insert!(vnv::VarNamedVector, val, vn::VarName)\n\nAdd a variable with given value to vnv.\n\nLike setindex!, but errors if the key vn already exists.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.loosen_types!!","page":"API","title":"DynamicPPL.loosen_types!!","text":"loosen_types!!(vnv::VarNamedVector{K,V,TVN,TVal,TTrans}, ::Type{KNew}, ::Type{TransNew})\n\nLoosen the types of vnv to allow varname type KNew and transformation type TransNew.\n\nIf KNew is a subtype of K and TransNew is a subtype of the element type of the TTrans then this is a no-op and vnv is returned as is. Otherwise a new VarNamedVector is returned with the same data but more abstract types, so that variables of type KNew and transformations of type TransNew can be pushed to it. Some of the underlying storage is shared between vnv and the return value, and thus mutating one may affect the other.\n\nSee also\n\ntighten_types\n\nExamples\n\njulia> using DynamicPPL: VarNamedVector, @varname, loosen_types!!, setindex_internal!\n\njulia> vnv = VarNamedVector(@varname(x) => [1.0]);\n\njulia> y_trans(x) = reshape(x, (2, 2));\n\njulia> setindex_internal!(vnv, collect(1:4), @varname(y), y_trans)\nERROR: MethodError: Cannot `convert` an object of type\n[...]\n\njulia> vnv_loose = DynamicPPL.loosen_types!!(vnv, typeof(@varname(y)), typeof(y_trans));\n\njulia> setindex_internal!(vnv_loose, collect(1:4), @varname(y), y_trans)\n\njulia> vnv_loose[@varname(y)]\n2×2 Matrix{Float64}:\n 1.0  3.0\n 2.0  4.0\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.tighten_types","page":"API","title":"DynamicPPL.tighten_types","text":"tighten_types(vnv::VarNamedVector)\n\nReturn a copy of vnv with the most concrete types possible.\n\nFor instance, if vnv has its vector of transforms have eltype Any, but all the transforms are actually identity transformations, this function will return a new VarNamedVector with the transforms vector having eltype typeof(identity).\n\nThis is a lot like the reverse of loosen_types!!, but with two notable differences: Unlike loosen_types!!, this function does not mutate vnv; it also changes not only the key and transform eltypes, but also the values eltype.\n\nSee also\n\nloosen_types!!\n\nExamples\n\njulia> using DynamicPPL: VarNamedVector, @varname, loosen_types!!, setindex_internal!\n\njulia> vnv = VarNamedVector();\n\njulia> setindex!(vnv, [23], @varname(x))\n\njulia> eltype(vnv)\nReal\n\njulia> vnv.transforms\n1-element Vector{Any}:\n identity (generic function with 1 method)\n\njulia> vnv_tight = DynamicPPL.tighten_types(vnv);\n\njulia> eltype(vnv_tight) == Int\ntrue\n\njulia> vnv_tight.transforms\n1-element Vector{typeof(identity)}:\n identity (generic function with 1 method)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.values_as","page":"API","title":"DynamicPPL.values_as","text":"values_as(varinfo[, Type])\n\nReturn the values/realizations in varinfo as Type, if implemented.\n\nIf no Type is provided, return values as stored in varinfo.\n\nExamples\n\nSimpleVarInfo with NamedTuple:\n\njulia> data = (x = 1.0, m = [2.0]);\n\njulia> values_as(SimpleVarInfo(data))\n(x = 1.0, m = [2.0])\n\njulia> values_as(SimpleVarInfo(data), NamedTuple)\n(x = 1.0, m = [2.0])\n\njulia> values_as(SimpleVarInfo(data), OrderedDict)\nOrderedDict{VarName{sym, typeof(identity)} where sym, Any} with 2 entries:\n  x => 1.0\n  m => [2.0]\n\njulia> values_as(SimpleVarInfo(data), Vector)\n2-element Vector{Float64}:\n 1.0\n 2.0\n\nSimpleVarInfo with OrderedDict:\n\njulia> data = OrderedDict{Any,Any}(@varname(x) => 1.0, @varname(m) => [2.0]);\n\njulia> values_as(SimpleVarInfo(data))\nOrderedDict{Any, Any} with 2 entries:\n  x => 1.0\n  m => [2.0]\n\njulia> values_as(SimpleVarInfo(data), NamedTuple)\n(x = 1.0, m = [2.0])\n\njulia> values_as(SimpleVarInfo(data), OrderedDict)\nOrderedDict{Any, Any} with 2 entries:\n  x => 1.0\n  m => [2.0]\n\njulia> values_as(SimpleVarInfo(data), Vector)\n2-element Vector{Float64}:\n 1.0\n 2.0\n\nVarInfo with NamedTuple of Metadata:\n\njulia> # Just use an example model to construct the `VarInfo` because we're lazy.\n       vi = DynamicPPL.typed_varinfo(DynamicPPL.TestUtils.demo_assume_dot_observe());\n\njulia> vi[@varname(s)] = 1.0; vi[@varname(m)] = 2.0;\n\njulia> # For the sake of brevity, let's just check the type.\n       md = values_as(vi); md.s isa Union{DynamicPPL.Metadata, DynamicPPL.VarNamedVector}\ntrue\n\njulia> values_as(vi, NamedTuple)\n(s = 1.0, m = 2.0)\n\njulia> values_as(vi, OrderedDict)\nOrderedDict{VarName{sym, typeof(identity)} where sym, Float64} with 2 entries:\n  s => 1.0\n  m => 2.0\n\njulia> values_as(vi, Vector)\n2-element Vector{Float64}:\n 1.0\n 2.0\n\nVarInfo with Metadata:\n\njulia> # Just use an example model to construct the `VarInfo` because we're lazy.\n       vi = DynamicPPL.untyped_varinfo(DynamicPPL.TestUtils.demo_assume_dot_observe());\n\njulia> vi[@varname(s)] = 1.0; vi[@varname(m)] = 2.0;\n\njulia> # For the sake of brevity, let's just check the type.\n       values_as(vi) isa Union{DynamicPPL.Metadata, Vector}\ntrue\n\njulia> values_as(vi, NamedTuple)\n(s = 1.0, m = 2.0)\n\njulia> values_as(vi, OrderedDict)\nOrderedDict{VarName{sym, typeof(identity)} where sym, Float64} with 2 entries:\n  s => 1.0\n  m => 2.0\n\njulia> values_as(vi, Vector)\n2-element Vector{Real}:\n 1.0\n 2.0\n\n\n\n\n\n","category":"function"},{"location":"api/#Transformations","page":"API","title":"Transformations","text":"","category":"section"},{"location":"api/#DynamicPPL.AbstractTransformation","page":"API","title":"DynamicPPL.AbstractTransformation","text":"abstract type AbstractTransformation\n\nRepresents a transformation to be used in link!! and invlink!!, amongst others.\n\nA concrete implementation of this should implement the following methods:\n\nlink!!: transforms the AbstractVarInfo to the unconstrained space.\ninvlink!!: transforms the AbstractVarInfo to the constrained space.\n\nAnd potentially:\n\nmaybe_invlink_before_eval!!: hook to decide whether to transform before evaluating the model.\n\nSee also: link!!, invlink!!, maybe_invlink_before_eval!!.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.NoTransformation","page":"API","title":"DynamicPPL.NoTransformation","text":"struct NoTransformation <: DynamicPPL.AbstractTransformation\n\nTransformation which applies the identity function.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.DynamicTransformation","page":"API","title":"DynamicPPL.DynamicTransformation","text":"struct DynamicTransformation <: DynamicPPL.AbstractTransformation\n\nTransformation which transforms the variables on a per-need-basis in the execution of a given Model.\n\nThis is in constrast to StaticTransformation which transforms all variables before the execution of a given Model.\n\nSee also: StaticTransformation.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.StaticTransformation","page":"API","title":"DynamicPPL.StaticTransformation","text":"struct StaticTransformation{F} <: DynamicPPL.AbstractTransformation\n\nTransformation which transforms all variables before the execution of a given Model.\n\nThis is done through the maybe_invlink_before_eval!! method.\n\nSee also: DynamicTransformation, maybe_invlink_before_eval!!.\n\nFields\n\nbijector::Any: The function, assumed to implement the Bijectors interface, to be applied to the variables\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.istrans","page":"API","title":"DynamicPPL.istrans","text":"istrans(vnv::VarNamedVector, vn::VarName)\n\nReturn a boolean for whether vn is guaranteed to have been transformed so that its domain is all of Euclidean space.\n\n\n\n\n\nistrans(vi::AbstractVarInfo[, vns::Union{VarName, AbstractVector{<:Varname}}])\n\nReturn true if vi is working in unconstrained space, and false if vi is assuming realizations to be in support of the corresponding distributions.\n\nIf vns is provided, then only check if this/these varname(s) are transformed.\n\nwarning: Warning\nNot all implementations of AbstractVarInfo support transforming only a subset of the variables.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.settrans!!","page":"API","title":"DynamicPPL.settrans!!","text":"settrans!!(vi::AbstractVarInfo, trans::Bool[, vn::VarName])\n\nReturn vi with istrans(vi, vn) evaluating to true.\n\nIf vn is not specified, then istrans(vi) evaluates to true for all variables.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.transformation","page":"API","title":"DynamicPPL.transformation","text":"transformation(vi::AbstractVarInfo)\n\nReturn the AbstractTransformation related to vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#Bijectors.link","page":"API","title":"Bijectors.link","text":"link([t::AbstractTransformation, ]vi::AbstractVarInfo, model::Model)\nlink([t::AbstractTransformation, ]vi::AbstractVarInfo, vns::NTuple{N,VarName}, model::Model)\n\nTransform variables in vi to their linked space without mutating vi.\n\nEither transform all variables, or only ones specified in vns.\n\nUse the  transformation t, or default_transformation(model, vi) if one is not provided.\n\nSee also: default_transformation, invlink.\n\n\n\n\n\n","category":"function"},{"location":"api/#Bijectors.invlink","page":"API","title":"Bijectors.invlink","text":"invlink([t::AbstractTransformation, ]vi::AbstractVarInfo, model::Model)\ninvlink([t::AbstractTransformation, ]vi::AbstractVarInfo, vns::NTuple{N,VarName}, model::Model)\n\nTransform variables in vi to their constrained space without mutating vi.\n\nEither transform all variables, or only ones specified in vns.\n\nUse the (inverse of) transformation t, or default_transformation(model, vi) if one is not provided.\n\nSee also: default_transformation, link.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.link!!","page":"API","title":"DynamicPPL.link!!","text":"link!!([t::AbstractTransformation, ]vi::AbstractVarInfo, model::Model)\nlink!!([t::AbstractTransformation, ]vi::AbstractVarInfo, vns::NTuple{N,VarName}, model::Model)\n\nTransform variables in vi to their linked space, mutating vi if possible.\n\nEither transform all variables, or only ones specified in vns.\n\nUse the  transformation t, or default_transformation(model, vi) if one is not provided.\n\nSee also: default_transformation, invlink!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.invlink!!","page":"API","title":"DynamicPPL.invlink!!","text":"invlink!!([t::AbstractTransformation, ]vi::AbstractVarInfo, model::Model)\ninvlink!!([t::AbstractTransformation, ]vi::AbstractVarInfo, vns::NTuple{N,VarName}, model::Model)\n\nTransform variables in vi to their constrained space, mutating vi if possible.\n\nEither transform all variables, or only ones specified in vns.\n\nUse the (inverse of) transformation t, or default_transformation(model, vi) if one is not provided.\n\nSee also: default_transformation, link!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.default_transformation","page":"API","title":"DynamicPPL.default_transformation","text":"default_transformation(model::Model[, vi::AbstractVarInfo])\n\nReturn the AbstractTransformation currently related to model and, potentially, vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.link_transform","page":"API","title":"DynamicPPL.link_transform","text":"link_transform(dist)\n\nReturn the constrained-to-unconstrained bijector for distribution dist.\n\nBy default, this is just Bijectors.bijector(dist).\n\nwarning: Warning\nNote that currently this is not used by Bijectors.logpdf_with_trans, hence that needs to be overloaded separately if the intention is to change behavior of an existing distribution.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.invlink_transform","page":"API","title":"DynamicPPL.invlink_transform","text":"invlink_transform(dist)\n\nReturn the unconstrained-to-constrained bijector for distribution dist.\n\nBy default, this is just inverse(link_transform(dist)).\n\nwarning: Warning\nNote that currently this is not used by Bijectors.logpdf_with_trans, hence that needs to be overloaded separately if the intention is to change behavior of an existing distribution.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.maybe_invlink_before_eval!!","page":"API","title":"DynamicPPL.maybe_invlink_before_eval!!","text":"maybe_invlink_before_eval!!([t::Transformation,] vi, model)\n\nReturn a possibly invlinked version of vi.\n\nThis will be called prior to model evaluation, allowing one to perform a single invlink!! before evaluation rather than lazyily evaluating the transforms on as-we-need basis as is done with DynamicTransformation.\n\nSee also: StaticTransformation, DynamicTransformation.\n\nExamples\n\njulia> using DynamicPPL, Distributions, Bijectors\n\njulia> @model demo() = x ~ Normal()\ndemo (generic function with 2 methods)\n\njulia> # By subtyping `Transform`, we inherit the `(inv)link!!`.\n       struct MyBijector <: Bijectors.Transform end\n\njulia> # Define some dummy `inverse` which will be used in the `link!!` call.\n       Bijectors.inverse(f::MyBijector) = identity\n\njulia> # We need to define `with_logabsdet_jacobian` for `MyBijector`\n       # (`identity` already has `with_logabsdet_jacobian` defined)\n       function Bijectors.with_logabsdet_jacobian(::MyBijector, x)\n           # Just using a large number of the logabsdet-jacobian term\n           # for demonstration purposes.\n           return (x, 1000)\n       end\n\njulia> # Change the `default_transformation` for our model to be a\n       # `StaticTransformation` using `MyBijector`.\n       function DynamicPPL.default_transformation(::Model{typeof(demo)})\n           return DynamicPPL.StaticTransformation(MyBijector())\n       end\n\njulia> model = demo();\n\njulia> vi = SimpleVarInfo(x=1.0)\nSimpleVarInfo((x = 1.0,), 0.0)\n\njulia> # Uses the `inverse` of `MyBijector`, which we have defined as `identity`\n       vi_linked = link!!(vi, model)\nTransformed SimpleVarInfo((x = 1.0,), 0.0)\n\njulia> # Now performs a single `invlink!!` before model evaluation.\n       logjoint(model, vi_linked)\n-1001.4189385332047\n\n\n\n\n\n","category":"function"},{"location":"api/#Utils","page":"API","title":"Utils","text":"","category":"section"},{"location":"api/#Base.merge-Tuple{AbstractVarInfo}","page":"API","title":"Base.merge","text":"merge(varinfo, other_varinfos...)\n\nMerge varinfos into one, giving precedence to the right-most varinfo when sensible.\n\nThis is particularly useful when combined with subset(varinfo, vns).\n\nSee docstring of subset(varinfo, vns) for examples.\n\n\n\n\n\n","category":"method"},{"location":"api/#DynamicPPL.subset","page":"API","title":"DynamicPPL.subset","text":"subset(varinfo::AbstractVarInfo, vns::AbstractVector{<:VarName})\n\nSubset a varinfo to only contain the variables vns.\n\nThe ordering of variables in the return value will be the same as in varinfo.\n\nExamples\n\njulia> @model function demo()\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, sqrt(s))\n           x = Vector{Float64}(undef, 2)\n           x[1] ~ Normal(m, sqrt(s))\n           x[2] ~ Normal(m, sqrt(s))\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo();\n\njulia> varinfo = VarInfo(model);\n\njulia> keys(varinfo)\n4-element Vector{VarName}:\n s\n m\n x[1]\n x[2]\n\njulia> for (i, vn) in enumerate(keys(varinfo))\n           varinfo[vn] = i\n       end\n\njulia> varinfo[[@varname(s), @varname(m), @varname(x[1]), @varname(x[2])]]\n4-element Vector{Float64}:\n 1.0\n 2.0\n 3.0\n 4.0\n\njulia> # Extract one with only `m`.\n       varinfo_subset1 = subset(varinfo, [@varname(m),]);\n\n\njulia> keys(varinfo_subset1)\n1-element Vector{VarName{:m, typeof(identity)}}:\n m\n\njulia> varinfo_subset1[@varname(m)]\n2.0\n\njulia> # Extract one with both `s` and `x[2]`.\n       varinfo_subset2 = subset(varinfo, [@varname(s), @varname(x[2])]);\n\njulia> keys(varinfo_subset2)\n2-element Vector{VarName}:\n s\n x[2]\n\njulia> varinfo_subset2[[@varname(s), @varname(x[2])]]\n2-element Vector{Float64}:\n 1.0\n 4.0\n\nsubset is particularly useful when combined with merge(varinfo::AbstractVarInfo)\n\njulia> # Merge the two.\n       varinfo_subset_merged = merge(varinfo_subset1, varinfo_subset2);\n\njulia> keys(varinfo_subset_merged)\n3-element Vector{VarName}:\n m\n s\n x[2]\n\njulia> varinfo_subset_merged[[@varname(s), @varname(m), @varname(x[2])]]\n3-element Vector{Float64}:\n 1.0\n 2.0\n 4.0\n\njulia> # Merge the two with the original.\n       varinfo_merged = merge(varinfo, varinfo_subset_merged);\n\njulia> keys(varinfo_merged)\n4-element Vector{VarName}:\n s\n m\n x[1]\n x[2]\n\njulia> varinfo_merged[[@varname(s), @varname(m), @varname(x[1]), @varname(x[2])]]\n4-element Vector{Float64}:\n 1.0\n 2.0\n 3.0\n 4.0\n\nNotes\n\nType-stability\n\nwarning: Warning\nThis function is only type-stable when vns contains only varnames with the same symbol. For exmaple, [@varname(m[1]), @varname(m[2])] will be type-stable, but [@varname(m[1]), @varname(x)] will not be.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.unflatten","page":"API","title":"DynamicPPL.unflatten","text":"unflatten(vi::AbstractVarInfo, x::AbstractVector)\n\nReturn a new instance of vi with the values of x assigned to the variables.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.varname_leaves","page":"API","title":"DynamicPPL.varname_leaves","text":"varname_leaves(vn::VarName, val)\n\nReturn an iterator over all varnames that are represented by vn on val.\n\nExamples\n\njulia> using DynamicPPL: varname_leaves\n\njulia> foreach(println, varname_leaves(@varname(x), rand(2)))\nx[1]\nx[2]\n\njulia> foreach(println, varname_leaves(@varname(x[1:2]), rand(2)))\nx[1:2][1]\nx[1:2][2]\n\njulia> x = (y = 1, z = [[2.0], [3.0]]);\n\njulia> foreach(println, varname_leaves(@varname(x), x))\nx.y\nx.z[1][1]\nx.z[2][1]\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.varname_and_value_leaves","page":"API","title":"DynamicPPL.varname_and_value_leaves","text":"varname_and_value_leaves(vn::VarName, val)\n\nReturn an iterator over all varname-value pairs that are represented by vn on val.\n\nExamples\n\njulia> using DynamicPPL: varname_and_value_leaves\n\njulia> foreach(println, varname_and_value_leaves(@varname(x), 1:2))\n(x[1], 1)\n(x[2], 2)\n\njulia> foreach(println, varname_and_value_leaves(@varname(x[1:2]), 1:2))\n(x[1:2][1], 1)\n(x[1:2][2], 2)\n\njulia> x = (y = 1, z = [[2.0], [3.0]]);\n\njulia> foreach(println, varname_and_value_leaves(@varname(x), x))\n(x.y, 1)\n(x.z[1][1], 2.0)\n(x.z[2][1], 3.0)\n\nThere is also some special handling for certain types:\n\njulia> using LinearAlgebra\n\njulia> x = reshape(1:4, 2, 2);\n\njulia> # `LowerTriangular`\n       foreach(println, varname_and_value_leaves(@varname(x), LowerTriangular(x)))\n(x[1, 1], 1)\n(x[2, 1], 2)\n(x[2, 2], 4)\n\njulia> # `UpperTriangular`\n       foreach(println, varname_and_value_leaves(@varname(x), UpperTriangular(x)))\n(x[1, 1], 1)\n(x[1, 2], 3)\n(x[2, 2], 4)\n\njulia> # `Cholesky` with lower-triangular\n       foreach(println, varname_and_value_leaves(@varname(x), Cholesky([1.0 0.0; 0.0 1.0], 'L', 0)))\n(x.L[1, 1], 1.0)\n(x.L[2, 1], 0.0)\n(x.L[2, 2], 1.0)\n\njulia> # `Cholesky` with upper-triangular\n       foreach(println, varname_and_value_leaves(@varname(x), Cholesky([1.0 0.0; 0.0 1.0], 'U', 0)))\n(x.U[1, 1], 1.0)\n(x.U[1, 2], 0.0)\n(x.U[2, 2], 1.0)\n\n\n\n\n\nvarname_and_value_leaves(container)\n\nReturn an iterator over all varname-value pairs that are represented by container.\n\nThis is the same as varname_and_value_leaves(vn::VarName, x) but over a container containing multiple varnames.\n\nSee also: varname_and_value_leaves(vn::VarName, x).\n\nExamples\n\njulia> using DynamicPPL: varname_and_value_leaves\n\njulia> # With an `OrderedDict`\n       dict = OrderedDict(@varname(y) => 1, @varname(z) => [[2.0], [3.0]]);\n\njulia> foreach(println, varname_and_value_leaves(dict))\n(y, 1)\n(z[1][1], 2.0)\n(z[2][1], 3.0)\n\njulia> # With a `NamedTuple`\n       nt = (y = 1, z = [[2.0], [3.0]]);\n\njulia> foreach(println, varname_and_value_leaves(nt))\n(y, 1)\n(z[1][1], 2.0)\n(z[2][1], 3.0)\n\n\n\n\n\n","category":"function"},{"location":"api/#Evaluation-Contexts","page":"API","title":"Evaluation Contexts","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Internally, model evaluation is performed with AbstractPPL.evaluate!!.","category":"page"},{"location":"api/#AbstractPPL.evaluate!!","page":"API","title":"AbstractPPL.evaluate!!","text":"evaluate!!(model::Model, varinfo)\n\nEvaluate the model with the given varinfo.\n\nIf multiple threads are available, the varinfo provided will be wrapped in a ThreadSafeVarInfo before evaluation.\n\nReturns a tuple of the model's return value, plus the updated varinfo (unwrapped if necessary).\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"This method mutates the varinfo used for execution. By default, it does not perform any actual sampling: it only evaluates the model using the values of the variables that are already in the varinfo. To perform sampling, you can either wrap model.context in a SamplingContext, or use this convenience method:","category":"page"},{"location":"api/#DynamicPPL.evaluate_and_sample!!","page":"API","title":"DynamicPPL.evaluate_and_sample!!","text":"evaluate_and_sample!!([rng::Random.AbstractRNG, ]model::Model, varinfo[, sampler])\n\nEvaluate the model with the given varinfo, but perform sampling during the evaluation using the given sampler by wrapping the model's context in a SamplingContext.\n\nIf sampler is not provided, defaults to SampleFromPrior.\n\nReturns a tuple of the model's return value, plus the updated varinfo object.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"The behaviour of a model execution can be changed with evaluation contexts, which are a field of the model. Contexts are subtypes of AbstractPPL.AbstractContext.","category":"page"},{"location":"api/#DynamicPPL.SamplingContext","page":"API","title":"DynamicPPL.SamplingContext","text":"SamplingContext(\n        [rng::Random.AbstractRNG=Random.default_rng()],\n        [sampler::AbstractSampler=SampleFromPrior()],\n        [context::AbstractContext=DefaultContext()],\n)\n\nCreate a context that allows you to sample parameters with the sampler when running the model. The context determines how the returned log density is computed when running the model.\n\nSee also: DefaultContext\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.DefaultContext","page":"API","title":"DynamicPPL.DefaultContext","text":"struct DefaultContext <: AbstractContext end\n\nThe DefaultContext is used by default to accumulate values like the log joint probability when running the model.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.PrefixContext","page":"API","title":"DynamicPPL.PrefixContext","text":"PrefixContext(vn::VarName[, context::AbstractContext])\nPrefixContext(vn::Val{sym}[, context::AbstractContext]) where {sym}\n\nCreate a context that allows you to use the wrapped context when running the model and prefixes all parameters with the VarName vn.\n\nPrefixContext(Val(:a), context) is equivalent to PrefixContext(@varname(a), context). If context is not provided, it defaults to DefaultContext().\n\nThis context is useful in nested models to ensure that the names of the parameters are unique.\n\nSee also: to_submodel\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.ConditionContext","page":"API","title":"DynamicPPL.ConditionContext","text":"ConditionContext{Values<:Union{NamedTuple,AbstractDict},Ctx<:AbstractContext}\n\nModel context that contains values that are to be conditioned on. The values can either be a NamedTuple mapping symbols to values, such as (a=1, b=2), or an AbstractDict mapping varnames to values (e.g. Dict(@varname(a) => 1, @varname(b) => 2)). The former is more performant, but the latter must be used when there are varnames that cannot be represented as symbols, e.g. @varname(x[1]).\n\n\n\n\n\n","category":"type"},{"location":"api/#Samplers","page":"API","title":"Samplers","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"In DynamicPPL two samplers are defined that are used to initialize unobserved random variables: SampleFromPrior which samples from the prior distribution, and SampleFromUniform which samples from a uniform distribution.","category":"page"},{"location":"api/#DynamicPPL.SampleFromPrior","page":"API","title":"DynamicPPL.SampleFromPrior","text":"SampleFromPrior\n\nSampling algorithm that samples unobserved random variables from their prior distribution.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.SampleFromUniform","page":"API","title":"DynamicPPL.SampleFromUniform","text":"SampleFromUniform\n\nSampling algorithm that samples unobserved random variables from a uniform distribution.\n\nReferences\n\nStan reference manual\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"Additionally, a generic sampler for inference is implemented.","category":"page"},{"location":"api/#DynamicPPL.Sampler","page":"API","title":"DynamicPPL.Sampler","text":"Sampler{T}\n\nGeneric sampler type for inference algorithms of type T in DynamicPPL.\n\nSampler should implement the AbstractMCMC interface, and in particular AbstractMCMC.step. A default implementation of the initial sampling step is provided that supports resuming sampling from a previous state and setting initial parameter values. It requires to overload loadstate and initialstep for loading previous states and actually performing the initial sampling step, respectively. Additionally, sometimes one might want to implement initialsampler that specifies how the initial parameter values are sampled if they are not provided. By default, values are sampled from the prior.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"The default implementation of Sampler uses the following unexported functions.","category":"page"},{"location":"api/#DynamicPPL.initialstep","page":"API","title":"DynamicPPL.initialstep","text":"initialstep(rng, model, sampler, varinfo; kwargs...)\n\nPerform the initial sampling step of the sampler for the model.\n\nThe varinfo contains the initial samples, which can be provided by the user or sampled randomly.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.loadstate","page":"API","title":"DynamicPPL.loadstate","text":"loadstate(data)\n\nLoad sampler state from data.\n\nBy default, data is returned.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.initialsampler","page":"API","title":"DynamicPPL.initialsampler","text":"initialsampler(sampler::Sampler)\n\nReturn the sampler that is used for generating the initial parameters when sampling with sampler.\n\nBy default, it returns an instance of SampleFromPrior.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"Finally, to specify which varinfo type a Sampler should use for a given Model, this is specified by DynamicPPL.default_varinfo and can thus be overloaded for each  model-sampler combination. This can be useful in cases where one has explicit knowledge that one type of varinfo will be more performant for the given model and sampler.","category":"page"},{"location":"api/#DynamicPPL.default_varinfo","page":"API","title":"DynamicPPL.default_varinfo","text":"default_varinfo(rng, model, sampler)\n\nReturn a default varinfo object for the given model and sampler.\n\nArguments\n\nrng::Random.AbstractRNG: Random number generator.\nmodel::Model: Model for which we want to create a varinfo object.\nsampler::AbstractSampler: Sampler which will make use of the varinfo object.\n\nReturns\n\nAbstractVarInfo: Default varinfo object for the given model and sampler.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"There is also the experimental DynamicPPL.Experimental.determine_suitable_varinfo, which uses static checking via JET.jl to determine whether one should use DynamicPPL.typed_varinfo or DynamicPPL.untyped_varinfo, depending on which supports the model:","category":"page"},{"location":"api/#DynamicPPL.Experimental.determine_suitable_varinfo","page":"API","title":"DynamicPPL.Experimental.determine_suitable_varinfo","text":"determine_suitable_varinfo(model; only_ddpl::Bool=true)\n\nReturn a suitable varinfo for the given model.\n\nSee also: DynamicPPL.Experimental.is_suitable_varinfo.\n\nwarning: Warning\nFor full functionality, this requires JET.jl to be loaded. If JET.jl is not loaded, this function will assume the model is compatible with typed varinfo.\n\nArguments\n\nmodel: The model for which to determine the varinfo.\n\nKeyword Arguments\n\nonly_ddpl: If true, only consider error reports within DynamicPPL.jl.\n\nExamples\n\njulia> using DynamicPPL.Experimental: determine_suitable_varinfo\n\njulia> using JET: JET  # needs to be loaded for full functionality\n\njulia> @model function model_with_random_support()\n           x ~ Bernoulli()\n           if x\n               y ~ Normal()\n           else\n               z ~ Normal()\n           end\n       end\nmodel_with_random_support (generic function with 2 methods)\n\njulia> model = model_with_random_support();\n\njulia> # Typed varinfo cannot handle this random support model properly\n       # as using a single execution of the model will not see all random variables.\n       # Hence, this this model requires untyped varinfo.\n       vi = determine_suitable_varinfo(model);\n┌ Warning: Model seems incompatible with typed varinfo. Falling back to untyped varinfo.\n└ @ DynamicPPLJETExt ~/.julia/dev/DynamicPPL.jl/ext/DynamicPPLJETExt.jl:48\n\njulia> vi isa typeof(DynamicPPL.untyped_varinfo(model))\ntrue\n\njulia> # In contrast, a simple model with no random support can be handled by typed varinfo.\n       @model model_with_static_support() = x ~ Normal()\nmodel_with_static_support (generic function with 2 methods)\n\njulia> vi = determine_suitable_varinfo(model_with_static_support());\n\njulia> vi isa typeof(DynamicPPL.typed_varinfo(model_with_static_support()))\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.Experimental.is_suitable_varinfo","page":"API","title":"DynamicPPL.Experimental.is_suitable_varinfo","text":"is_suitable_varinfo(model::Model, varinfo::AbstractVarInfo; kwargs...)\n\nCheck if the model supports evaluation using the provided varinfo.\n\nwarning: Warning\nLoading JET.jl is required before calling this function.\n\nArguments\n\nmodel: The model to verify the support for.\nvarinfo: The varinfo to verify the support for.\n\nKeyword Arguments\n\nonly_ddpl: If true, only consider error reports occuring in the tilde pipeline. Default: true.\n\nReturns\n\nissuccess: true if the model supports the varinfo, otherwise false.\nreport: The result of report_call from JET.jl.\n\n\n\n\n\n","category":"function"},{"location":"api/#model_internal","page":"API","title":"Model-Internal Functions","text":"","category":"section"},{"location":"api/#DynamicPPL.tilde_assume","page":"API","title":"DynamicPPL.tilde_assume","text":"tilde_assume(context::SamplingContext, right, vn, vi)\n\nHandle assumed variables, e.g., x ~ Normal() (where x does occur in the model inputs), accumulate the log probability, and return the sampled value with a context associated with a sampler.\n\nFalls back to\n\ntilde_assume(context.rng, context.context, context.sampler, right, vn, vi)\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"#DynamicPPL.jl","page":"Home","title":"DynamicPPL.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A domain-specific language and backend for probabilistic programming languages, used by Turing.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"}]
}
