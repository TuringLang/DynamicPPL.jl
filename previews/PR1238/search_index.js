var documenterSearchIndex = {"docs":
[{"location":"init/#Initialisation-strategies","page":"Initialisation strategies","title":"Initialisation strategies","text":"In DynamicPPL, initialisation strategies are used to determine the parameters used to evaluate a model.\n\nnote: Note\nOne might perhaps more appropriately call them parameter generation strategies. Even the name initialisation is a bit of a historical misnomer (the original intent was that they would be used to populate an empty VarInfo with some values). However, over time, it has become clear that these are general enough to describe essentially any way of choosing parameters to evaluate a model with.\n\nCurrently, initialisation strategies are stored inside a model: specifically, if a model's context field is an InitContext, that context will contain a DynamicPPL.AbstractInitStrategy.\n\nEvery time an assume tilde-statement is seen (i.e., a random variable), the initialisation strategy is used to generate a value for that variable.\n\nEach initialisation strategy must implement DynamicPPL.init(rng, vn, dist, strategy), which must return an AbstractTransformedValue.","category":"section"},{"location":"init/#An-example","page":"Initialisation strategies","title":"An example","text":"Consider the following model:\n\nusing DynamicPPL, Distributions, Random\n\n@model function f()\n    x ~ Normal()\n    return x\nend\nmodel = f()\n\nSuppose we are writing a Metropolis–Hastings sampler, and we want to perform a random walk where the next proposed value of x depends on the previous value of x. Given a previous value x_prev we can define a custom initialisation strategy as follows:\n\nstruct InitRandomWalk <: DynamicPPL.AbstractInitStrategy\n    x_prev::Float64\n    step_size::Float64\nend\n\nfunction DynamicPPL.init(rng, vn::VarName, ::Distribution, strategy::InitRandomWalk)\n    new_x = rand(rng, Normal(strategy.x_prev, strategy.step_size))\n    # Insert some printing to see when this is called.\n    @info \"init() is returning: $new_x\"\n    return DynamicPPL.UntransformedValue(new_x)\nend\n\nGiven a previous value of x\n\nx_prev = 4.0\nnothing # hide\n\nwe can then make a proposal for x as follows:\n\nnew_x, new_vi = DynamicPPL.init!!(model, VarInfo(), InitRandomWalk(x_prev, 0.5))\nnothing # hide\n\nWhen evaluating the model, the value for x will be exactly that new value we proposed. We can see this from the return value:\n\nnew_x\n\nFurthermore, we can read off the associated log-probability from the newly returned VarInfo:\n\nDynamicPPL.getlogjoint(new_vi) ≈ logpdf(Normal(), new_x)\n\n(From this log-probability, we can compute the acceptance ratio for the Metropolis–Hastings step.)\n\nIn this case, we have defined an initialisation strategy that is random (and thus uses the rng argument for reproducibility). However, initialisation strategies can also be fully deterministic, in which case the rng argument is not needed. For example, DynamicPPL.InitFromParams reads from a set of given parameters.","category":"section"},{"location":"init/#The-returned-AbstractTransformedValue","page":"Initialisation strategies","title":"The returned AbstractTransformedValue","text":"warning: Warning\nThe correctness of this section is contingent on https://github.com/TuringLang/DynamicPPL.jl/pull/1231 being merged.\n\nAs mentioned above, the init function must return an AbstractTransformedValue. The subtype of AbstractTransformedValue used does not affect the result of the model evaluation, but it may have performance implications. In particular, the returned subtype does not determine whether the log-Jacobian term is accumulated or not: that is determined by a separate link strategy.\n\nWhat this means is that initialisation strategies should always choose the laziest possible subtype of AbstractTransformedValue.\n\nFor example, in the above example, we used UntransformedValue, which is the simplest possible choice. If a linked value is required by a later step inside tilde_assume!!, it is the responsibility of that step to perform the linking.\n\nConversely, DynamicPPL.InitFromUniform samples inside linked space. Instead of performing the inverse link transform and returning an UntransformedValue, it directly returns a LinkedVectorValue: this means that if a linked value is required by a later step, it is not necessary to link it again. Even if no linked value is required, this lazy approach does not hurt performance, as it just defers the inverse linking to the later step.\n\nIn both cases, only one linking operation is performed (at most).\n\n","category":"section"},{"location":"init/#DynamicPPL.AbstractInitStrategy-init","page":"Initialisation strategies","title":"DynamicPPL.AbstractInitStrategy","text":"AbstractInitStrategy\n\nAbstract type representing the possible ways of initialising new values for the random variables in a model (e.g., when creating a new VarInfo).\n\nAny subtype of AbstractInitStrategy must implement the DynamicPPL.init method, and in some cases, DynamicPPL.get_param_eltype (see its docstring for details).\n\n\n\n\n\n","category":"type"},{"location":"conditionfix/#Conditioning-and-fixing","page":"Conditioning and fixing","title":"Conditioning and fixing","text":"DynamicPPL allows you to first define a model, and then modify it by either conditioning on observed data, or fixing variables to specific values. This is useful for defining models once and then using them in different ways.\n\nAs an example, one could define a linear regression model as follows:\n\nusing DynamicPPL, Distributions\n\n@model function linear_regression(x)\n    m ~ Normal(0, 1)\n    c ~ Normal(0, 1)\n\n    y = Vector{Float64}(undef, length(x))\n    for i in eachindex(x)\n        y[i] ~ Normal(m * x[i] + c, 1.0)\n    end\nend\n\nThis model right now does not have any observed data: the variable y is not part of the model arguments, nor is it conditioned on any values, so all the y[i]'s are treated as latent variables.\n\nnote: Why do we need to define `y` in the model?\nThe definition of y in the model is needed so that there is somewhere to assign y[i] to after the tilde-statement runs. If we did not define y, we would get an error when trying to call setindex! on an undefined variable.The fact that we defined y within the model does not change this: all variables on the left-hand side of a tilde-statement are treated as latent variables unless explicitly conditioned on or provided as an argument to the model function.\n\nLet's create some synthetic data to work with:\n\ntrue_m, true_c = 5.0, 3.0\n\nx = 0:0.1:0.5\ny_data = true_m .* x .+ true_c .+ randn(length(x))\n\nIf we run the model before conditioning on y, we will find that all of m, c, and y are drawn from the prior distribution.\n\nmodel = linear_regression(x)\n\n# Here, `rand(model())` samples from the prior distribution and returns a\n# VarNamedTuple of latent variables.\nrand(model)\n\nWe could, for example, do this many times, and compute the prior mean of y. This is analogous to using Turing's Prior() sampler.\n\nvnts = [rand(model) for _ in 1:1000]\nmean(vnt[@varname(y)] for vnt in vnts)\n\nThis is useful for prior predictive checks, for example.","category":"section"},{"location":"conditionfix/#Conditioning","page":"Conditioning and fixing","title":"Conditioning","text":"To condition the model on observed data, we can use the condition function, or its alias |. The most robust way of conditioning is to provide a VarNamedTuple that holds the values to condition on.\n\n# Construct a `VarNamedTuple` that holds the conditioning values.\nobservations = @vnt begin\n    y := y_data\nend\n\n# Equivalently: conditioned_model = condition(model, observations).\ncond_model = model | observations\n\nWe can inspect the values that have been conditioned on, using the conditioned function:\n\nconditioned(cond_model)\n\nIf we were to run this model, we would now find that y is an observed variable, and thus it is not sampled:\n\nparameters = rand(cond_model)\n\nWe can't directly draw from the posterior using DynamicPPL (rand still draws from the prior). However, since this is now an observed variable, the log-likelihood associated with the newly provided y will be computed:\n\nloglikelihood(cond_model, parameters)\n\nand this quantity can be used by MCMC algorithms to draw samples from the posterior distribution.","category":"section"},{"location":"conditionfix/#Fixing","page":"Conditioning and fixing","title":"Fixing","text":"Fixing is exactly the same as conditioning, except that instead of incrementing the log-likelihood, there is no log-probability contribution from the fixed variables.\n\nIn essence, fixing a variable x ~ dist to a value x_val is equivalent to replacing the statement with x = x_val, which removes it from the model entirely.\n\nWe can illustrate this by fixing the intercept c to its true value:\n\n# Construct a `VarNamedTuple` that holds the fixed values.\nfix_values = VarNamedTuple(; c=true_c)\n\nfixed_model = fix(model, fix_values)\n\nand sampling from the prior again:\n\nparameters_fixed = rand(fixed_model)\n\nIf we were to repeat this many times, we would find that y is drawn from its prior, but because c is fixed, the samples will reflect that:\n\nmean(vnt[@varname(y)] for vnt in [rand(fixed_model) for _ in 1:1000])","category":"section"},{"location":"conditionfix/#Supplying-parameters-to-condition-or-fix-on","page":"Conditioning and fixing","title":"Supplying parameters to condition or fix on","text":"In the above examples we have provided the conditioning and fixing values as VarNamedTuples. Internally, DynamicPPL stores the values as VarNamedTuples, and it is strongly recommended that you construct them this way.\n\nFor convenience, both condition and fix also accept a variety of different input formats:\n\n# NamedTuple\nmodel | (; y=y_data)\n\n# AbstractDict{VarName}\nmodel | Dict(@varname(y) => y_data)\n\n# Pair\nmodel | (@varname(y) => y_data)\n\nNote, however, that these alternative input formats are not necessarily rich enough to capture all the necessary information. We recommend using VarNamedTuples directly in all cases.\n\nFor example, if you only wanted to condition y[1] but not the other y[i]'s, you cannot specify this via a NamedTuple, since NamedTuples require Symbols as keys.\n\nYou can easily specify this via VarNamedTuple and its helper macro @vnt:\n\nvnt = @vnt begin\n    y[1] := y_data[1]\nend\n\nNote that in this case since the VarNamedTuple has no knowledge of the length or shape of y, DynamicPPL will assume that y is a Base.Vector of unknown length (hence the GrowableArray above).\n\nThis will work fine as long as y is indeed a Base.Vector. However, if you want to avoid this, you should provide the full shape of y when defining the VarNamedTuple:\n\nvnt = @vnt begin\n    @template y = y_data\n    y[1] := y_data[1]\nend\n\nNow, the variable y is known to have the same shape and type as y_data.\n\nwarning: Warning\nIf you use custom array types in DynamicPPL that have different indexing semantics from Base.Array, then the templating shown here becomes mandatory. For example, OffsetArrays may behave incorrectly if templates are not supplied.\n\nIf we run the model again, we should find that y[1] is no longer sampled:\n\ncond_model_partial = model | vnt\nrand(cond_model_partial)","category":"section"},{"location":"conditionfix/#Missing-data","page":"Conditioning and fixing","title":"Missing data","text":"warning: Warning\nThe details in this section are tied closely to internal DynamicPPL details and we recommend that you use the above methods on conditioning on subsets of data. This is merely documented for completeness, and to avoid confusion since these details have been discussed in previous issues and Discourse threads.\n\nSometimes, in order to condition on a part of y, you can in fact condition on a vector y that has some of its entries missing.\n\nFor this to work, it is mandatory that each y[i] is individually on the left-hand side of a tilde-statement, as in the linear regression example above. That means that you can write\n\nfor i in eachindex(x)\n    y[i] ~ Normal(m * x[i] + c, 1.0)\nend\n\nbut not\n\ny ~ MvNormal(m .* x .+ c, I)\n\nThe reason why this works is if DynamicPPL finds a conditioned value of missing, it will treat the variable as not actually being conditioned. When each y[i] is individually on the left-hand side of a tilde-statement, this means that DynamicPPL can identify individual y[i]'s that are missing, and treat them as latent variables.\n\nvnt = @vnt begin\n    y := [missing, missing, 1.0, missing, 2.0, missing]\nend\ncond_model_missing = model | vnt\n\nrand(cond_model_missing)\n\nOn the other hand, if the entire y vector is on the left-hand side of a single tilde-statement, DynamicPPL cannot separate it into its missing and non-missing parts.\n\n","category":"section"},{"location":"flow/#How-data-flows-through-a-model","page":"Model evaluation","title":"How data flows through a model","text":"Having discussed initialisation strategies and accumulators, we can now put all the pieces together to show how data enters a model, is used to perform computations, and how the results are extracted.\n\nThe summary is: initialisation strategies are responsible for telling the model what values to use for its parameters, whereas accumulators act as containers for aggregated outputs.\n\nThus, there is a clear separation between the inputs to the model, and the outputs of the model.\n\nnote: Note\nWhile VarInfo and DefaultContext still exist, this is mostly a historical remnant. DefaultContext means that the inputs should come from the values of the provided VarInfo, and the outputs are stored in the accumulators of the provided VarInfo. However, this can easily be refactored such that the values are provided directly as an initialisation strategy. See this issue for more details.\n\nThere are three stages to every tilde-statement:\n\nInitialisation: get an AbstractTransformedValue from the initialisation strategy.\nComputation: figure out the untransformed (raw) value; compute the log-Jacobian if necessary.\nAccumulation: pass all the relevant information to the accumulators, which individually decide what to do with it.\n\nIn fact this (more or less) directly translates into three lines of code: see e.g. the method for tilde_assume!! in src/onlyaccs.jl, which (as of the time of writing) looks like:\n\nfunction DynamicPPL.tilde_assume!!(ctx::InitContext, dist, vn, template, vi)\n    # 1. Initialisation\n    tval = DynamicPPL.init(ctx.rng, vn, dist, ctx.strategy)\n\n    # 2. Computation\n    # (Though see also the warning in the computation section below.)\n    x, inv_logjac = Bijectors.with_logabsdet_jacobian(\n        DynamicPPL.get_transform(tval), DynamicPPL.get_internal_value(tval)\n    )\n\n    # 3. Accumulation\n    vi = DynamicPPL.accumulate_assume!!(vi, x, tval, -inv_logjac, vn, dist, template)\n    return x, vi\nend\n\nFor tilde_observe!!, the code is very similar, but even easier: the value can be read directly from the data provided to the model, so there is no need for an initialisation step. Since the value is already untransformed, we can skip the second step. Finally, accumulators must behave differently: e.g. incrementing the likelihood instead of the prior. That is accomplished by calling accumulate_observe!! instead of accumulate_assume!!.\n\nIn the following sections, we stick to the three sections of tilde_assume!!.","category":"section"},{"location":"flow/#Initialisation","page":"Model evaluation","title":"Initialisation","text":"tval = DynamicPPL.init(ctx.rng, vn, dist, ctx.strategy)\n\nThe initialisation step is handled by the init function, which dispatches on the initialisation strategy. For example, if ctx.strategy is InitFromPrior(), then init() samples a value from the distribution dist.\n\nnote: Note\nFor DefaultContext, this is replaced by looking for the value stored inside vi. As described above, this can be refactored in the near future.\n\nAs discussed in the Initialisation strategies page, this step, in general, does not return just the raw value (like rand(dist)). It returns an DynamicPPL.AbstractTransformedValue, which represents a value that may have been transformed. In the case of InitFromPrior(), the value is of course not transformed; we return a DynamicPPL.UntransformedValue wrapping the sampled value.\n\nHowever, consider the case where we are using parameters stored inside a VarInfo: the value may have been stored either as a vectorised form, or as a linked vectorised form. In this case, init() will return either a DynamicPPL.VectorValue or a DynamicPPL.LinkedVectorValue.\n\nThe reason why we return this wrapped value is because sometimes we don't want to eagerly perform the transformation. Consider the case where we have an accumulator that attempts to store linked values (this is done precisely when linking a VarInfo: the linked values are stored in an accumulator, which then becomes the basis of the linked VarInfo). In this case, if we eagerly perform the inverse link transformation, we would have to link it again inside the accumulator, which is inefficient!\n\nThe AbstractTransformedValue is passed straight through and is used by both the computation and accumulation steps.","category":"section"},{"location":"flow/#Computation","page":"Model evaluation","title":"Computation","text":"x, inv_logjac = Bijectors.with_logabsdet_jacobian(\n    DynamicPPL.get_transform(tval), DynamicPPL.get_internal_value(tval)\n)\n\nAt some point, we do need to perform the transformation to get the actual raw value. This is because DynamicPPL promises in the model that the variables on the left-hand side of the tilde are actual raw values.\n\n@model function f()\n    x ~ dist\n    # Here, `x` _must_ be the actual raw value.\n    @show x\nend\n\nThus, regardless of what we are accumulating, we will have to unwrap the transformed value provided by init(). We also need to account for the log-Jacobian of the transformation, if any.\n\nnote: Note\nIn principle, if the log-Jacobian is not of interest to any of the accumulators, we could skip computing it here. However, that is not easy to determine in practice. We also cannot defer the log-Jacobian computation to the accumulator, since if multiple accumulators need the log-Jacobian, we would end up computing it multiple times. The current situation of computing it once here is the most sensible compromise (for now).One could envision a future where accumulators declare upfront (via their type) whether they need the log-Jacobian or not. We could then skip computing it if no accumulator needs it.\n\nwarning: Warning\nIf you look at the source code for that method, it is more complicated than the above! Have we lied? It turns out that there is a subtlety here: the transformation obtained from DynamicPPL.get_transform(tval) may in fact be incorrect.Consider the case where a transform is dependent on the value itself (e.g., a variable whose support depends on another variable). In this case, setting new values into a VarInfo (via unflatten!!) may cause the cached transformations to be invalid. Where possible, it is better to re-obtain the transformation from dist, which is always up-to-date since it is obtained from model execution.","category":"section"},{"location":"flow/#Accumulation","page":"Model evaluation","title":"Accumulation","text":"vi = DynamicPPL.accumulate_assume!!(vi, x, tval, -inv_logjac, vn, dist, template)\n\nThis step is where most of the interesting action happens.\n\nAccumulators are described in much more detail on the Accumulators page; please read that for more information!\n\n","category":"section"},{"location":"values/#Storing-values","page":"Storing values","title":"Storing values","text":"","category":"section"},{"location":"values/#The-role-of-VarInfo","page":"Storing values","title":"The role of VarInfo","text":"As described in the model evaluation documentation page, each tilde-statement is split up into three parts:\n\nInitialisation;\nComputation; and\nAccumulation.\n\nUnfortunately, not everything in DynamicPPL follows this clean structure yet. In particular, there is a struct, called VarInfo, which has a dual role in both initialisation and accumulation:\n\nstruct VarInfo{linked,V<:VarNamedTuple,A<:AccumulatorTuple}\n    values::V\n    accs::A\nend\n\nThe values field stores either LinkedVectorValues or VectorValues. The link type parameter can either be true or false, which indicates that all values stored are linked or unlinked, respectively; or it can be nothing, which indicates that it is not known whether the values are linked or unlinked, and must be checked on a case-by-case basis.\n\nHere is an example:\n\nusing DynamicPPL, Distributions\n\n@model function dirichlet()\n    x = zeros(3)\n    return x[1:3] ~ Dirichlet(ones(3))\nend\ndirichlet_model = dirichlet()\nvi = VarInfo(dirichlet_model)\nvi\n\nIn VarInfo, it is mandatory to store LinkedVectorValues or VectorValues as ArrayLikeBlocks (see the Array-like blocks documentation for information on this). The reason is because, if the value is linked, it may have a different size than the number of indices in the VarName. This means that when retrieving the keys, we obtain each block as a single key:\n\nkeys(vi.values)","category":"section"},{"location":"values/#Towards-a-new-framework","page":"Storing values","title":"Towards a new framework","text":"In a VarInfo, the accs field is responsible for the accumulation step, just like an ordinary AccumulatorTuple.\n\nHowever, values serves a dual purpose: it is sometimes used for initialisation (when the model's leaf context is DefaultContext, the AbstractTransformedValue to be used in the computation step is read from it) and it is sometimes also used for accumulation (when linking a VarInfo, we will potentially store a new AbstractTransformedValue in it).\n\nThe path to removing VarInfo is essentially to separate these two roles:\n\nThe initialisation role of varinfo.values can be taken over by an initialisation strategy that wraps it. Recall that the only role of an initialisation strategy is to provide an AbstractTransformedValue via DynamicPPL.init. This can be trivially done by indexing into the VarNamedTuple stored in the strategy.\nThe accumulation role of varinfo.values can be taken over by a new accumulator, which we call TransformedValueAccumulator. The nomenclature here is not especially precise: it does not store AbstractTransformedValues per se, but only two subtypes of it, LinkedVectorValue and VectorValue.\n\nTransformedValueAccumulator is implemented inside src/accs/transformed_value.jl, and additionally includes a link strategy as a parameter: the link strategy is responsible for deciding which values should be stored as LinkedVectorValues and which as VectorValues.\n\nnote: Note\nDecoupling the initialisation from the accumulation also means that we can pair different initialisation strategies with a TransformedValueAccumulator. Previously, to link a VarInfo, you would need to first generate an unlinked VarInfo and then link it. Now, you can directly create a linked VarInfo (i.e., accumulate LinkedVectorValues) by sampling from the prior (i.e., initialise with InitFromPrior).","category":"section"},{"location":"values/#ValuesAsInModelAccumulator","page":"Storing values","title":"ValuesAsInModelAccumulator","text":"Earlier we said that TransformedValueAccumulator stores only two subtypes of AbstractTransformedValue: LinkedVectorValue and VectorValue.\n\nIt is often also useful to store the raw values, i.e., UntransformedValues; but additionally, since UntransformedValues must always correspond exactly to the indices they are assigned to, we can unwrap them and do not need to store them as array-like blocks.\n\nThis is the role of ValuesAsInModelAccumulator.\n\nnote: Note\nThe name is a historical artefact, and can definitely be improved. Suggestions are welcome!\n\noavi = DynamicPPL.OnlyAccsVarInfo()\noavi = DynamicPPL.setaccs!!(oavi, (DynamicPPL.ValuesAsInModelAccumulator(false),))\n_, oavi = DynamicPPL.init!!(dirichlet_model, oavi)\nraw_vals = DynamicPPL.getacc(oavi, Val(:ValuesAsInModel)).values\n\nNote that when we unwrap UntransformedValues, we also lose the block structure that was present in the model. That means that in ValuesAsInModelAccumulator, there is no longer any notion that x[1:3] was set together, so the keys correspond to the individual indices.\n\nkeys(raw_vals)\n\nIn particular, the outputs of ValuesAsInModelAccumulator are used for chain construction. This is why indices are split up in chains.\n\nnote: Note\nIf you have an entire vector stored as a top-level symbol, e.g. x ~ Dirichlet(ones(3)), it will not be broken up (as long as you use FlexiChains).","category":"section"},{"location":"values/#Why-do-we-still-need-to-store-TransformedValues?","page":"Storing values","title":"Why do we still need to store TransformedValues?","text":"Given that ValuesAsInModelAccumulator exists, one may wonder why we still need to store TransformedValues at all, i.e. what the purpose of TransformedValueAccumulator is.\n\nCurrently, the only remaining reason for transformed values is the fact that we may sometimes need to perform DynamicPPL.unflatten!! on a VarInfo, to insert new values into it from a vector.\n\nvi = VarInfo(dirichlet_model)\nvi[@varname(x[1:3])]\n\nvi = DynamicPPL.unflatten!!(vi, [0.2, 0.5, 0.3])\nvi[@varname(x[1:3])]\n\nIf we do not store the vectorised form of the values, we will not know how many values to read from the input vector for each key.\n\nRemoving upstream usage of unflatten!! would allow us to completely get rid of TransformedValueAccumulator and only ever use ValuesAsInModelAccumulator. See this DynamicPPL issue for more information.\n\n","category":"section"},{"location":"vnt/motivation/#Motivation","page":"Motivation","title":"Motivation","text":"When executing a DynamicPPL model, it is very often necessary to store information about the random variables in the model. Consider, e.g.\n\nusing DynamicPPL, Distributions\n\n@model function f1()\n    x ~ Normal(0, 1)\n    y ~ Normal(x, 1)\n    z ~ Normal(y, 1)\n    return nothing\nend\nnothing # hide\n\nWhen we evaluate the model, we want to know the values of x, y, and z (even if the return value of the function is nothing; the return value is typically used for other purposes). Sometimes we might want to store other information about them, like their distributions. This information can be extracted and used by inference algorithms, for example.\n\nIn general this is done by storing some kind of mapping from AbstractPPL.VarNames to values. This is the job of VarNamedTuples, or VNT for short. Before we go into that, let's take a short view back to the past to see various approaches that don't quite work. This will provide a motivation for the design of VNT.","category":"section"},{"location":"vnt/motivation/#Historical-approaches","page":"Motivation","title":"Historical approaches","text":"Julia contains two main data structures for key-value maps: NamedTuples and Dicts.","category":"section"},{"location":"vnt/motivation/#NamedTuple","page":"Motivation","title":"NamedTuple","text":"NamedTuples are extremely lightweight data structures and are completely type stable. For example, in the above, we could store the values in a NamedTuple like so:\n\n(x=0.5, y=1.2, z=-0.3)\nnothing # hide\n\n(or whatever the sampled values are.) The issue with this, however, is that the keys of NamedTuples are symbols. This is fine for variables that are single identifiers (i.e., VarNames with an optic of AbstractPPL.Iden; which we'll call 'identity VarNames').\n\nBut in a model like the following, we have the VarNames x[1], x[2], x[3], and y.a. These cannot be properly converted into Symbols without loss of information, and this makes the output NamedTuple unsuitable for subsequent use.\n\n@model function f2()\n    x = Vector{Float64}(undef, 3)\n    for i in eachindex(x)\n        x[i] ~ Normal()\n    end\n\n    y = (; a=1.0)\n    return y.a ~ Normal()\nend\nnothing # hide\n\nIn the past, there was something called SimpleVarInfo which stored variables in NamedTuples (possibly converting non-identity VarNames to symbols with loss of information). This was a very fast data structure, but was unsuitable for general use.","category":"section"},{"location":"vnt/motivation/#Dict","page":"Motivation","title":"Dict","text":"In order to be completely general, we could use a Dict{VarName, Any}. This allows us to store arbitrary VarNames as keys, and arbitrary values. Again, there was a SimpleVarInfo implementation that used this approach (specifically an OrderedDict).\n\nDict(\n    @varname(x[1]) => 0.5,\n    @varname(x[2]) => -1.2,\n    @varname(x[3]) => 1.7,\n    @varname(y.a) => 0.3,\n)\n\nThe main issue with Dicts is performance. In general there is substantial overhead in hashing and looking up keys in a Dict, compared to NamedTuple field access which is just direct memory access. Furthermore, accessing values is type-unstable (unless all the values can be made to share the same concrete type, which is the case above, but is unrealistic).","category":"section"},{"location":"vnt/motivation/#Metadata-and-VarNamedVector","page":"Motivation","title":"Metadata and VarNamedVector","text":"In an attempt to get around the performance issue, DynamicPPL used to have data structures called Metadata and VarNamedVector. These structures essentially attempted to remove as much overhead as possible from Dicts by flattening their elements (i.e. variable values) and storing vectorised forms of them in contiguous vectors. Furthermore, they were often wrapped in NamedTuples to get some type stability benefits. This approach was somewhat successful and was used for many years: it is also described in the Turing.jl ACM Transactions on Probabilistic Machine Learning paper.\n\nWhile this fixed many performance problems with Dict, at its very core, it is still a mapping of VarNames to values, and therefore suffers from a lack of what we call 'constructiveness'.","category":"section"},{"location":"vnt/motivation/#Constructiveness","page":"Motivation","title":"Constructiveness","text":"This is a very subtle issue, but caused a number of headaches with DynamicPPL. As we will soon see, this is the main motivation behind VNT, and even so VNT does not fully solve it.\n\nConsider the following model:\n\n@model function f3()\n    x = Vector{Float64}(undef, 2)\n    x[1] ~ Normal()\n    return x[2] ~ Normal()\nend\n\nIf at the end of the model we were to ask what the value of x was, we would have no way of knowing this. Let's say we are using a Dict to store the values. We would have something like\n\nd = Dict(@varname(x[1]) => 0.5, @varname(x[2]) => -1.2)\n\nbut attempting to get d[@varname(x)] would return nothing, since there is no such key in the Dict. In fact, we cannot even access x[1:2], despite both indices obviously being defined.\n\nhaskey(d, @varname(x)), haskey(d, @varname(x[1:2]))","category":"section"},{"location":"vnt/motivation/#What's-the-problem-with-this?","page":"Motivation","title":"What's the problem with this?","text":"One issue that a lack of constructiveness causes is when reading information back from a Chains object. MCMCChains.jl, for example, breaks up all variables into its constituent scalar components. Thus, even if you have a multivariate distribution\n\nusing LinearAlgebra\n\n@model function f4()\n    x ~ MvNormal(zeros(2), I)\n    return x\nend\nnothing # hide\n\nsampling from this model would give a chain with keys x[1] and x[2]. When calling functions such as returned or predict on the chain, we have to somehow 'reconstruct' the value of x from its components, so that when executing the model we can use the actual value of x.\n\ninfo: Info\nSome workarounds exist for this (see this PR, and AbstractPPLDistributionsExt).using AbstractPPL\n\nno_dist = AbstractPPL.hasvalue(d, @varname(x))\nwith_dist = AbstractPPL.hasvalue(d, @varname(x), MvNormal(zeros(2), I))\n\n(no_dist, with_dist)\n\nAnother problem was when conditioning on values. In such cases, you had to condition on x in full, rather than its components:\n\nmodel = f4() | Dict(@varname(x) => [1.0, -1.0])  # This would work.\nmodel = f4() | Dict(@varname(x[1]) => 1.0, @varname(x[2]) => -1.0)  # This would not.\n\n(This code block isn't run, because with the current version of DynamicPPL and VNT, both versions will work.)\n\nFinally, we are unable to properly use different indexing schemes. For example, x[1] and x[1,1] mean the same thing if x is a Matrix, but the dictionary will think that they are different VarNames. Fundamentally, the issue is that the indexing semantics inside a Dict are not the same as the indexing semantics inside the model itself.","category":"section"},{"location":"vnt/motivation/#Desiderata","page":"Motivation","title":"Desiderata","text":"In summary, we want a data structure that:\n\nCan store arbitrary VarNames as keys, with arbitrary values.\nIs performant and as type stable where possible. In particular, property access should always be type-stable, and indexing should be type-stable as long as the indexed values are homogeneous in type.\nIs constructive.\n\nVarNamedTuple generally solves these issues, with a few very niche edge cases that will be discussed at the very end.\n\n","category":"section"},{"location":"vnt/arraylikeblocks/#Array-like-blocks","page":"Array-like blocks","title":"Array-like blocks","text":"In a number of VNT use cases, it is necessary to associate multiple indices in a VarNamedTuple with an object that is not necessarily the same number of elements.\n\nConsider, for example, this model:\n\n@model function f()\n    x = zeros(3)\n    return x[1:3] ~ Dirichlet(ones(3))\nend\n\nand suppose we want to store the prior distribution associated with each variable in a VarNamedTuple. With a Dict{VarName,Distribution}, we can do this:\n\nd = Dict{VarName,Distribution}(@varname(x[1:3]) => Dirichlet(ones(3)))\n\nbut we incur all the costs associated with the use of a Dict, as described before.\n\nWith a VarNamedTuple, we cannot store this directly:\n\nvnt.data.x = ... # some array\nvnt.data.x[1:3] = Dirichlet(ones(3))  # will error\n\nbecause Dirichlet is not an array, and setindex! will fail. Nor can we write\n\nvnt.data.x = ... # some array\nvnt.data.x[1:3] .= Dirichlet(ones(3))\n\nbecause although this will not error, it is semantically different: this means that every element x[1], x[2], and x[3] will be assigned the same Dirichlet(ones(3)) object, which is not what we want.\n\nThe current solution to this is to use ArrayLikeBlocks, which are thin wrappers around the actual value, but additionally also store the indices used to set the value. The second and third arguments here are the indices (positional and keyword) used to set the value, and the fourth argument is the size of the block.\n\nusing DynamicPPL, Distributions\nusing DynamicPPL.VarNamedTuples: ArrayLikeBlock\n\nalb = ArrayLikeBlock(Dirichlet(ones(3)), 1:3, (;), (3,))\n\nWe then set this ArrayLikeBlock in all the relevant indices. The extra information in the ArrayLikeBlock allows us to forbid partial indexing into it later on. In particular, we want to ensure that users can only retrieve the entire block at once, and not e.g. just x[1] or x[2:3].","category":"section"},{"location":"vnt/arraylikeblocks/#Getting-and-setting:-in-practice","page":"Array-like blocks","title":"Getting and setting: in practice","text":"As a user you should not have to deal with ArrayLikeBlocks directly. Under the hood, templated_setindex!! will automatically wrap values in ArrayLikeBlocks when necessary:\n\nx = zeros(5)\nvnt = DynamicPPL.templated_setindex!!(\n    VarNamedTuple(), Dirichlet(ones(3)), @varname(x[1:3]), x\n)\n\nYou can access the value again as long as you refer to the full range:\n\nvnt[@varname(x[1:3])]\n\nBecause we provided template information, you can access this via any other combination of indexing, as long as it refers to all three indices:\n\nvnt[@varname(x[begin:(end - 2)])]\n\nHowever, if you try to access only part of the block, you will get an error:\n\nvnt[@varname(x[1])]\n\nFurthermore, if you set a value into any of the indices covered by the block, the entire block is invalidated and thus removed:\n\nvnt = DynamicPPL.templated_setindex!!(vnt, Normal(), @varname(x[2]), x)","category":"section"},{"location":"vnt/arraylikeblocks/#Size-checks","page":"Array-like blocks","title":"Size checks","text":"Currently, when setting any object val as an ArrayLikeBlock, there is a size check: we make sure that the range of indices being set to has the same size as DynamicPPL.VarNamedTuples.vnt_size(val). By default, vnt_size(x) returns Base.size(x).\n\nDynamicPPL.VarNamedTuples.vnt_size(Dirichlet(ones(3)))\n\nThis is what allows us to set a Dirichlet distribution to three indices. However, trying to set the same distribution to two indices will fail:\n\nvnt = DynamicPPL.templated_setindex!!(\n    VarNamedTuple(), Dirichlet(ones(3)), @varname(x[1:2]), zeros(5)\n)\n\nnote: Note\nIn principle, these checks can be removed since if Dirichlet(ones(3)) is set as the prior of x[1:2], then model evaluation will error anyway. Furthermore, if at any point we need to know the size of the block, we can always retrieve it via size(view(parent_array, alb.ix...; alb.kw...)). However, the checks are still here for now.","category":"section"},{"location":"vnt/arraylikeblocks/#Which-parts-of-DynamicPPL-use-array-like-blocks?","page":"Array-like blocks","title":"Which parts of DynamicPPL use array-like blocks?","text":"Simply put, anywhere where we don't store raw values. Some examples follow. (This list is meant to only be illustrative, not exhaustive!)","category":"section"},{"location":"vnt/arraylikeblocks/#VarInfo","page":"Array-like blocks","title":"VarInfo","text":"In VarInfo, we need to be able to store either linked or unlinked values (in general, AbstractTransformedValues). These are always vectorised values, and the linked and unlinked vectors may have different sizes (this is indeed the case for Dirichlet distributions). This means that we have to collectively assign multiple indices in the VarNamedTuple to a single vector, which may or may not have the same size as the indices.\n\n@model function dirichlet()\n    x = zeros(3)\n    return x[1:3] ~ Dirichlet(ones(3))\nend\ndirichlet_model = dirichlet()\nvi = VarInfo(dirichlet_model)\nvi.values\n\nThis means that in the actual VarInfo we do not have a notion of what x[1] is:\n\nvi[@varname(x[1])]\n\nSee the documentation on storing values for more details.","category":"section"},{"location":"vnt/arraylikeblocks/#Prior-distributions","page":"Array-like blocks","title":"Prior distributions","text":"In extract_priors we use a VNT to store the prior distributions seen at each point in the model. This is exactly the same use case as in the introduction.\n\nDynamicPPL.extract_priors(dirichlet_model)","category":"section"},{"location":"vnt/arraylikeblocks/#LogDensityFunction","page":"Array-like blocks","title":"LogDensityFunction","text":"DynamicPPL.LogDensityFunction has to retain information about whether each VarNames is linked or not, and the indices in the vectorised parameters that correspond to each variable.\n\nFor example, consider creating a linked LogDensityFunction for (a slightly expanded version of) the Dirichlet model above:\n\n@model function expanded_dirichlet()\n    x = zeros(4)\n    x[1] ~ Normal()\n    return x[2:4] ~ Dirichlet(ones(3))\nend\nmodel = expanded_dirichlet()\n\nvi = VarInfo(model)\nlinked_vi = DynamicPPL.link!!(vi, model)\nldf = LogDensityFunction(model, DynamicPPL.getlogjoint_internal, linked_vi)\nnothing # hide\n\nWhen linking a Dirichlet(ones(3)), the resulting vector will have length 2. So, the LogDensityFunction takes in a vector of length 3, for which the first index belongs to x[1], and the next two indices belong to the linked parameters for x[2:4]. Furthermore, it needs to remember that all the variables have been linked. We can see that this is exactly how the LogDensityFunction has stored the information:\n\nldf._varname_ranges\n\nnote: Note\nFrom the example above, we can see that indexing into this PartialArray is necessarily type-unstable (since the element type is Any). This immediately suggests a performance optimisation for the user: do not mix and match different kinds of distributions within the same vector. For example, if all the x[i]'s were distributed according to univariate distributions, this would not be an issue.\n\n","category":"section"},{"location":"accumulators/#Accumulators","page":"Accumulators","title":"Accumulators","text":"Accumulators are objects in DynamicPPL which collect the results of computations in each tilde-statement.\n\nConsider a tilde-statement x ~ Beta(2, 2). There are several things going on in here (we will discuss this in full detail in the Model evaluation page). Loosely speaking:\n\nWe need to get a value for x that is consistent with the distribution Beta(2, 2);\nThat value may or may not be transformed to linked space;\nWe need to calculate the log-density of that value.\n\nOn top of that, we may want to store other information, such as:\n\nThe VarName itself, i.e. @varname(x);\nThe distribution;\n\nand so on.\n\nThese pieces of information are collected by accumulators. Each different accumulator is responsible for a different piece of information: thus, for example, log-likelihoods and log-priors are collected in separate accumulators. By choosing the right set of accumulators, we can control what information is collected during model evaluation. This allows us to perform exactly the necessary amount of computation we need to do.\n\nFurthermore, accumulators are completely independent: inside the accumulate_...!! method of an accumulator, it is not possible to access the state of other accumulators. This creates a modular design, where new accumulators can be defined and added without worrying about potential interactions with existing ones.","category":"section"},{"location":"accumulators/#The-AbstractAccumulator-API","page":"Accumulators","title":"The AbstractAccumulator API","text":"Accumulators must subtype DynamicPPL.AbstractAccumulator, whose docstring explains the required interface:\n\nThe reason each accumulator must have a different name is because (for type stability reasons) accumulators are stored in a NamedTuple, and Julia requires that the names of fields in a NamedTuple be unique.\n\nreset is called when starting a new model evaluation, to ensure that previously accumulated results do not affect the current evaluation.\n\nThe central two methods though are accumulate_assume!! and accumulate_observe!!. These two methods are called whenever a tilde-statement is encountered during model evaluation. As can be seen from their signatures, they receive all the information that we have discussed above about tilde-statements.\n\nFormally, accumulators can be seen as a monoidal structure where:\n\nreset specifies the identity (indeed for some accumulators in DynamicPPL we define a function called zero);\naccumulate_assume!! and accumulate_observe!! collectively specify the binary operation;\nthe accumulated result is a fold over all tilde-statements in the model.\n\nNote that there is no guarantee that the binary operation be commutative (although in practice for many accumulators it is).","category":"section"},{"location":"accumulators/#An-example","page":"Accumulators","title":"An example","text":"As an example, let's consider an accumulator that associates VarNames with their log-densities. We will store these in an OrderedDict{VarName,Tuple{Bool,Float64}} where the Bool indicates whether the variable was observed (true) or assumed (false), and the Float64 is the log-density.\n\nnote: Note\nThis is very similar to the pointwise_logdensities functionality in DynamicPPL.\n\nWe define the accumulator as follows. As one may have guessed from the above, much of the definition is really just boilerplate to make things run smoothly. The interesting behaviour is in the two accumulate_...!! methods, where we compute the log-density and store it in the OrderedDict.\n\nusing DynamicPPL, OrderedCollections, Distributions\n\nstruct VarNameLogpAccumulator <: DynamicPPL.AbstractAccumulator\n    logps::OrderedDict{VarName,Tuple{Bool,Float64}}\n\n    VarNameLogpAccumulator() = new(OrderedDict{VarName,Tuple{Bool,Float64}}())\nend\n\n# Note, it's a good idea to define the symbol as a top-level `const`, since it's often\n# necessary to refer to it elsewhere. We'll see this happen later.\nconst VARNAMELOGP_NAME = :VarNameLogp\nDynamicPPL.accumulator_name(::VarNameLogpAccumulator) = VARNAMELOGP_NAME\nDynamicPPL.reset(acc::VarNameLogpAccumulator) = VarNameLogpAccumulator()\nDynamicPPL.copy(acc::VarNameLogpAccumulator) = VarNameLogpAccumulator(copy(acc.logps))\n\nfunction DynamicPPL.accumulate_assume!!(\n    acc::VarNameLogpAccumulator,\n    val,\n    tval,\n    logjac,\n    vn::VarName,\n    dist::Distribution,\n    template,\n)\n    acc.logps[vn] = (false, logpdf(dist, val))\n    return acc\nend\n\nfunction DynamicPPL.accumulate_observe!!(acc::VarNameLogpAccumulator, dist, val, vn)\n    acc.logps[vn] = (true, logpdf(dist, val))\n    return acc\nend\n\nIn this implementation, our accumulate_...!! methods actually mutate the accumulator in place. This is not mandatory; you can return a new accumulator if you prefer an immutable style.\n\nTo use this accumulator in a model evaluation, we need to add it into a VarInfo. We can either do this by creating a VarInfo from scratch, or by calling DynamicPPL.setacc!! or DynamicPPL.setaccs!! on an existing VarInfo.\n\nnote: Note\nThese two functions have very similar names, so be careful to use the right one! setacc!! adds a single accumulator to a VarInfo, whereas setaccs!! replaces all the VarInfo's accumulators with a new set.\n\nIn this example, we'll create a VarInfo from scratch using only our new accumulator. To minimise the computational overhead, we use an OnlyAccsVarInfo, which is a slimmed down version of a VarInfo that only contains accumulators. (This is a minor detail; don't worry about it if you aren't familiar with VarInfo types.) Once we've evaluated the model, we can access the accumulated log-densities by reading it back from the accumulator:\n\n@model function f(y)\n    x ~ Normal()\n    return y ~ Normal(x)\nend\nmodel = f(2.0)\n\nvi = DynamicPPL.OnlyAccsVarInfo((VarNameLogpAccumulator(),))\n_, vi = DynamicPPL.init!!(model, vi, InitFromParams((; x=1.0)))\n\n# This is why we used a const.\noutput_acc = DynamicPPL.getacc(vi, Val(VARNAMELOGP_NAME))\n\nSince we specified that x should be initialised to 1.0, we should have that\n\noutput_acc.logps[@varname(x)] == (false, logpdf(Normal(), 1.0))\n\nand\n\noutput_acc.logps[@varname(y)] == (true, logpdf(Normal(1.0), 2.0))\n\n(Notice that because here we used an OrderedDict, the accumulation process is not commutative.)","category":"section"},{"location":"accumulators/#Thread-safe-accumulation","page":"Accumulators","title":"Thread-safe accumulation","text":"DynamicPPL contains a 'thread-safe model evaluation mode', which can be accessed by calling DynamicPPL.setthreadsafe on a model.\n\n@model function g(y)\n    x ~ Normal()\n    Threads.@threads for i in eachindex(y)\n        y[i] ~ Normal(x)\n    end\nend\ny = [2.0, 3.0, 4.0]\nmodel = setthreadsafe(g(y), true)\n\nThis is accomplished by creating one copy of each accumulator per thread (using DynamicPPL.split), and then after the model evaluation is complete, merging the result of each thread's accumulator with DynamicPPL.combine.\n\nEach accumulator sees only the tilde-statements that were executed on its own thread. However, the intent is that after merging the results from all threads, the final accumulator should be equivalent to what would have been obtained by a single-threaded evaluation (modulo ordering). Because the accumulation process is not always commutative, you may in general end up with a different ordering of results. However, for many accumulators such as log-probability accumulators, this is not an issue.\n\nWe can see this in action if we step through the internal DynamicPPL calls. (Note that calling DynamicPPL.evaluate!! on a model where thread-safe mode has been enabled will automatically perform these steps for you.)\n\nThreads.nthreads()\n\nvi = DynamicPPL.OnlyAccsVarInfo((DynamicPPL.LogLikelihoodAccumulator(),))\ntsvi = DynamicPPL.ThreadSafeVarInfo(vi)\ntsvi.accs_by_thread\n\n(Here it actually creates a vector of length maxthreadid(). This is slightly hacky, see the warning below and links therein for more discussion.)\n\nx = 1.0\nmodel = setleafcontext(model, DynamicPPL.InitContext(InitFromParams((; x=x))))\n_, tsvi = DynamicPPL._evaluate!!(model, tsvi)\ntsvi.accs_by_thread\n\nIn the above output, the accumulators that have non-zero log-likelihoods are the ones corresponding to the threads that executed tilde-statements.\n\nFinally, to collapse the per-thread accumulators into a single accumulator, we can call getacc. This does the combine step for us.\n\noutput_acc = DynamicPPL.getacc(tsvi, Val(:LogLikelihood))\n\nWe can check whether this is correct:\n\noutput_acc.logp ≈ sum(logpdf.(Normal(x), y))\n\nwarning: Warning\nThe current implementation of thread safety, with one accumulator per thread, is not fully safe since it relies on indexing into a vector with threadid(). See this issue for details. In practice, though, we have not observed any problems with the current approach.There is also a possibility that DynamicPPL may shift to using 'atomic' accumulators in the future, where only one set of accumulators is maintained, but modifications to it must be performed atomically. See this draft PR for details.\n\nIgnoring the caveats above, it can be generally said that any output that is obtained from an accumulator can be accumulated correctly in a thread-safe manner. In other words, full thread safety in DynamicPPL is possible as long as all the outputs you need are obtained from accumulators.\n\nThe main situation where this is not yet true is when using a full VarInfo, which stores a VarNamedTuple in its varinfo.values field. Modifications to this field are currently not thread-safe. However, the values VNT is entirely equivalent to a VectorValueAccumulator. In the near future it should be possible to use a OnlyAccsVarInfo with a VectorValueAccumulator instead of a full VarInfo, which would allow DynamicPPL to be fully thread-safe.\n\n","category":"section"},{"location":"accumulators/#DynamicPPL.AbstractAccumulator-accumulators","page":"Accumulators","title":"DynamicPPL.AbstractAccumulator","text":"AbstractAccumulator\n\nAn abstract type for accumulators.\n\nAn accumulator is an object that may change its value at every tildeassume!! or tildeobserve!! call based on the random variable in question. The obvious examples of accumulators are the log prior and log likelihood. Other examples might be a variable that counts the number of observations in a trace, or a list of the names of random variables seen so far.\n\nAn accumulator type T <: AbstractAccumulator must implement the following methods:\n\naccumulator_name(acc::T) or accumulator_name(::Type{T})\naccumulate_observe!!(acc::T, dist, val, vn)\naccumulate_assume!!(acc::T, val, tval, logjac, vn, dist, template)\nreset(acc::T)\nBase.copy(acc::T)\n\nIn these functions:\n\nval is the new value of the random variable sampled from a distribution (always in the original unlinked space), or the value on the left-hand side of an observe statement.\ntval is the original AbstractTransformedValue that was obtained from the initialisation strategy. This is passed through unchanged to accumulate_assume!! since it can be reused for some accumulators (e.g. when storing linked values, if the linked value was already provided, it is faster to reuse it than to re-link val).\ndist is the distribution on the RHS of the tilde statement.\nvn is the VarName that is on the left-hand side of the tilde-statement. If the tilde-statement is a literal observation like 0.0 ~ Normal(), then vn is nothing.\nlogjac is the log determinant of the Jacobian of the link transformation, if the variable is stored as a linked value in the VarInfo. If the variable is stored in its original, unlinked form, then logjac is zero.\ntemplate is a value that conveys the shape of the top-level symbol in vn, and is used specifically for accumulators that carry VarNamedTuples.\n\nTo be able to work with multi-threading, it should also implement:\n\nsplit(acc::T)\ncombine(acc::T, acc2::T)\n\nSee the documentation for each of these functions for more details.\n\n\n\n\n\n","category":"type"},{"location":"vnt/implementation/#Implementation","page":"Implementation","title":"Implementation","text":"Having discussed what a VarNamedTuple should look like, we now turn our attention to how it is constructed. The core entry point is a function called _setindex_optic!!, which essentially says: 'set the value that can be accessed using this optic, creating it if necessary'. For example,\n\nusing AbstractPPL, DynamicPPL\nusing DynamicPPL.VarNamedTuples: NoTemplate, _setindex_optic!!\n\ncollection = VarNamedTuple()\n_setindex_optic!!(collection, 1.0, @opticof(_.x[1].a), NoTemplate())\n\nmeans: 'modify this collection such that the value at the path _.x[1].a is set to 1.0, creating any missing structure along the way, and with no template provided.'\n\nNotice that, if collection is the top-level VarNamedTuple being used to hold variable values, this is the same as saying \"add the VarName @varname(x[1].a) with value 1.0 to the VarNamedTuple vnt\". Indeed, BangBang.setindex!!(vnt, 1.0, @varname(x[1].a)) directly calls the above.\n\nIf a template is provided, it must be for the entire structure being created, that is, the template should be the shape of vnt.\n\ninfo: Info\nWhen we called templated_setindex!!, we said that the template should be for the top-level symbol, i.e. x. It seems like we are introducing an inconsistency here, since the template above would be for the entire structure. That is why templated_setindex!! does not pass the template as-is; it wraps the template in one level of SkipTemplate{1}(template), which effectively means 'don't use a template for the first level, then use it for the next'.\n\nBecause VarNames have a nested structure, it should not be surprising to find that VarNamedTuples are constructed by recursing into _setindex_optic!!. For an optic like _.x[1].a, the strategy is as follows:\n\nLook at the outermost layer of the optic (.x above).\nIf collection already has a value for that layer (i.e. a property called x), get that sub-value, and call _setindex_optic!! on that sub-value with the rest of the optic ([1].a above).\nIf not, call the function make_leaf, which constructs the necessary sub-structure, using any template provided.\n\nmake_leaf is itself of course also recursive, and is where the bulk of the complicated logic occurs.","category":"section"},{"location":"vnt/implementation/#Making-leaves","page":"Implementation","title":"Making leaves","text":"Following on from the explanation above, it follows that make_leaf(value, optic, template) is responsible for creating a new structure s, which already holds value at the path specified by optic. If a template is provided, s should be constructed to match the shape and type of template.\n\nLet's build this up using some simple examples to illustrate the idea, first ignoring any templates.\n\nHere, this is an identity optic, which is the base case. Of course, the value itself (1.0) can be indexed into with the identity optic to give itself. So we can just return the value.\n\nusing DynamicPPL.VarNamedTuples: make_leaf\n\nmake_leaf(1.0, @opticof(_), NoTemplate())\n\nNext, consider a field optic like _.a. To create a structure that holds 1.0 at that path, we can create a VarNamedTuple with a single field a set to 1.0.\n\nmake_leaf(1.0, @opticof(_.a), NoTemplate())\n\nFinally, consider an index optic like _[3]. Since no template is provided, we will need to make a guess: in this case it will be a 1-dimensional GrowableArray, with a size of at least 3.\n\nl = make_leaf(1.0, @opticof(_[3]), NoTemplate())\n# l isa PartialArray, which is quite boring to print, so let's peek inside it.\ntypeof(l.data), l.data, l.mask\n\nConversely, if a template is provided, we'll just use that directly. (But we still have to make sure to set the value at the correct index!)\n\nl = make_leaf(1.0, @opticof(_[3]), zeros(4))\nl.data, l.mask\n\nNow, consider a recursive case, like @opticof(_.a.b). make_leaf needs to create something which can hold 1.0 at the path .a.b.\n\nTo do so, it first has to create the sub-structure that will hold 1.0 at .b, and then it can create an outer structure that holds that sub-structure at .a.\n\nmake_leaf(1.0, @opticof(_.a.b), NoTemplate())\n\nThis should conceptually be fairly understandable. Here is a simplified version of the recursive implementation:\n\n# Let's say `optic` is _[1].a\nfunction make_leaf(leaf_value, optic, template)\n    this_optic, child_optic = split_optic(optic)\n    # ^ _[1]    ^ _.a \n\n    sub_value = make_leaf(leaf_value, child_optic, child(template))\n    # ^ VNT                           ^ _.a        ^ template[1]\n\n    empty_value = create_empty_structure(this_optic, template)\n    # ^ PA                               ^ _[1]\n\n    value = setindex!!(empty_value, this_optic, sub_value)\n    # ^ PA->VNT        ^ PA         ^ _.[1]     ^ VNT\n\n    return value\nend\n\nSome explanatory notes:\n\nThe whole purpose of the function is to ensure that value is something where you can index into with optic to get leaf_value.\nSince sub_value is also created with the same function, that means it must be something you can index into with child_optic to get leaf_value.\nempty_value needs to be something that can hold sub_value at this_optic. We don't yet insert the data. However, to ensure type stability, we should instantiate the PA with the correct element type: in this case that's just typeof(sub_value). (If we don't use the correct element type, the subsequent call to setindex!! will have to change the element type of the PA.)\nvalue is then created by putting sub_value into empty_value at this_optic.\n\ninfo: Info\nRegarding point (3): we haven't yet covered ArrayLikeBlocks (that will be on the next page). If sub_value is something that would be stored as an ArrayLikeBlock, we need to instantiate empty_value with typeof(ArrayLikeBlock(sub_value)) instead of typeof(sub_value), again for type stability reasons. If you are not familiar with this, don't worry about it for now.","category":"section"},{"location":"vnt/implementation/#Multi-indices","page":"Implementation","title":"Multi-indices","text":"Multi-indexing, or slices, is where things get a bit more complicated, as it enforces extra constraints that are not present above. To illustrate this, we'll now consider the case where the optic is _[2:3][1].\n\nLogically speaking, this is exactly the same as _[2]. So we should be creating a PartialArray that holds leaf_value at index 2. But on top of that, we also need to make sure that the created structure has at least three indices: otherwise, the index 2:3 would be invalid.\n\n# Let's say `optic` is _[2:3][1]\nfunction make_leaf(leaf_value, optic, template)\n    this_optic, child_optic = split_optic(optic)\n    # ^ _[2:3]  ^ _[1]\n\n    sub_value = make_leaf(leaf_value, child_optic, child(template))\n    # ^ PA (x)                        ^ _[1]       ^ template[2:3]\n\n    empty_value = create_empty_structure(this_optic, template)\n    # ^ PA (y)                           ^ _[2:3]\n\n    value = setindex!!(empty_value, this_optic, sub_value)\n    # ^ PA (z)         ^ PA (y)     ^ _[2:3]    ^ PA (x)   \n\n    return value\nend\n\nThere are three PartialArrays being created here, which are called x, y, and z in the comments above.\n\nThe first point of difference is when creating empty_value: previously, for type stability purposes, we would create the PA with an element type of typeof(sub_value). However, in this case, sub_value is actually a slice of empty_value, and so we can't use its type: we need to use eltype(sub_value) instead.\n\nThe other tricky part is about lengths. Let's work backwards from the last line. z and y will have the same length, since they are related by the setindex!! call. They must be at least of length 3. This is easy to guarantee: when creating y, we either have a template to work with (which must already be of more than length 3), or we can use a GrowableArray and deduce the minimum length from the index 2:3.\n\nHowever, x must also exactly have length 2; otherwise, when setting it into the indices 2:3 of y, an error will occur. This part is more problematic, because the recursive call to make_leaf only ever sees the index 1. If it doesn't have a template to work with, this will error, because it will create a GrowableArray of length 1, which cannot then be set into indices 2:3 of y.\n\n(If it does have a template, we are all good, because the template will be created by indexing into the upper-level template with 2:3, which will give a template of the right size.)\n\nTo solve this, we have two choices:\n\nRecursively pass down information about the expected size of the template; or\nAfter getting sub_value, check if this_index is a multi-index, and if so, expand sub_value to the correct length.\n\nThe current implementation uses the second approach. Note that this is only needed when there is no template provided, and when there is a multi-index.","category":"section"},{"location":"vnt/implementation/#Detecting-multi-indices","page":"Implementation","title":"Detecting multi-indices","text":"This means that in general we need a good way of differentiating between single-element indexing and multi-element indexing. One could iterate over the indices and check which of them are ranges or colons, for example; however, that's not general and doesn't allow for user-defined indices or arbitrary index types. (Of course, if there is no template, then we do fall back on that approach.)\n\nThe solution is this helper function, which is used liberally throughout the VarNamedTuple implementation:\n\nfunction _is_multiindex(template::AbstractArray, ix...; kw...)\n    return ndims(view(template, ix...; kw...)) > 0\nend\n\nwhich works really well across different array types, and is frequently (if not always?) constant propagated.\n\nusing DimensionalData;\nusing InteractiveUtils: @code_warntype;\n\nda = DimArray(randn(2, 3), (X(), :y));\n@code_warntype _is_multiindex(da; a=X(Not(2)), y=2)\n\n","category":"section"},{"location":"api/#API","page":"API","title":"API","text":"Part of the API of DynamicPPL is defined in the more lightweight interface package AbstractPPL.jl and reexported here.","category":"section"},{"location":"api/#Model","page":"API","title":"Model","text":"","category":"section"},{"location":"api/#Macros","page":"API","title":"Macros","text":"A core component of DynamicPPL is the @model macro. It can be used to define probabilistic models in an intuitive way by specifying random variables and their distributions with ~ statements. These statements are rewritten by @model as calls of internal functions for sampling the variables and computing their log densities.","category":"section"},{"location":"api/#Type","page":"API","title":"Type","text":"A Model can be created by calling the model function, as defined by @model.\n\nModels are callable structs.\n\nBasic properties of a model can be accessed with getargnames, getmissings, and nameof.\n\nThe context of a model can be set using contextualize:\n\nSome models require threadsafe evaluation (see the Turing docs for more information on when this is necessary). If this is the case, one must enable threadsafe evaluation for a model:","category":"section"},{"location":"api/#Evaluation","page":"API","title":"Evaluation","text":"With rand one can draw samples from the prior distribution of a Model.\n\nOne can also evaluate the log prior, log likelihood, and log joint probability.","category":"section"},{"location":"api/#LogDensityProblems.jl-interface","page":"API","title":"LogDensityProblems.jl interface","text":"The LogDensityProblems.jl interface is also supported by wrapping a Model in a DynamicPPL.LogDensityFunction.\n\nInternally, this is accomplished using init!! on:","category":"section"},{"location":"api/#Condition-and-decondition","page":"API","title":"Condition and decondition","text":"A Model can be conditioned on a set of observations with AbstractPPL.condition or its alias |.\n\nSimilarly, one can specify with AbstractPPL.decondition that certain, or all, random variables are not observed.","category":"section"},{"location":"api/#Fixing-and-unfixing","page":"API","title":"Fixing and unfixing","text":"We can also fix a collection of variables in a Model to certain values using DynamicPPL.fix.\n\nThis is quite similar to the aforementioned condition and its siblings, but they are indeed different operations:\n\nconditioned variables are considered to be observations, and are thus included in the computation logjoint and loglikelihood, but not in logprior.\nfixed variables are considered to be constant, and are thus not included in any log-probability computations.\n\nThe differences are more clearly spelled out in the docstring of DynamicPPL.fix below.\n\nThe difference between DynamicPPL.fix and DynamicPPL.condition is described in the docstring of DynamicPPL.fix above.\n\nSimilarly, we can revert this with DynamicPPL.unfix, i.e. return the variables to their original meaning:","category":"section"},{"location":"api/#Predicting","page":"API","title":"Predicting","text":"DynamicPPL provides functionality for generating samples from the posterior predictive distribution through the predict function. This allows you to use posterior parameter samples to generate predictions for unobserved data points.\n\nThe predict function has two main methods:\n\nFor AbstractVector{<:AbstractVarInfo} - useful when you have a collection of VarInfo objects representing posterior samples.\nFor MCMCChains.Chains (only available when MCMCChains.jl is loaded) - useful when you have posterior samples in the form of an MCMCChains.Chains object.","category":"section"},{"location":"api/#Basic-Usage","page":"API","title":"Basic Usage","text":"The typical workflow for posterior prediction involves:\n\nFitting a model to observed data to obtain posterior samples\nCreating a new model instance with some variables marked as missing (unobserved)\nUsing predict to generate samples for these missing variables based on the posterior parameter samples\n\nWhen using predict with MCMCChains.Chains, you can control which variables are included in the output with the include_all parameter:\n\ninclude_all=false (default): Include only newly predicted variables\ninclude_all=true: Include both parameters from the original chain and predicted variables","category":"section"},{"location":"api/#Marginalisation","page":"API","title":"Marginalisation","text":"DynamicPPL provides the marginalize function to marginalise out variables from a model. This requires MarginalLogDensities.jl to be loaded in your environment.\n\nA MarginalLogDensity object acts as a function which maps non-marginalised parameter values to a marginal log-probability. To retrieve a VarInfo object from it, you can use:","category":"section"},{"location":"api/#Models-within-models","page":"API","title":"Models within models","text":"One can include models and call another model inside the model function with left ~ to_submodel(model).\n\nNote that a [to_submodel](@ref) is only sampleable; one cannot compute logpdf for its realizations.\n\nIn the context of including models within models, it's also useful to prefix the variables in sub-models to avoid variable names clashing:","category":"section"},{"location":"api/#Utilities","page":"API","title":"Utilities","text":"typed_identity is the same as identity, but with an overload for with_logabsdet_jacobian that ensures that it never errors.\n\nIt is possible to manually increase (or decrease) the accumulated log likelihood or prior from within a model function.\n\nReturn values of the model function can be obtained with returned(model, sample), where sample is either a MCMCChains.Chains object (which represents a collection of samples), or a single sample represented as a NamedTuple or a dictionary of VarNames.\n\nFor a chain of samples, one can compute the pointwise log-likelihoods of each observed random variable with pointwise_loglikelihoods. Similarly, the log-densities of the priors using pointwise_prior_logdensities or both, i.e. all variables, using pointwise_logdensities.\n\nFor converting a chain into a format that can more easily be fed into a Model again, for example using condition, you can use value_iterator_from_chain.\n\nSometimes it can be useful to extract the priors of a model. This is the possible using extract_priors.\n\nSafe extraction of values from a given AbstractVarInfo as they are seen in the model can be done using values_as_in_model.","category":"section"},{"location":"api/#AD-testing-and-benchmarking-utilities","page":"API","title":"AD testing and benchmarking utilities","text":"To test and/or benchmark the performance of an AD backend on a model, DynamicPPL provides the following utilities:\n\nThe default test setting is to compare against ForwardDiff. You can have more fine-grained control over how to test the AD backend using the following types:\n\nThese are returned / thrown by the run_ad function:","category":"section"},{"location":"api/#Demo-models","page":"API","title":"Demo models","text":"DynamicPPL provides several demo models in the DynamicPPL.TestUtils submodule.\n\nFor every demo model, one can define the true log prior, log likelihood, and log joint probabilities.\n\nAnd in the case where the model includes constrained variables, it can also be useful to define\n\nFinally, the following methods can also be of use:","category":"section"},{"location":"api/#Debugging-Utilities","page":"API","title":"Debugging Utilities","text":"DynamicPPL provides a few methods for checking validity of a model-definition.\n\nAnd some which might be useful to determine certain properties of the model based on the debug trace.\n\nFor determining whether one might have type instabilities in the model, the following can be useful\n\nInterally, the type-checking methods make use of the following method for construction of the call with the argument types:","category":"section"},{"location":"api/#Advanced","page":"API","title":"Advanced","text":"","category":"section"},{"location":"api/#Variable-names","page":"API","title":"Variable names","text":"Names and possibly nested indices of variables are described with AbstractPPL.VarName. They can be defined with AbstractPPL.@varname. Please see the documentation of AbstractPPL.jl for further information.","category":"section"},{"location":"api/#Data-Structures-of-Variables","page":"API","title":"Data Structures of Variables","text":"DynamicPPL provides a data structure for storing samples and accumulation of the log-probabilities, called VarInfo. The interface that VarInfo respects is described by the abstract type AbstractVarInfo. Internally DynamicPPL also uses a couple of other subtypes of AbstractVarInfo.\n\nOne main characteristic of VarInfo is that samples are transformed to unconstrained Euclidean space and stored in a linearized form, as described in the main Turing documentation. The Transformations section below describes the methods used for this. In the specific case of VarInfo, it keeps track of whether samples have been transformed by setting flags on them, using the following functions.","category":"section"},{"location":"api/#VarNamedTuples","page":"API","title":"VarNamedTuples","text":"VarInfo is only a thin wrapper around VarNamedTuple, which stores arbitrary data keyed by VarNames. For more details on VarNamedTuple, see the Internals section of our documentation.\n\nVarNamedTuple provides a Dict-like interface, so you can iterate over keys(vnt), values(vnt), and pairs(vnt). You can also use getindex(vnt, key), but setindex! is not allowed: all changes to a VarNamedTuple must be done via setindex!! or templated_setindex!!. Please see the VarNamedTuple documentation for more details.\n\nYou can convert a VarNamedTuple to a NamedTuple in the case where all keys are VarNames with identity optics.","category":"section"},{"location":"api/#Accumulators","page":"API","title":"Accumulators","text":"The subtypes of AbstractVarInfo store the cumulative log prior and log likelihood, and sometimes other variables that change during executing, in what are called accumulators.\n\nDynamicPPL provides the following default accumulators.","category":"section"},{"location":"api/#Common-API","page":"API","title":"Common API","text":"","category":"section"},{"location":"api/#Accumulation-of-log-probabilities","page":"API","title":"Accumulation of log-probabilities","text":"","category":"section"},{"location":"api/#Variables-and-their-realizations","page":"API","title":"Variables and their realizations","text":"","category":"section"},{"location":"api/#Transformations","page":"API","title":"Transformations","text":"","category":"section"},{"location":"api/#Utils","page":"API","title":"Utils","text":"","category":"section"},{"location":"api/#Evaluation-Contexts","page":"API","title":"Evaluation Contexts","text":"Internally, model evaluation is performed with AbstractPPL.evaluate!!.\n\nThis method mutates the varinfo used for execution. By default, it does not perform any actual sampling: it only evaluates the model using the values of the variables that are already in the varinfo. If you wish to sample new values, see the section on VarInfo initialisation just below this.\n\nThe behaviour of a model execution can be changed with evaluation contexts, which are a field of the model.\n\nAll contexts are subtypes of AbstractPPL.AbstractContext.\n\nContexts are split into two kinds:\n\nLeaf contexts: These are the most important contexts as they ultimately decide how model evaluation proceeds. For example, DefaultContext evaluates the model using values stored inside a VarInfo's metadata, whereas InitContext obtains new values either by sampling or from a known set of parameters. DynamicPPL has more leaf contexts which are used for internal purposes, but these are the two that are exported.\n\nTo implement a leaf context, you need to subtype AbstractPPL.AbstractContext and implement the tilde_assume!! and tilde_observe!! methods for your context.\n\nParent contexts: These essentially act as 'modifiers' for leaf contexts. For example, PrefixContext adds a prefix to all variable names during evaluation, while CondFixContext marks certain variables as being either conditioned or fixed.\n\nTo implement a parent context, you have to subtype DynamicPPL.AbstractParentContext, and implement the childcontext and setchildcontext methods. If needed, you can also implement tilde_assume!! and tilde_observe!! for your context. This is optional; the default implementation is to simply delegate to the child context.\n\nSince contexts form a tree structure, these functions are automatically defined for manipulating context stacks. They are mainly useful for modifying the fundamental behaviour (i.e. the leaf context), without affecting any of the modifiers (i.e. parent contexts).","category":"section"},{"location":"api/#VarInfo-initialisation","page":"API","title":"VarInfo initialisation","text":"The function init!! is used to initialise, or overwrite, values in a VarInfo. It is really a thin wrapper around using evaluate!! with an InitContext.\n\nTo accomplish this, an initialisation strategy is required, which defines how new values are to be obtained. There are three concrete strategies provided in DynamicPPL:\n\nIf you wish to write your own, you have to subtype DynamicPPL.AbstractInitStrategy and implement the init method. In very rare situations, you may also need to implement get_param_eltype, which defines the element type of the parameters generated by the strategy.\n\nThe function DynamicPPL.init should return an AbstractTransformedValue. There are three subtypes currently available:\n\nThe interface for working with transformed values consists of:","category":"section"},{"location":"api/#Converting-VarInfos-to/from-chains","page":"API","title":"Converting VarInfos to/from chains","text":"It is a fairly common operation to want to convert a collection of VarInfo objects into a chains object for downstream analysis.\n\nThis can be accomplished by first converting each VarInfo into a ParamsWithStats object:\n\nOnce you have a matrix of these, you can convert them into a chains object using:\n\nIf you only have a vector you can use hcat to convert it into an N×1 matrix first.\n\nFurthermore, one can convert chains back into a collection of parameter dictionaries and/or stats with:\n\nWith these, you can (for example) extract the parameter dictionaries and use InitFromParams to re-evaluate a model at each point in the chain.\n\n","category":"section"},{"location":"api/#DynamicPPL.@model","page":"API","title":"DynamicPPL.@model","text":"@model(expr[, warn = false])\n\nMacro to specify a probabilistic model.\n\nIf warn is true, a warning is displayed if internal variable names are used in the model definition.\n\nExamples\n\nModel definition:\n\n@model function model(x, y = 42)\n    ...\nend\n\nTo generate a Model, call model(xvalue) or model(xvalue, yvalue).\n\n\n\n\n\n","category":"macro"},{"location":"api/#DynamicPPL.Model","page":"API","title":"DynamicPPL.Model","text":"struct Model{F,argnames,defaultnames,missings,Targs,Tdefaults,Ctx<:AbstractContext,Threaded}\n    f::F\n    args::NamedTuple{argnames,Targs}\n    defaults::NamedTuple{defaultnames,Tdefaults}\n    context::Ctx=DefaultContext()\nend\n\nA Model struct with model evaluation function of type F, arguments of names argnames types Targs, default arguments of names defaultnames with types Tdefaults, missing arguments missings, and evaluation context of type Ctx.\n\nHere argnames, defaultargnames, and missings are tuples of symbols, e.g. (:a, :b). context is by default DefaultContext().\n\nAn argument with a type of Missing will be in missings by default. However, in non-traditional use-cases missings can be defined differently. All variables in missings are treated as random variables rather than observations.\n\nThe Threaded type parameter indicates whether the model requires threadsafe evaluation (i.e., whether the model contains statements which modify the internal VarInfo that are executed in parallel). By default, this is set to false.\n\nThe default arguments are used internally when constructing instances of the same model with different arguments.\n\nExamples\n\njulia> Model(f, (x = 1.0, y = 2.0))\nModel{typeof(f),(:x, :y),(),(),Tuple{Float64,Float64},Tuple{}}(f, (x = 1.0, y = 2.0), NamedTuple())\n\njulia> Model(f, (x = 1.0, y = 2.0), (x = 42,))\nModel{typeof(f),(:x, :y),(:x,),(),Tuple{Float64,Float64},Tuple{Int64}}(f, (x = 1.0, y = 2.0), (x = 42,))\n\njulia> Model{(:y,)}(f, (x = 1.0, y = 2.0), (x = 42,)) # with special definition of missings\nModel{typeof(f),(:x, :y),(:x,),(:y,),Tuple{Float64,Float64},Tuple{Int64}}(f, (x = 1.0, y = 2.0), (x = 42,))\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.Model-Tuple{}","page":"API","title":"DynamicPPL.Model","text":"(model::Model)([rng, varinfo])\n\nSample from the prior of the model with random number generator rng.\n\nReturns the model's return value.\n\nNote that calling this with an existing varinfo object will mutate it.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.nameof-Tuple{Model}","page":"API","title":"Base.nameof","text":"nameof(model::Model)\n\nGet the name of the model as Symbol.\n\n\n\n\n\n","category":"method"},{"location":"api/#DynamicPPL.getargnames","page":"API","title":"DynamicPPL.getargnames","text":"getargnames(model::Model)\n\nGet a tuple of the argument names of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getmissings","page":"API","title":"DynamicPPL.getmissings","text":"getmissings(model::Model)\n\nGet a tuple of the names of the missing arguments of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.contextualize","page":"API","title":"DynamicPPL.contextualize","text":"contextualize(model::Model, context::AbstractContext)\n\nReturn a new Model with the same evaluation function and other arguments, but with its underlying context set to context.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setthreadsafe","page":"API","title":"DynamicPPL.setthreadsafe","text":"setthreadsafe(model::Model, threadsafe::Bool)\n\nReturns a new Model with its threadsafe flag set to threadsafe.\n\nThreadsafe evaluation ensures correctness when executing model statements that mutate the internal VarInfo object in parallel. For example, this is needed if tilde-statements are nested inside Threads.@threads or similar constructs.\n\nIt is not needed for generic multithreaded operations that don't involve VarInfo. For example, calculating a log-likelihood term in parallel and then calling @addlogprob! outside of the parallel region is safe without needing to set threadsafe=true.\n\nIt is also not needed for multithreaded sampling with AbstractMCMC's MCMCThreads().\n\nSetting threadsafe to true increases the overhead in evaluating the model. Please see the Turing.jl docs for more details.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.requires_threadsafe","page":"API","title":"DynamicPPL.requires_threadsafe","text":"requires_threadsafe(model::Model)\n\nReturn whether model has been marked as needing threadsafe evaluation (using setthreadsafe).\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.rand","page":"API","title":"Base.rand","text":"rand([rng=Random.default_rng()], model::Model)\n\nSample a VarNamedTuple of raw values from the prior of model.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.logprior","page":"API","title":"DynamicPPL.logprior","text":"logprior(model::Model, params)\nlogprior(model::Model, varinfo::AbstractVarInfo)\n\nReturn the log prior probability of variables params for the probabilistic model, or the log prior of the data in varinfo if provided.\n\nNote that this probability always refers to the parameters in unlinked space, i.e., the return value of logprior does not depend on whether VarInfo has been linked or not.\n\nSee also logjoint and loglikelihood.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       logprior(demo([1.0]), (m = 100.0, ))\n-5000.918938533205\n\njulia> # Using a `OrderedDict`.\n       logprior(demo([1.0]), OrderedDict(@varname(m) => 100.0))\n-5000.918938533205\n\njulia> # Truth.\n       logpdf(Normal(), 100.0)\n-5000.918938533205\n\n\n\n\n\nlogprior(model::Model, values::Union{NamedTuple,AbstractDict})\n\nReturn the log prior probability of variables values for the probabilistic model.\n\nSee also logjoint and loglikelihood.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       logprior(demo([1.0]), (m = 100.0, ))\n-5000.918938533205\n\njulia> # Using a `OrderedDict`.\n       logprior(demo([1.0]), OrderedDict(@varname(m) => 100.0))\n-5000.918938533205\n\njulia> # Truth.\n       logpdf(Normal(), 100.0)\n-5000.918938533205\n\n\n\n\n\nlogprior(model::DynamicPPL.Model, chain::MCMCChains.Chains)\n\nReturn an array of log prior probabilities evaluated at each sample in an MCMC chain.\n\nExamples\n\njulia> using MCMCChains, Distributions\n\njulia> @model function demo_model(x)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, sqrt(s))\n           for i in eachindex(x)\n               x[i] ~ Normal(m, sqrt(s))\n           end\n       end;\n\njulia> # Construct a chain of samples using MCMCChains.\n       # This sets s = 0.5 and m = 1.0 for all three samples.\n       chain = Chains(repeat([0.5 1.0;;;], 3, 1, 1), [:s, :m]);\n\njulia> logprior(demo_model([1., 2.]), chain)\n3×1 Matrix{Float64}:\n -3.2956988239086447\n -3.2956988239086447\n -3.2956988239086447\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.loglikelihood","page":"API","title":"StatsAPI.loglikelihood","text":"loglikelihood(model::Model, params)\nloglikelihood(model::Model, varinfo::AbstractVarInfo)\n\nReturn the log likelihood of variables params for the probabilistic model, or the log likelihood of the data in varinfo if provided.\n\nSee also logjoint and logprior.\n\nExamples\n\n```jldoctest; setup=:(using Distributions) julia> @model function demo(x)            m ~ Normal()            for i in eachindex(x)                x[i] ~ Normal(m, 1.0)            end        end demo (generic function with 2 methods)\n\njulia> # Using a NamedTuple.        loglikelihood(demo([1.0]), (m = 100.0, )) -4901.418938533205\n\njulia> # Using a OrderedDict.        loglikelihood(demo([1.0]), OrderedDict(@varname(m) => 100.0)) -4901.418938533205\n\njulia> # Truth.        logpdf(Normal(100.0, 1.0), 1.0) -4901.418938533205\n\n\n\n\n\nloglikelihood(model::Model, values::Union{NamedTuple,AbstractDict})\n\nReturn the log likelihood of variables values for the probabilistic model.\n\nSee also logjoint and logprior.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       loglikelihood(demo([1.0]), (m = 100.0, ))\n-4901.418938533205\n\njulia> # Using a `OrderedDict`.\n       loglikelihood(demo([1.0]), OrderedDict(@varname(m) => 100.0))\n-4901.418938533205\n\njulia> # Truth.\n       logpdf(Normal(100.0, 1.0), 1.0)\n-4901.418938533205\n\n\n\n\n\nloglikelihood(model::DynamicPPL.Model, chain::MCMCChains.Chains)\n\nReturn an array of log likelihoods evaluated at each sample in an MCMC chain.\n\nExamples\n\njulia> using MCMCChains, Distributions\n\njulia> @model function demo_model(x)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, sqrt(s))\n           for i in eachindex(x)\n               x[i] ~ Normal(m, sqrt(s))\n           end\n       end;\n\njulia> # Construct a chain of samples using MCMCChains.\n       # This sets s = 0.5 and m = 1.0 for all three samples.\n       chain = Chains(repeat([0.5 1.0;;;], 3, 1, 1), [:s, :m]);\n\njulia> loglikelihood(demo_model([1., 2.]), chain)\n3×1 Matrix{Float64}:\n -2.1447298858494\n -2.1447298858494\n -2.1447298858494\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.logjoint","page":"API","title":"DynamicPPL.logjoint","text":"logjoint(model::Model, params)\nlogjoint(model::Model, varinfo::AbstractVarInfo)\n\nReturn the log joint probability of variables params for the probabilistic model, or the log joint of the data in varinfo if provided.\n\nNote that this probability always refers to the parameters in unlinked space, i.e., the return value of logjoint does not depend on whether VarInfo has been linked or not.\n\nSee also logprior and loglikelihood.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       logjoint(demo([1.0]), (m = 100.0, ))\n-9902.33787706641\n\njulia> # Using a `OrderedDict`.\n       logjoint(demo([1.0]), OrderedDict(@varname(m) => 100.0))\n-9902.33787706641\n\njulia> # Truth.\n       logpdf(Normal(100.0, 1.0), 1.0) + logpdf(Normal(), 100.0)\n-9902.33787706641\n\n\n\n\n\nlogjoint(model::Model, values::Union{NamedTuple,AbstractDict})\n\nReturn the log joint probability of variables values for the probabilistic model.\n\nSee logprior and loglikelihood.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       logjoint(demo([1.0]), (m = 100.0, ))\n-9902.33787706641\n\njulia> # Using a `OrderedDict`.\n       logjoint(demo([1.0]), OrderedDict(@varname(m) => 100.0))\n-9902.33787706641\n\njulia> # Truth.\n       logpdf(Normal(100.0, 1.0), 1.0) + logpdf(Normal(), 100.0)\n-9902.33787706641\n\n\n\n\n\nlogjoint(model::Model, chain::MCMCChains.Chains)\n\nReturn an array of log joint probabilities evaluated at each sample in an MCMC chain.\n\nExamples\n\njulia> using MCMCChains, Distributions\n\njulia> @model function demo_model(x)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, sqrt(s))\n           for i in eachindex(x)\n               x[i] ~ Normal(m, sqrt(s))\n           end\n       end;\n\njulia> # Construct a chain of samples using MCMCChains.\n       # This sets s = 0.5 and m = 1.0 for all three samples.\n       chain = Chains(repeat([0.5 1.0;;;], 3, 1, 1), [:s, :m]);\n\njulia> logjoint(demo_model([1., 2.]), chain)\n3×1 Matrix{Float64}:\n -5.440428709758045\n -5.440428709758045\n -5.440428709758045\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.LogDensityFunction","page":"API","title":"DynamicPPL.LogDensityFunction","text":"DynamicPPL.LogDensityFunction(\n    model::Model,\n    getlogdensity::Any=getlogjoint_internal,\n    varinfo::AbstractVarInfo=VarInfo(model)\n    accs::Union{NTuple{<:Any,AbstractAccumulator},AccumulatorTuple}=DynamicPPL.ldf_accs(getlogdensity);\n    adtype::Union{ADTypes.AbstractADType,Nothing}=nothing,\n)\n\nA struct which contains a model, along with all the information necessary to:\n\ncalculate its log density at a given point;\nand if adtype is provided, calculate the gradient of the log density at that point.\n\nThis information can be extracted using the LogDensityProblems.jl interface, specifically, using LogDensityProblems.logdensity and LogDensityProblems.logdensity_and_gradient. If adtype is nothing, then only logdensity is implemented. If adtype is a concrete AD backend type, then logdensity_and_gradient is also implemented.\n\ngetlogdensity should be a callable which takes a single argument: a VarInfo, and returns a Real corresponding to the log density of interest. There are several functions in DynamicPPL that are 'supported' out of the box:\n\ngetlogjoint_internal: calculate the log joint, including the log-Jacobian term for any variables that have been linked in the provided VarInfo.\ngetlogprior_internal: calculate the log prior, including the log-Jacobian term for any variables that have been linked in the provided VarInfo.\ngetlogjoint: calculate the log joint in the model space, ignoring any effects of linking\ngetlogprior: calculate the log prior in the model space, ignoring any effects of linking\ngetloglikelihood: calculate the log likelihood (this is unaffected by linking, since transforms are only applied to random variables)\n\nnote: Note\nBy default, LogDensityFunction uses getlogjoint_internal, i.e., the result of LogDensityProblems.logdensity(f, x) will depend on whether the LogDensityFunction was created with a linked or unlinked VarInfo. This is done primarily to ease interoperability with MCMC samplers.\n\nIf you provide one of these functions, a VarInfo will be automatically created for you. If you provide a different function, you have to manually create a VarInfo and pass it as the third argument.\n\naccs allows you to specify an AccumulatorTuple or a tuple of AbstractAccumulators which will be used when evaluating the log density. (Note that the accumulators from theVarInfoargument are discarded.) By default, this uses an internal function,DynamicPPL.ldf_accs`, which attempts to choose an appropriate set of accumulators based on which kind of log-density is being calculated.\n\nIf the adtype keyword argument is provided, then this struct will also store the adtype along with other information for efficient calculation of the gradient of the log density. Note that preparing a LogDensityFunction with an AD type AutoBackend() requires the AD backend itself to have been loaded (e.g. with import Backend).\n\nFields\n\nNote that it is undefined behaviour to access any of a LogDensityFunction's fields, apart from:\n\nldf.model: The original model from which this LogDensityFunction was constructed.\nldf.adtype: The AD type used for gradient calculations, or nothing if no AD type was provided.\n\nExtended help\n\nUp until DynamicPPL v0.38, there have been two ways of evaluating a DynamicPPL model at a given set of parameters:\n\nWith unflatten!! + evaluate!! with DefaultContext: this stores a vector of parameters inside a VarInfo's metadata, then reads parameter values from the VarInfo during evaluation.\nWith InitFromParams: this reads parameter values from a NamedTuple or a Dict, and stores them inside a VarInfo's metadata.\n\nIn general, both of these approaches work fine, but the fact that they modify the VarInfo's metadata can often be quite wasteful. In particular, it is very common that the only outputs we care about from model evaluation are those which are stored in accumulators, such as log probability densities, or ValuesAsInModel.\n\nTo avoid this issue, we use OnlyAccsVarInfo, which is a VarInfo that only contains accumulators. It implements enough of the AbstractVarInfo interface to not error during model evaluation.\n\nBecause OnlyAccsVarInfo does not store any parameter values, when evaluating a model with it, it is mandatory that parameters are provided from outside the VarInfo, namely via InitContext.\n\nThe main problem that we face is that it is not possible to directly implement DynamicPPL.init(rng, vn, dist, strategy) for strategy::InitFromParams{<:AbstractVector}. In particular, it is not clear:\n\nwhich parts of the vector correspond to which random variables, and\nwhether the variables are linked or unlinked.\n\nTraditionally, this problem has been solved by unflatten!!, because that function would place values into the VarInfo's metadata alongside the information about ranges and linking. That way, when we evaluate with DefaultContext, we can read this information out again. However, we want to avoid using a metadata. Thus, here, we extract this information from the VarInfo a single time when constructing a LogDensityFunction object. Inside the LogDensityFunction, we store a mapping from VarNames to ranges in that vector, along with link status.\n\nWhen evaluating the model, this allows us to combine the parameter vector together with those ranges to create an InitFromParams{VectorWithRanges}, which lets us very quickly read parameter values from the vector.\n\nNote that this assumes that the ranges and link status are static throughout the lifetime of the LogDensityFunction object. Therefore, a LogDensityFunction object cannot handle models which have variable numbers of parameters, or models which may visit random variables in different orders depending on stochastic control flow. Indeed, silent errors may occur with such models. This is a general limitation of vectorised parameters: the original unflatten!! + evaluate!! approach also fails with such models.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.OnlyAccsVarInfo","page":"API","title":"DynamicPPL.OnlyAccsVarInfo","text":"OnlyAccsVarInfo\n\nThis is a wrapper around an AccumulatorTuple that implements the minimal AbstractVarInfo interface to work with the tilde_assume!! and tilde_observe!! functions for InitContext.\n\nNote that this does not implement almost every other AbstractVarInfo interface function, and so using this with a different leaf context such as DefaultContext will result in errors.\n\nConceptually, one can also think of this as a VarInfo that doesn't contain a metadata field. This is also why it only works with InitContext: in this case, the parameters used for evaluation are supplied by the context instead of the metadata.\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.:|-Tuple{Model, Union{Tuple, AbstractDict{<:VarName}, NamedTuple}}","page":"API","title":"Base.:|","text":"model | (x = 1.0, ...)\n\nReturn a Model which now treats variables on the right-hand side as observations.\n\nSee condition for more information and examples.\n\n\n\n\n\n","category":"method"},{"location":"api/#AbstractPPL.condition","page":"API","title":"AbstractPPL.condition","text":"condition(model::Model; values...)\ncondition(model::Model, values::NamedTuple)\n\nReturn a Model which now treats the variables in values as observations.\n\nSee also: decondition, conditioned\n\nLimitations\n\nThis does currently not work with variables that are provided to the model as arguments, e.g. @model function demo(x) ... end means that condition will not affect the variable x.\n\nTherefore if one wants to make use of condition and decondition one should not be specifying any random variables as arguments.\n\nThis is done for the sake of backwards compatibility.\n\nExamples\n\nSimple univariate model\n\njulia> using Distributions\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo();\n\njulia> m, x = model(); (m != 1.0 && x != 100.0)\ntrue\n\njulia> # Create a new instance which treats `x` as observed\n       # with value `100.0`, and similarly for `m=1.0`.\n       conditioned_model = condition(model, x=100.0, m=1.0);\n\njulia> m, x = conditioned_model(); (m == 1.0 && x == 100.0)\ntrue\n\njulia> # Let's only condition on `x = 100.0`.\n       conditioned_model = condition(model, x = 100.0);\n\njulia> m, x = conditioned_model(); (m != 1.0 && x == 100.0)\ntrue\n\njulia> # We can also use the nicer `|` syntax.\n       conditioned_model = model | (x = 100.0, );\n\njulia> m, x = conditioned_model(); (m != 1.0 && x == 100.0)\ntrue\n\nIn the above we have specified the conditioning variables via keyword arguments. You can also provide a NamedTuple, AbstractDict{<:VarName}, or a VarNamedTuple; internally these are all converted to a VarNamedTuple.\n\nFor example, here we use a Dict:\n\njulia> conditioned_model_dict = condition(model, Dict(@varname(x) => 100.0));\n\njulia> m, x = conditioned_model_dict(); (m != 1.0 && x == 100.0)\ntrue\n\njulia> # There's also an option using `|` by letting the right-hand side be a tuple\n       # with elements of type `Pair{<:VarName}`, i.e. `vn => value` with `vn isa VarName`.\n       conditioned_model_pairs = model | (@varname(x) => 100.0);\n\njulia> m, x = conditioned_model_pairs(); (m != 1.0 && x == 100.0)\ntrue\n\nCondition only a part of a multivariate variable\n\nWhen conditioning on multiple variables at a time, we can use missing to signal that a part of the variable should not be conditioned on.\n\nHowever, note that in this case each element of the multivariate random variable must be on its own tilde-statement. In other words, if we write m ~ MvNormal(...), then we cannot condition on only m[1]. (In principle, for some distributions this can be possible, specifically when the distribution can be factorised into independent components, like an MvNormal with a diagonal covariance matrix. However, this is not currently implemented.)\n\njulia> @model function demo_mv(::Type{TV}=Float64) where {TV}\n           m = Vector{TV}(undef, 2)\n           m[1] ~ Normal()\n           m[2] ~ Normal()\n           return m\n       end\ndemo_mv (generic function with 4 methods)\n\njulia> model = demo_mv();\n\njulia> conditioned_model = condition(model, m = [missing, 1.0]);\n\njulia> # (✓) `m[1]` sampled while `m[2]` is fixed\n       m = conditioned_model(); (m[1] != 1.0 && m[2] == 1.0)\ntrue\n\nIntuitively one might also expect to be able to write model | (m[2] = 1.0, ). You cannot do this with a NamedTuple because the VarName m[2] cannot be represented as a Symbol (i.e., Symbol(\"m[2]\") is not the same as @varname(m[2])).\n\njulia> # (×) `m[2]` is not set to 1.0.\n       m = condition(model, var\"m[2]\" = 1.0)(); m[2] == 1.0\nfalse\n\nBut you can do this if you use a Dict or a VarNamedTuple as the underlying storage instead:\n\njulia> vnt = @vnt begin\n           m[2] := 1.0\n       end\nVarNamedTuple\n└─ m => PartialArray size=(2,) data::DynamicPPL.VarNamedTuples.GrowableArray{Float64, 1}\n        └─ (2,) => 1.0\n\njulia> m = condition(model, vnt)(); (m[1] != 1.0 && m[2] == 1.0)\ntrue\n\nNested models\n\ncondition also supports the use of nested models through the use of to_submodel.\n\njulia> @model demo_inner() = m ~ Normal()\ndemo_inner (generic function with 2 methods)\n\njulia> @model function demo_outer()\n           # By default, `to_submodel` prefixes the variables using the left-hand side of `~`.\n           inner ~ to_submodel(demo_inner())\n           return inner\n       end\ndemo_outer (generic function with 2 methods)\n\njulia> model = demo_outer();\n\njulia> model() ≠ 1.0\ntrue\n\njulia> # To condition the variable inside `demo_inner` we need to refer to it as `inner.m`.\n       conditioned_model = model | (@varname(inner.m) => 1.0, );\n\njulia> conditioned_model()\n1.0\n\njulia> # If you attempt to condition on `inner` itself, it must refer to the prefixed\n       # latent variables, not the return value. For example, this will work:\n       conditioned_model2 = model | (inner = (m = 1.0,), );\n\njulia> conditioned_model2()\n1.0\n\njulia> # However, if `inner` does not contain `m` inside it as a field, this will not\n       # result in any conditioning:\n       conditioned_model_fail = model | (inner = \"something else\", );\n\njulia> conditioned_model_fail == 1.0\nfalse\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.conditioned","page":"API","title":"DynamicPPL.conditioned","text":"conditioned(context::AbstractContext)\n\nReturn VarNamedTuple of values that are conditioned on under context.\n\nNote that this will recursively traverse the context stack and return a merged version of the condition values.\n\n\n\n\n\nconditioned(model::Model)\n\nReturn the conditioned values in model.\n\nExamples\n\njulia> using Distributions\n\njulia> using DynamicPPL: conditioned, contextualize, PrefixContext, CondFixContext, Condition\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n       end\ndemo (generic function with 2 methods)\n\njulia> m = demo();\n\njulia> # Returns all the variables we have conditioned on + their values.\n       conditioned(condition(m, x=100.0, m=1.0))\nVarNamedTuple\n├─ x => 100.0\n└─ m => 1.0\n\njulia> # Nested ones also work. (Note that `PrefixContext` also prefixes\n       # the variables of any `CondFixContext` that is _inside_ it.)\n       new_context = PrefixContext(@varname(a), CondFixContext{Condition}(VarNamedTuple(m=1.0,)));\n       cm = condition(contextualize(m, new_context), x=100.0);\n\njulia> conditioned(cm)\nVarNamedTuple\n├─ a => VarNamedTuple\n│       └─ m => 1.0\n└─ x => 100.0\n\njulia> # Since we conditioned on `a.m`, it is not treated as a random variable.\n       # However, `a.x` will still be a random variable.\n       keys(VarInfo(cm))\n1-element Vector{VarName}:\n a.x\n\njulia> # We can also condition on `a.m` _outside_ of the PrefixContext:\n       cm = condition(contextualize(m, PrefixContext(@varname(a))), (@varname(a.m) => 1.0));\n\njulia> conditioned(cm)\nVarNamedTuple\n└─ a => VarNamedTuple\n        └─ m => 1.0\n\njulia> # Now `a.x` will be sampled.\n       keys(VarInfo(cm))\n1-element Vector{VarName}:\n a.x\n\n\n\n\n\n","category":"function"},{"location":"api/#AbstractPPL.decondition","page":"API","title":"AbstractPPL.decondition","text":"decondition(model::Model)\ndecondition(model::Model, variables...)\n\nReturn a Model for which variables... are not conditioned on. If no variables are provided, then all conditioned variables will be removed.\n\nNote that this function cannot decondition variables that are provided as arguments to the model function itself; it can only decondition variables that were provided via condition or |.\n\nThis is essentially the inverse of condition.\n\nExamples\n\njulia> using Distributions\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> conditioned_model = condition(demo(), m = 1.0, x = 10.0);\n\njulia> conditioned_model()\n(m = 1.0, x = 10.0)\n\njulia> # By specifying the `VarName` to `decondition`.\n       model = decondition(conditioned_model, @varname(m));\n\njulia> (m, x) = model(); (m ≠ 1.0 && x == 10.0)\ntrue\n\njulia> # `decondition` also accepts symbols, although VarNames are preferable for\n       # type stability reasons.\n       model = decondition(conditioned_model, :m);\n\njulia> (m, x) = model(); (m ≠ 1.0 && x == 10.0)\ntrue\n\njulia> # `decondition` multiple at once:\n       (m, x) = decondition(model, :m, :x)(); (m ≠ 1.0 && x ≠ 10.0)\ntrue\n\njulia> # `decondition` without any symbols will `decondition` all variables.\n       (m, x) = decondition(model)(); (m ≠ 1.0 && x ≠ 10.0)\ntrue\n\nNote that decondition is only guaranteed to work when you decondition variables that were explicitly provided to condition earlier. In this example we condition on @varname(m) but decondition on @varname(m[1]), which fails because m[1] was not explicitly conditioned on:\n\njulia> @model function demo_mv(::Type{TV}=Float64) where {TV}\n           m = Vector{TV}(undef, 2)\n           m[1] ~ Normal()\n           m[2] ~ Normal()\n           return m\n       end\ndemo_mv (generic function with 4 methods)\n\njulia> model = demo_mv();\n\njulia> conditioned_model = condition(model, @varname(m) => [1.0, 2.0]);\n\njulia> conditioned_model()\n2-element Vector{Float64}:\n 1.0\n 2.0\n\njulia> deconditioned_model = decondition(conditioned_model, @varname(m[1]));\n\njulia> deconditioned_model()  # (×) `m[1]` is still conditioned\n2-element Vector{Float64}:\n 1.0\n 2.0\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.fix","page":"API","title":"DynamicPPL.fix","text":"fix(model::Model; values...)\nfix(model::Model, values::NamedTuple)\n\nReturn a Model which now treats the variables in values as fixed.\n\nSee also: unfix, fixed\n\nExamples\n\nSimple univariate model\n\njulia> using Distributions\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo();\n\njulia> m, x = model(); (m ≠ 1.0 && x ≠ 100.0)\ntrue\n\njulia> # Create a new instance which treats `x` as observed\n       # with value `100.0`, and similarly for `m=1.0`.\n       fixed_model = fix(model, x=100.0, m=1.0);\n\njulia> m, x = fixed_model(); (m == 1.0 && x == 100.0)\ntrue\n\njulia> # Let's only fix on `x = 100.0`.\n       fixed_model = fix(model, x = 100.0);\n\njulia> m, x = fixed_model(); (m != 1.0 && x == 100.0)\ntrue\n\nOther ways of specifying fixed values\n\nSpecifying fixed values can be done exactly in the same way as for condition; please see its docstring for more examples.\n\nDifference from condition\n\nThe only difference between fixing and conditioning is as follows:\n\nConditioned variables are considered to be observations, and are thus included in the computation log-joint and log-likelihood, but not the log-prior.\nFixed variables are considered to be constant, and are thus not included in any log-probability computations.\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo();\n\njulia> model_fixed = fix(model, m = 1.0);\n\njulia> model_conditioned = condition(model, m = 1.0);\n\njulia> logjoint(model_fixed, (x=1.0,))\n-0.9189385332046728\n\njulia> logjoint(model_conditioned, (x=1.0,))\n-2.3378770664093453\n\njulia> # The difference is the missing log-probability of `m`:\n       logpdf(Normal(), 1.0)\n-1.4189385332046727\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.fixed","page":"API","title":"DynamicPPL.fixed","text":"fixed(context::AbstractContext)\n\nReturn a VarNamedTuple containing the values that are fixed under context.\n\nNote that this will recursively traverse the context stack and return a merged version of the fix values.\n\n\n\n\n\nfixed(model::Model)\n\nReturn the fixed values in model.\n\nExamples\n\njulia> using Distributions\n\njulia> using DynamicPPL: fixed, contextualize, PrefixContext, CondFixContext, Fix\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n       end\ndemo (generic function with 2 methods)\n\njulia> m = demo();\n\njulia> # Returns all the variables we have fixed on + their values.\n       fixed(fix(m, x=100.0, m=1.0))\nVarNamedTuple\n├─ x => 100.0\n└─ m => 1.0\n\njulia> # The rest of this is the same as the `condition` example above.\n       fm = fix(contextualize(m, PrefixContext(@varname(a), CondFixContext{Fix}(VarNamedTuple(m=1.0)))), x=100.0);\n\njulia> Set(keys(fixed(fm))) == Set([@varname(a.m), @varname(x)])\ntrue\n\njulia> keys(VarInfo(fm))\n1-element Vector{VarName}:\n a.x\n\njulia> # We can also fix `a.m` _outside_ of the PrefixContext:\n       fm = fix(contextualize(m, PrefixContext(@varname(a))), (@varname(a.m) => 1.0));\n\njulia> fixed(fm)\nVarNamedTuple\n└─ a => VarNamedTuple\n        └─ m => 1.0\n\njulia> # Now `a.x` will be sampled.\n       keys(VarInfo(fm))\n1-element Vector{VarName}:\n a.x\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.unfix","page":"API","title":"DynamicPPL.unfix","text":"unfix(model::Model)\nunfix(model::Model, variables...)\n\nReturn a Model for which variables... are not considered fixed. If no variables are provided, then all fixed variables will be removed.\n\nThis is essentially the inverse of fix.\n\nConceptually this is very similar to decondition and thus the same limitations apply; please see its docstring for more details.\n\nExamples\n\njulia> using Distributions\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> fixed_model = fix(demo(), m = 1.0, x = 10.0);\n\njulia> fixed_model()\n(m = 1.0, x = 10.0)\n\njulia> # By specifying the `VarName` to `unfix`.\n       model = unfix(fixed_model, @varname(m));\n\njulia> (m, x) = model(); (m != 1.0 && x == 10.0)\ntrue\n\njulia> # When `NamedTuple` is used as the underlying, you can also provide\n       # the symbol directly (though the `@varname` approach is preferable if\n       # if the variable is known at compile-time).\n       model = unfix(fixed_model, :m);\n\njulia> (m, x) = model(); (m != 1.0 && x == 10.0)\ntrue\n\njulia> # `unfix` multiple at once:\n       (m, x) = unfix(model, :m, :x)(); (m != 1.0 && x != 10.0)\ntrue\n\njulia> # `unfix` without any symbols will `unfix` all variables.\n       (m, x) = unfix(model)(); (m != 1.0 && x != 10.0)\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.predict","page":"API","title":"StatsAPI.predict","text":"predict([rng::AbstractRNG,] model::Model, chain::MCMCChains.Chains; include_all=false)\n\nSample from the posterior predictive distribution by executing model with parameters fixed to each sample in chain, and return the resulting Chains.\n\nThe model passed to predict is often different from the one used to generate chain. Typically, the model from which chain originated treats certain variables as observed (i.e., data points), while the model you pass to predict may mark these same variables as missing or unobserved. Calling predict then leverages the previously inferred parameter values to simulate what new, unobserved data might look like, given your posterior beliefs.\n\nFor each parameter configuration in chain:\n\nAll random variables present in chain are fixed to their sampled values.\nAny variables not included in chain are sampled from their prior distributions.\n\nIf include_all is false, the returned Chains will contain only those variables that were not fixed by the samples in chain. This is useful when you want to sample only new variables from the posterior predictive distribution.\n\nExamples\n\nusing AbstractMCMC, Distributions, DynamicPPL, Random\n\n@model function linear_reg(x, y, σ = 0.1)\n    β ~ Normal(0, 1)\n    for i in eachindex(y)\n        y[i] ~ Normal(β * x[i], σ)\n    end\nend\n\n# Generate synthetic chain using known ground truth parameter\nground_truth_β = 2.0\n\n# Create chain of samples from a normal distribution centered on ground truth\nβ_chain = MCMCChains.Chains(\n    rand(Normal(ground_truth_β, 0.002), 1000), [:β,]\n)\n\n# Generate predictions for two test points\nxs_test = [10.1, 10.2]\n\nm_train = linear_reg(xs_test, fill(missing, length(xs_test)))\n\npredictions = DynamicPPL.AbstractPPL.predict(\n    Random.default_rng(), m_train, β_chain\n)\n\nys_pred = vec(mean(Array(predictions); dims=1))\n\n# Check if predictions match expected values within tolerance\n(\n    isapprox(ys_pred[1], ground_truth_β * xs_test[1], atol = 0.01),\n    isapprox(ys_pred[2], ground_truth_β * xs_test[2], atol = 0.01)\n)\n\n# output\n\n(true, true)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.marginalize","page":"API","title":"DynamicPPL.marginalize","text":"marginalize(\n    model::DynamicPPL.Model,\n    marginalized_varnames::AbstractVector{<:VarName};\n    varinfo::DynamicPPL.AbstractVarInfo=link(VarInfo(model), model),\n    getlogprob=DynamicPPL.getlogjoint,\n    method::MarginalLogDensities.AbstractMarginalizer=MarginalLogDensities.LaplaceApprox();\n    kwargs...,\n)\n\nConstruct a MarginalLogDensities.MarginalLogDensity object that represents the marginal log-density of the given model, after marginalizing out the variables specified in varnames.\n\nThe resulting object can be called with a vector of parameter values to compute the marginal log-density.\n\nKeyword arguments\n\nvarinfo: The varinfo to use for the model. By default we use a linked VarInfo,  meaning that the resulting log-density function accepts parameters that have been  transformed to unconstrained space.\ngetlogprob: A function which specifies which kind of marginal log-density to compute.  Its default value is DynamicPPL.getlogjoint which returns the marginal log-joint  probability.\nmethod: The marginalization method; defaults to a Laplace approximation. Please see the  MarginalLogDensities.jl package  for other options.\nOther keyword arguments are passed to the MarginalLogDensities.MarginalLogDensity constructor.\n\nExample\n\njulia> using DynamicPPL, Distributions, MarginalLogDensities\n\njulia> @model function demo()\n           x ~ Normal(1.0)\n           y ~ Normal(2.0)\n       end\ndemo (generic function with 2 methods)\n\njulia> marginalized = marginalize(demo(), [:x]);\n\njulia> # The resulting callable computes the marginal log-density of `y`.\n       marginalized([1.0])\n-1.4189385332046727\n\njulia> logpdf(Normal(2.0), 1.0)\n-1.4189385332046727\n\nwarning: Warning\nThe default usage of linked VarInfo means that, for example, optimization of the marginal log-density can be performed in unconstrained space. However, care must be taken if the model contains variables where the link transformation depends on a marginalized variable. For example:@model function f()\n    x ~ Normal()\n    y ~ truncated(Normal(); lower=x)\nendHere, the support of y, and hence the link transformation used, depends on the value of x. If we now marginalize over x, we obtain a function mapping linked values of y to log-probabilities. However, it will not be possible to use DynamicPPL to correctly retrieve unlinked values of y.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.VarInfo-Tuple{MarginalLogDensities.MarginalLogDensity{<:DynamicPPLMarginalLogDensitiesExt.LogDensityFunctionWrapper}, Union{Nothing, AbstractVector}}","page":"API","title":"DynamicPPL.VarInfo","text":"VarInfo(\n    mld::MarginalLogDensities.MarginalLogDensity{<:LogDensityFunctionWrapper},\n    unmarginalized_params::Union{AbstractVector,Nothing}=nothing\n)\n\nRetrieve the VarInfo object used in the marginalisation process.\n\nIf a Laplace approximation was used for the marginalisation, the values of the marginalized parameters are also set to their mode (note that this only happens if the mld object has been used to compute the marginal log-density at least once, so that the mode has been computed).\n\nIf a vector of unmarginalized_params is specified, the values for the corresponding parameters will also be updated in the returned VarInfo. This vector may be obtained e.g. by performing an optimization of the marginal log-density.\n\nAll other aspects of the VarInfo, such as link status, are preserved from the original VarInfo used in the marginalisation.\n\nnote: Note\nThe other fields of the VarInfo, e.g. accumulated log-probabilities, will not be updated. If you wish to have a fully consistent VarInfo, you should re-evaluate the model with the returned VarInfo (e.g. using vi = last(DynamicPPL.evaluate!!(model, vi))).\n\nExample\n\njulia> using DynamicPPL, Distributions, MarginalLogDensities\n\njulia> @model function demo()\n           x ~ Normal()\n           y ~ Beta(2, 2)\n       end\ndemo (generic function with 2 methods)\n\njulia> # Note that by default `marginalize` uses a linked VarInfo.\n       mld = marginalize(demo(), [@varname(x)]);\n\njulia> using MarginalLogDensities: Optimization, OptimizationOptimJL\n\njulia> # Find the mode of the marginal log-density of `y`, with an initial point of `y0`.\n       y0 = 2.0; opt_problem = Optimization.OptimizationProblem(mld, [y0])\nOptimizationProblem. In-place: true\nu0: 1-element Vector{Float64}:\n 2.0\n\njulia> # This tells us the optimal (linked) value of `y` is around 0.\n       opt_solution = Optimization.solve(opt_problem, OptimizationOptimJL.NelderMead())\nretcode: Success\nu: 1-element Vector{Float64}:\n 4.88281250001733e-5\n\njulia> # Get the VarInfo corresponding to the mode of `y`.\n       vi = VarInfo(mld, opt_solution.u);\n\njulia> # `x` is set to its mode (which for `Normal()` is zero).\n       vi[@varname(x)]\n0.0\n\njulia> # `y` is set to the optimal value we found above.\n       DynamicPPL.getindex_internal(vi, @varname(y))\n1-element Vector{Float64}:\n 4.88281250001733e-5\n\njulia> # To obtain values in the original constrained space, we can either\n       # use `getindex`:\n       vi[@varname(y)]\n0.5000122070312476\n\njulia> # Or invlink the entire VarInfo object using the model:\n       vi_unlinked = DynamicPPL.invlink(vi, demo()); vi_unlinked[:]\n2-element Vector{Float64}:\n 0.0\n 0.5000122070312476\n\n\n\n\n\n","category":"method"},{"location":"api/#DynamicPPL.to_submodel","page":"API","title":"DynamicPPL.to_submodel","text":"to_submodel(model::Model[, auto_prefix::Bool])\n\nReturn a model wrapper indicating that it is a sampleable model over the return-values.\n\nThis is mainly meant to be used on the right-hand side of a ~ operator to indicate that the model can be sampled from but not necessarily evaluated for its log density.\n\nwarning: Warning\nNote that some other operations that one typically associate with expressions of the form left ~ right such as condition, will also not work with to_submodel.\n\nwarning: Warning\nTo avoid variable names clashing between models, it is recommended to leave the argument auto_prefix equal to true. If one does not use automatic prefixing, then it's recommended to use prefix(::Model, input) explicitly, i.e. to_submodel(prefix(model, @varname(my_prefix)))\n\nArguments\n\nmodel::Model: the model to wrap.\nauto_prefix::Bool: whether to automatically prefix the variables in the model using the left-hand   side of the ~ statement. Default: true.\n\nExamples\n\nSimple example\n\njulia> @model function demo1(x)\n           x ~ Normal()\n           return 1 + abs(x)\n       end;\n\njulia> @model function demo2(x, y)\n            a ~ to_submodel(demo1(x))\n            return y ~ Uniform(0, a)\n       end;\n\nWhen we sample from the model demo2(missing, 0.4) random variable x will be sampled:\n\njulia> vi = VarInfo(demo2(missing, 0.4));\n\njulia> @varname(a.x) in keys(vi)\ntrue\n\nThe variable a is not tracked. However, it will be assigned the return value of demo1, and can be used in subsequent lines of the model, as shown above.\n\njulia> @varname(a) in keys(vi)\nfalse\n\nWe can check that the log joint probability of the model accumulated in vi is correct:\n\njulia> x = vi[@varname(a.x)];\n\njulia> getlogjoint(vi) ≈ logpdf(Normal(), x) + logpdf(Uniform(0, 1 + abs(x)), 0.4)\ntrue\n\nWithout automatic prefixing\n\nAs mentioned earlier, by default, the auto_prefix argument specifies whether to automatically prefix the variables in the submodel. If auto_prefix=false, then the variables in the submodel will not be prefixed.\n\njulia> @model function demo1(x)\n           x ~ Normal()\n           return 1 + abs(x)\n       end;\n\njulia> @model function demo2_no_prefix(x, z)\n            a ~ to_submodel(demo1(x), false)\n            return z ~ Uniform(-a, 1)\n       end;\n\njulia> vi = VarInfo(demo2_no_prefix(missing, 0.4));\n\njulia> @varname(x) in keys(vi)  # here we just use `x` instead of `a.x`\ntrue\n\nHowever, not using prefixing is generally not recommended as it can lead to variable name clashes unless one is careful. For example, if we're re-using the same model twice in a model, not using prefixing will lead to variable name clashes: However, one can manually prefix using the prefix(::Model, input):\n\njulia> @model function demo2(x, y, z)\n            a ~ to_submodel(prefix(demo1(x), :sub1), false)\n            b ~ to_submodel(prefix(demo1(y), :sub2), false)\n            return z ~ Uniform(-a, b)\n       end;\n\njulia> vi = VarInfo(demo2(missing, missing, 0.4));\n\njulia> @varname(sub1.x) in keys(vi)\ntrue\n\njulia> @varname(sub2.x) in keys(vi)\ntrue\n\nVariables a and b are not tracked, but are assigned the return values of the respective calls to demo1:\n\njulia> @varname(a) in keys(vi)\nfalse\n\njulia> @varname(b) in keys(vi)\nfalse\n\nWe can check that the log joint probability of the model accumulated in vi is correct:\n\njulia> sub1_x = vi[@varname(sub1.x)];\n\njulia> sub2_x = vi[@varname(sub2.x)];\n\njulia> logprior = logpdf(Normal(), sub1_x) + logpdf(Normal(), sub2_x);\n\njulia> loglikelihood = logpdf(Uniform(-1 - abs(sub1_x), 1 + abs(sub2_x)), 0.4);\n\njulia> getlogjoint(vi) ≈ logprior + loglikelihood\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.prefix","page":"API","title":"DynamicPPL.prefix","text":"prefix(ctx::AbstractContext, vn::VarName)\n\nApply the prefixes in the context ctx to the variable name vn.\n\n\n\n\n\nprefix(model::Model, x::VarName)\nprefix(model::Model, x::Val{sym})\nprefix(model::Model, x::Any)\n\nReturn model but with all random variables prefixed by x, where x is either:\n\na VarName (e.g. @varname(a)),\na Val{sym} (e.g. Val(:a)), or\nfor any other type, x is converted to a Symbol and then to a VarName. Note that this will introduce runtime overheads so is not recommended unless absolutely necessary.\n\nExamples\n\njulia> using DynamicPPL: prefix\n\njulia> @model demo() = x ~ Dirac(1)\ndemo (generic function with 2 methods)\n\njulia> rand(prefix(demo(), @varname(my_prefix)))\nVarNamedTuple\n└─ my_prefix => VarNamedTuple\n                └─ x => 1\n\njulia> rand(prefix(demo(), Val(:my_prefix)))\nVarNamedTuple\n└─ my_prefix => VarNamedTuple\n                └─ x => 1\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.typed_identity","page":"API","title":"DynamicPPL.typed_identity","text":"typed_identity(x)\n\nIdentity function, but with an overload for with_logabsdet_jacobian to ensure that it returns a sensible zero logjac.\n\nThe problem with plain old identity is that the default definition of with_logabsdet_jacobian for identity returns zero(eltype(x)): https://github.com/JuliaMath/ChangesOfVariables.jl/blob/d6a8115fc9b9419decbdb48e2c56ec9675b4c6a4/src/with_ladj.jl#L154\n\nThis is fine for most samples x, but if eltype(x) doesn't return a sensible type (e.g. if it's Any), then using identity will error with zero(Any). This can happen with, for example, ProductNamedTupleDistribution:\n\njulia> using Distributions; d = product_distribution((a = Normal(), b = LKJCholesky(3, 0.5)));\n\njulia> eltype(rand(d))\nAny\n\nThe same problem precludes us from eventually broadening the scope of DynamicPPL.jl to support distributions with non-numeric samples.\n\nFurthermore, in principle, the type of the log-probability should be separate from the type of the sample. Thus, instead of using zero(LogProbType), we should use the eltype of the LogJacobianAccumulator. There's no easy way to thread that through here, but if a way to do this is discovered, then typed_identity is what will allow us to obtain that custom behaviour.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.@addlogprob!","page":"API","title":"DynamicPPL.@addlogprob!","text":"@addlogprob!(ex)\n\nAdd a term to the log joint.\n\nIf ex evaluates to a NamedTuple with keys :loglikelihood and/or :logprior, the values are added to the log likelihood and log prior respectively.\n\nIf ex evaluates to a number it is added to the log likelihood.\n\nExamples\n\njulia> mylogjoint(x, μ) = (; loglikelihood=loglikelihood(Normal(μ, 1), x), logprior=1.0);\n\njulia> @model function demo(x)\n           μ ~ Normal()\n           @addlogprob! mylogjoint(x, μ)\n       end;\n\njulia> x = [1.3, -2.1];\n\njulia> loglikelihood(demo(x), (μ=0.2,)) ≈ mylogjoint(x, 0.2).loglikelihood\ntrue\n\njulia> logprior(demo(x), (μ=0.2,)) ≈ logpdf(Normal(), 0.2) + mylogjoint(x, 0.2).logprior\ntrue\n\nand to reject samples:\n\njulia> @model function demo(x)\n           m ~ MvNormal(zero(x), I)\n           if dot(m, x) < 0\n               @addlogprob! (; loglikelihood=-Inf)\n               # Exit the model evaluation early\n               return\n           end\n           x ~ MvNormal(m, I)\n           return\n       end;\n\njulia> logjoint(demo([-2.1]), (m=[0.2],)) == -Inf\ntrue\n\n\n\n\n\n","category":"macro"},{"location":"api/#DynamicPPL.returned-Tuple{Model, Chains}","page":"API","title":"DynamicPPL.returned","text":"returned(model::Model, chain::MCMCChains.Chains)\n\nExecute model for each of the samples in chain and return an array of the values returned by the model for each sample.\n\nExamples\n\nGeneral\n\nOften you might have additional quantities computed inside the model that you want to inspect, e.g.\n\n@model function demo(x)\n    # sample and observe\n    θ ~ Prior()\n    x ~ Likelihood()\n    return interesting_quantity(θ, x)\nend\nm = demo(data)\nchain = sample(m, alg, n)\n# To inspect the `interesting_quantity(θ, x)` where `θ` is replaced by samples\n# from the posterior/`chain`:\nreturned(m, chain) # <= results in a `Vector` of returned values\n                               #    from `interesting_quantity(θ, x)`\n\nConcrete (and simple)\n\njulia> using Turing\n\njulia> @model function demo(xs)\n           s ~ InverseGamma(2, 3)\n           m_shifted ~ Normal(10, √s)\n           m = m_shifted - 10\n\n           for i in eachindex(xs)\n               xs[i] ~ Normal(m, √s)\n           end\n\n           return (m, )\n       end\ndemo (generic function with 1 method)\n\njulia> model = demo(randn(10));\n\njulia> chain = sample(model, MH(), 10);\n\njulia> returned(model, chain)\n10×1 Array{Tuple{Float64},2}:\n (2.1964758025119338,)\n (2.1964758025119338,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.043088571494005024,)\n (-0.16489786710222099,)\n (-0.16489786710222099,)\n\n\n\n\n\n","category":"method"},{"location":"api/#DynamicPPL.returned-Tuple{Model, Union{AbstractDict{<:VarName}, NamedTuple}}","page":"API","title":"DynamicPPL.returned","text":"returned(model::Model, parameters...)\n\nInitialise a model using the given parameters and return the model's return value. The parameters must be provided in a format that can be wrapped in an InitFromParams, i.e., InitFromParams(parameters..., nothing) must be a valid AbstractInitStrategy (where nothing is the fallback strategy to use if parameters are not provided).\n\nAs far as DynamicPPL is concerned, parameters can be either a singular NamedTuple or an AbstractDict{<:VarName}; however this method is left flexible to allow for other packages that wish to extend InitFromParams.\n\nExample\n\njulia> using DynamicPPL, Distributions\n\njulia> @model function demo()\n           m ~ Normal()\n           return (mp1 = m + 1,)\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo();\n\njulia> returned(model, (; m = 1.0))\n(mp1 = 2.0,)\n\njulia> returned(model, Dict{VarName,Float64}(@varname(m) => 2.0))\n(mp1 = 3.0,)\n\n\n\n\n\n","category":"method"},{"location":"api/#DynamicPPL.pointwise_logdensities","page":"API","title":"DynamicPPL.pointwise_logdensities","text":"DynamicPPL.pointwise_logdensities(\n    model::DynamicPPL.Model,\n    chain::MCMCChains.Chains,\n    ::Type{Tout}=MCMCChains.Chains\n    ::Val{whichlogprob}=Val(:both),\n)\n\nRuns model on each sample in chain, returning a new MCMCChains.Chains object where the log-density of each variable at each sample is stored (rather than its value).\n\nwhichlogprob specifies which log-probabilities to compute. It can be :both, :prior, or :likelihood.\n\nYou can pass Tout=OrderedDict to get the result as an OrderedDict{VarName, Matrix{Float64}} instead.\n\nSee also: DynamicPPL.pointwise_loglikelihoods, DynamicPPL.pointwise_prior_logdensities.\n\nExamples\n\njulia> using MCMCChains\n\njulia> @model function demo(xs, y)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, √s)\n           for i in eachindex(xs)\n               xs[i] ~ Normal(m, √s)\n           end\n           y ~ Normal(m, √s)\n       end\ndemo (generic function with 2 methods)\n\njulia> # Example observations.\n       model = demo([1.0, 2.0, 3.0], [4.0]);\n\njulia> # A chain with 3 iterations.\n       chain = Chains(\n           reshape(1.:6., 3, 2),\n           [:s, :m];\n           info=(varname_to_symbol=Dict(\n               @varname(s) => :s,\n               @varname(m) => :m,\n           ),),\n       );\n\njulia> plds = pointwise_logdensities(model, chain)\nChains MCMC chain (3×6×1 Array{Float64, 3}):\n\nIterations        = 1:1:3\nNumber of chains  = 1\nSamples per chain = 3\nparameters        = s, m, xs[1], xs[2], xs[3], y\n[...]\n\njulia> plds[:s]\n2-dimensional AxisArray{Float64,2,...} with axes:\n    :iter, 1:1:3\n    :chain, 1:1\nAnd data, a 3×1 Matrix{Float64}:\n -0.8027754226637804\n -1.3822169643436162\n -2.0986122886681096\n\njulia> # The above is the same as:\n       logpdf.(InverseGamma(2, 3), chain[:s])\n3×1 Matrix{Float64}:\n -0.8027754226637804\n -1.3822169643436162\n -2.0986122886681096\n\njulia> # Alternatively:        pldsdict = pointwiselogdensities(model, chain, OrderedDict) OrderedDict{VarName, Matrix{Float64}} with 6 entries:   s     => [-0.802775; -1.38222; -2.09861;;]   m     => [-8.91894; -7.51551; -7.46824;;]   xs[1] => [-5.41894; -5.26551; -5.63491;;]   xs[2] => [-2.91894; -3.51551; -4.13491;;]   xs[3] => [-1.41894; -2.26551; -2.96824;;]   y     => [-0.918939; -1.51551; -2.13491;;]\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.pointwise_loglikelihoods","page":"API","title":"DynamicPPL.pointwise_loglikelihoods","text":"DynamicPPL.pointwise_loglikelihoods(\n    model::DynamicPPL.Model,\n    chain::MCMCChains.Chains,\n    ::Type{Tout}=MCMCChains.Chains\n)\n\nCompute the pointwise log-likelihoods of the model given the chain. This is the same as pointwise_logdensities(model, chain), but only including the likelihood terms.\n\nSee also: DynamicPPL.pointwise_logdensities, DynamicPPL.pointwise_prior_logdensities.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.pointwise_prior_logdensities","page":"API","title":"DynamicPPL.pointwise_prior_logdensities","text":"DynamicPPL.pointwise_prior_logdensities(\n    model::DynamicPPL.Model,\n    chain::MCMCChains.Chains\n)\n\nCompute the pointwise log-prior-densities of the model given the chain. This is the same as pointwise_logdensities(model, chain), but only including the prior terms.\n\nSee also: DynamicPPL.pointwise_logdensities, DynamicPPL.pointwise_loglikelihoods.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.value_iterator_from_chain","page":"API","title":"DynamicPPL.value_iterator_from_chain","text":"value_iterator_from_chain(model::Model, chain)\nvalue_iterator_from_chain(varinfo::AbstractVarInfo, chain)\n\nReturn an iterator over the values in chain for each variable in model/varinfo.\n\nExample\n\njulia> using MCMCChains, DynamicPPL, Distributions, StableRNGs\n\njulia> rng = StableRNG(42);\n\njulia> @model function demo_model(x)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, sqrt(s))\n           for i in eachindex(x)\n               x[i] ~ Normal(m, sqrt(s))\n           end\n\n           return s, m\n       end\ndemo_model (generic function with 2 methods)\n\njulia> model = demo_model([1.0, 2.0]);\n\njulia> chain = Chains(rand(rng, 10, 2, 3), [:s, :m]);\n\njulia> iter = value_iterator_from_chain(model, chain);\n\njulia> first(iter)\nOrderedDict{VarName, Any} with 2 entries:\n  s => 0.580515\n  m => 0.739328\n\njulia> collect(iter)\n10×3 Matrix{OrderedDict{VarName, Any}}:\n OrderedDict(s=>0.580515, m=>0.739328)  …  OrderedDict(s=>0.186047, m=>0.402423)\n OrderedDict(s=>0.191241, m=>0.627342)     OrderedDict(s=>0.776277, m=>0.166342)\n OrderedDict(s=>0.971133, m=>0.637584)     OrderedDict(s=>0.651655, m=>0.712044)\n OrderedDict(s=>0.74345, m=>0.110359)      OrderedDict(s=>0.469214, m=>0.104502)\n OrderedDict(s=>0.170969, m=>0.598514)     OrderedDict(s=>0.853546, m=>0.185399)\n OrderedDict(s=>0.704776, m=>0.322111)  …  OrderedDict(s=>0.638301, m=>0.853802)\n OrderedDict(s=>0.441044, m=>0.162285)     OrderedDict(s=>0.852959, m=>0.0956922)\n OrderedDict(s=>0.803972, m=>0.643369)     OrderedDict(s=>0.245049, m=>0.871985)\n OrderedDict(s=>0.772384, m=>0.646323)     OrderedDict(s=>0.906603, m=>0.385502)\n OrderedDict(s=>0.70882, m=>0.253105)      OrderedDict(s=>0.413222, m=>0.953288)\n\njulia> # This can be used to `condition` a `Model`.\n       conditioned_model = model | first(iter);\n\njulia> conditioned_model()  # <= results in same values as the `first(iter)` above\n(0.5805148626851955, 0.7393275279160691)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.extract_priors","page":"API","title":"DynamicPPL.extract_priors","text":"extract_priors([rng::Random.AbstractRNG, ]model::Model)\n\nExtract the priors from a model. This is done by sampling from the model and recording the distributions that are used to generate the samples.\n\nwarning: Warning\nBecause the extraction is done by execution of the model, there are several caveats:If the distribution itself is not a constant (e.g. if it depends on another random variable, then the extracted prior will have different parameters in every extraction!\nIf the model does not have static support, say, n ~ Categorical(1:10); x ~ MvNormal(zeros(n), I), then the extracted priors themselves will be different between extractions, not just their parameters.Both of these caveats are demonstrated below.\n\nExamples\n\nChanging parameters\n\njulia> using Distributions, StableRNGs\n\njulia> rng = StableRNG(42);\n\njulia> @model function model_dynamic_parameters()\n           x ~ Normal(0, 1)\n           y ~ Normal(x, 1)\n       end;\n\njulia> model = model_dynamic_parameters();\n\njulia> extract_priors(rng, model)[@varname(y)]\nNormal{Float64}(μ=-0.6702516921145671, σ=1.0)\n\njulia> extract_priors(rng, model)[@varname(y)]\nNormal{Float64}(μ=1.3736306979834252, σ=1.0)\n\nChanging support\n\njulia> using LinearAlgebra, Distributions, StableRNGs\n\njulia> rng = StableRNG(42);\n\njulia> @model function model_dynamic_support()\n           n ~ Categorical(ones(10) ./ 10)\n           x ~ MvNormal(zeros(n), I)\n       end;\n\njulia> model = model_dynamic_support();\n\njulia> length(extract_priors(rng, model)[@varname(x)])\n6\n\njulia> length(extract_priors(rng, model)[@varname(x)])\n9\n\n\n\n\n\nextract_priors(model::Model, varinfo::AbstractVarInfo)\n\nExtract the priors that were used to generate a VarInfo.\n\nThis is done by evaluating the model at the values present in varinfo and recording the distributions that are present at each tilde statement.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.values_as_in_model","page":"API","title":"DynamicPPL.values_as_in_model","text":"values_as_in_model(model::Model, include_colon_eq::Bool, varinfo::AbstractVarInfo)\n\nGet the values of varinfo as they would be seen in the model.\n\nMore specifically, this method attempts to extract the realization as seen in the model. For example, x[1] ~ truncated(Normal(); lower=0) will result in a realization that is compatible with truncated(Normal(); lower=0) – i.e. one where the value of x[1] is positive – regardless of whether varinfo is working in unconstrained space.\n\nHence this method is a \"safe\" way of obtaining realizations in constrained space at the cost of additional model evaluations.\n\nReturns a VarNamedTuple.\n\nArguments\n\nmodel::Model: model to extract realizations from.\ninclude_colon_eq::Bool: whether to also include variables on the LHS of :=.\nvarinfo::AbstractVarInfo: variable information to use for the extraction.\n\nExamples\n\nWhen VarInfo fails\n\nThe following demonstrates a common pitfall when working with VarInfo and constrained variables.\n\njulia> using Distributions, StableRNGs\n\njulia> rng = StableRNG(42);\n\njulia> @model function model_changing_support()\n           x ~ Bernoulli(0.5)\n           y ~ x == 1 ? Uniform(0, 1) : Uniform(11, 12)\n       end;\n\njulia> model = model_changing_support();\n\njulia> # Construct initial `VarInfo`.\n       varinfo = VarInfo(rng, model);\n\njulia> # Link it so it works in unconstrained space.\n       varinfo_linked = DynamicPPL.link(varinfo, model);\n\njulia> # Perform computations in unconstrained space, e.g. changing the values of `vals`.\n       # Flip `x` so we hit the other support of `y`.\n       vals = [!varinfo[@varname(x)], rand(rng)];\n\njulia> # Update the `VarInfo` with the new values.\n       varinfo_linked = DynamicPPL.unflatten!!(varinfo_linked, vals);\n\njulia> # Determine the expected support of `y`.\n       lb, ub = vals[1] == 1 ? (0, 1) : (11, 12)\n(0, 1)\n\njulia> # Approach 1: Convert back to constrained space using `invlink` and extract.\n       varinfo_invlinked = DynamicPPL.invlink(varinfo_linked, model);\n\njulia> lb ≤ first(varinfo_invlinked[@varname(y)]) ≤ ub\ntrue\n\njulia> # Approach 2: Extract realizations using `values_as_in_model`.\n       lb ≤ values_as_in_model(model, true, varinfo_linked)[@varname(y)] ≤ ub\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.NamedDist","page":"API","title":"DynamicPPL.NamedDist","text":"A named distribution that carries the name of the random variable with it.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.AD.run_ad","page":"API","title":"DynamicPPL.TestUtils.AD.run_ad","text":"run_ad(\n    model::Model,\n    adtype::ADTypes.AbstractADType;\n    test::Union{AbstractADCorrectnessTestSetting,Bool}=WithBackend(),\n    benchmark=false,\n    atol::AbstractFloat=1e-8,\n    rtol::AbstractFloat=sqrt(eps()),\n    getlogdensity::Function=getlogjoint_internal,\n    rng::Random.AbstractRNG=Random.default_rng(),\n    varinfo::AbstractVarInfo=link(VarInfo(model), model),\n    params::Union{Nothing,Vector{<:AbstractFloat}}=nothing,\n    verbose=true,\n)::ADResult\n\nDescription\n\nTest the correctness and/or benchmark the AD backend adtype for the model model.\n\nWhether to test and benchmark is controlled by the test and benchmark keyword arguments. By default, test is true and benchmark is false.\n\nNote that to run AD successfully you will need to import the AD backend itself. For example, to test with AutoReverseDiff() you will need to run import ReverseDiff.\n\nArguments\n\nThere are two positional arguments, which absolutely must be provided:\n\nmodel - The model being tested.\nadtype - The AD backend being tested.\n\nEverything else is optional, and can be categorised into several groups:\n\nHow to specify the VarInfo.\nDynamicPPL contains several different types of VarInfo objects which change the way model evaluation occurs. If you want to use a specific type of VarInfo, pass it as the varinfo argument. Otherwise, it will default to using a linked TypedVarInfo generated from the model. Here, linked means that the parameters in the VarInfo have been transformed to unconstrained Euclidean space if they aren't already in that space.\nHow to specify the parameters.\nFor maximum control over this, generate a vector of parameters yourself and pass this as the params argument. If you don't specify this, it will be taken from the contents of the VarInfo.\nNote that if the VarInfo is not specified (and thus automatically generated) the parameters in it will have been sampled from the prior of the model. If you want to seed the parameter generation for the VarInfo, you can pass the rng keyword argument, which will then be used to create the VarInfo.\nFinally, note that these only reflect the parameters used for evaluating the gradient. If you also want to control the parameters used for preparing the gradient, then you need to manually set these parameters in the VarInfo object, for example using vi = DynamicPPL.unflatten!!(vi, prep_params). You could then evaluate the gradient at a different set of parameters using the params keyword argument.\nWhich type of logp is being calculated.\nBy default, run_ad evaluates the 'internal log joint density' of the model, i.e., the log joint density in the unconstrained space. Thus, for example, in\n@model f() = x ~ LogNormal()\nthe internal log joint density is logpdf(Normal(), log(x)). This is the relevant log density for e.g. Hamiltonian Monte Carlo samplers and is therefore the most useful to test.\nIf you want the log joint density in the original model parameterisation, you can use getlogjoint. Likewise, if you want only the prior or likelihood, you can use getlogprior or getloglikelihood, respectively.\nHow to specify the results to compare against.\nOnce logp and its gradient has been calculated with the specified adtype, it can optionally be tested for correctness. The exact way this is tested is specified in the test parameter.\nThere are several options for this:\nYou can explicitly specify the correct value using WithExpectedResult().\nYou can compare against the result obtained with a different AD backend using WithBackend(adtype).\nYou can disable testing by passing NoTest().\nThe default is to compare against the result obtained with ForwardDiff, i.e. WithBackend(AutoForwardDiff()).\ntest=false and test=true are synonyms for NoTest() and WithBackend(AutoForwardDiff()), respectively.\nHow to specify the tolerances. (Only if testing is enabled.)\nBoth absolute and relative tolerances can be specified using the atol and rtol keyword arguments respectively. The behaviour of these is similar to isapprox(), i.e. the value and gradient are considered correct if either atol or rtol is satisfied. The default values are 100*eps() for atol and sqrt(eps()) for rtol.\nFor the most part, it is the rtol check that is more meaningful, because we cannot know the magnitude of logp and its gradient a priori. The atol value is supplied to handle the case where gradients are equal to zero.\nWhether to benchmark.\nBy default, benchmarking is disabled. To enable it, set benchmark=true. When enabled, the time taken to evaluate logp as well as its gradient is measured using Chairmarks.jl, and the ADResult object returned will contain grad_time and primal_time fields with the median times (in seconds).\nWhether to output extra logging information.\nBy default, this function prints messages when it runs. To silence it, set verbose=false.\n\nReturns / Throws\n\nReturns an ADResult object, which contains the results of the test and/or benchmark.\n\nIf test is true and the AD backend returns an incorrect value or gradient, an ADIncorrectException is thrown. If a different error occurs, it will be thrown as-is.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.AD.AbstractADCorrectnessTestSetting","page":"API","title":"DynamicPPL.TestUtils.AD.AbstractADCorrectnessTestSetting","text":"AbstractADCorrectnessTestSetting\n\nDifferent ways of testing the correctness of an AD backend.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.AD.WithBackend","page":"API","title":"DynamicPPL.TestUtils.AD.WithBackend","text":"WithBackend(adtype::AbstractADType=AutoForwardDiff()) <: AbstractADCorrectnessTestSetting\n\nTest correctness by comparing it against the result obtained with adtype.\n\nadtype defaults to ForwardDiff.jl, since it's the default AD backend used in Turing.jl.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.AD.WithExpectedResult","page":"API","title":"DynamicPPL.TestUtils.AD.WithExpectedResult","text":"WithExpectedResult(\n    value::T,\n    grad::AbstractVector{T}\n) where {T <: AbstractFloat}\n<: AbstractADCorrectnessTestSetting\n\nTest correctness by comparing it against a known result (e.g. one obtained analytically, or one obtained with a different backend previously). Both the value of the primal (i.e. the log-density) as well as its gradient must be supplied.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.AD.NoTest","page":"API","title":"DynamicPPL.TestUtils.AD.NoTest","text":"NoTest() <: AbstractADCorrectnessTestSetting\n\nDisable correctness testing.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.AD.ADResult","page":"API","title":"DynamicPPL.TestUtils.AD.ADResult","text":"ADResult{Tparams<:AbstractFloat,Tresult<:AbstractFloat,Ttol<:AbstractFloat}\n\nData structure to store the results of the AD correctness test.\n\nThe type parameter Tparams is the numeric type of the parameters passed in; Tresult is the type of the value and the gradient; and Ttol is the type of the absolute and relative tolerances used for correctness testing.\n\nFields\n\nmodel::Model: The DynamicPPL model that was tested\ngetlogdensity::Function: The function used to extract the log density from the model\nvarinfo::AbstractVarInfo: The VarInfo that was used\nparams::Vector{Tparams} where Tparams<:AbstractFloat: The values at which the model was evaluated\nadtype::ADTypes.AbstractADType: The AD backend that was tested\natol::AbstractFloat: Absolute tolerance used for correctness test\nrtol::AbstractFloat: Relative tolerance used for correctness test\nvalue_expected::Union{Nothing, Tresult} where Tresult<:AbstractFloat: The expected value of logp\ngrad_expected::Union{Nothing, Vector{Tresult}} where Tresult<:AbstractFloat: The expected gradient of logp\nvalue_actual::AbstractFloat: The value of logp (calculated using adtype)\ngrad_actual::Vector{Tresult} where Tresult<:AbstractFloat: The gradient of logp (calculated using adtype)\ngrad_time::Union{Nothing, Tresult} where Tresult<:AbstractFloat: If benchmarking was requested, the time taken by the AD backend to evaluate the gradient     of logp (in seconds)\nprimal_time::Union{Nothing, Tresult} where Tresult<:AbstractFloat: If benchmarking was requested, the time taken by the AD backend to evaluate logp (in     seconds)\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.AD.ADIncorrectException","page":"API","title":"DynamicPPL.TestUtils.AD.ADIncorrectException","text":"ADIncorrectException{T<:AbstractFloat}\n\nException thrown when an AD backend returns an incorrect value or gradient.\n\nThe type parameter T is the numeric type of the value and gradient.\n\nFields\n\nvalue_expected::AbstractFloat\nvalue_actual::AbstractFloat\ngrad_expected::Vector{T} where T<:AbstractFloat\ngrad_actual::Vector{T} where T<:AbstractFloat\natol::AbstractFloat\nrtol::AbstractFloat\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TestUtils.DEMO_MODELS","page":"API","title":"DynamicPPL.TestUtils.DEMO_MODELS","text":"A collection of models corresponding to the posterior distribution defined by the generative process\n\ns ~ InverseGamma(2, 3)\nm ~ Normal(0, √s)\n1.5 ~ Normal(m, √s)\n2.0 ~ Normal(m, √s)\n\nor by\n\ns[1] ~ InverseGamma(2, 3)\ns[2] ~ InverseGamma(2, 3)\nm[1] ~ Normal(0, √s)\nm[2] ~ Normal(0, √s)\n1.5 ~ Normal(m[1], √s[1])\n2.0 ~ Normal(m[2], √s[2])\n\nThese are examples of a Normal-InverseGamma conjugate prior with Normal likelihood, for which the posterior is known in closed form.\n\nIn particular, for the univariate model (the former one):\n\nmean(s) == 49 / 24\nmean(m) == 7 / 6\n\nAnd for the multivariate one (the latter one):\n\nmean(s[1]) == 19 / 8\nmean(m[1]) == 3 / 4\nmean(s[2]) == 8 / 3\nmean(m[2]) == 1\n\n\n\n\n\n","category":"constant"},{"location":"api/#DynamicPPL.TestUtils.ALL_MODELS","page":"API","title":"DynamicPPL.TestUtils.ALL_MODELS","text":"A tuple of all models defined in DynamicPPL.TestUtils.\n\n\n\n\n\n","category":"constant"},{"location":"api/#DynamicPPL.TestUtils.logprior_true","page":"API","title":"DynamicPPL.TestUtils.logprior_true","text":"logprior_true(model, args...)\n\nReturn the logprior of model for args.\n\nThis should generally be implemented by hand for every specific model.\n\nSee also: logjoint_true, loglikelihood_true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.loglikelihood_true","page":"API","title":"DynamicPPL.TestUtils.loglikelihood_true","text":"loglikelihood_true(model, args...)\n\nReturn the loglikelihood of model for args.\n\nThis should generally be implemented by hand for every specific model.\n\nSee also: logjoint_true, logprior_true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.logjoint_true","page":"API","title":"DynamicPPL.TestUtils.logjoint_true","text":"logjoint_true(model, args...)\n\nReturn the logjoint of model for args.\n\nDefaults to logprior_true(model, args...) + loglikelihood_true(model, args..).\n\nThis should generally be implemented by hand for every specific model so that the returned value can be used as a ground-truth for testing things like:\n\nValidity of evaluation of model using a particular implementation of AbstractVarInfo.\nValidity of a sampler when combined with DynamicPPL by running the sampler twice: once targeting ground-truth functions, e.g. logjoint_true, and once targeting model.\n\nAnd more.\n\nSee also: logprior_true, loglikelihood_true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.logprior_true_with_logabsdet_jacobian","page":"API","title":"DynamicPPL.TestUtils.logprior_true_with_logabsdet_jacobian","text":"logprior_true_with_logabsdet_jacobian(model::Model, args...)\n\nReturn a tuple (args_unconstrained, logprior_unconstrained) of model for args....\n\nUnlike logprior_true, the returned logprior computation includes the log-absdet-jacobian adjustment, thus computing logprior for the unconstrained variables.\n\nNote that args are assumed be in the support of model, while args_unconstrained will be unconstrained.\n\nSee also: logprior_true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.logjoint_true_with_logabsdet_jacobian","page":"API","title":"DynamicPPL.TestUtils.logjoint_true_with_logabsdet_jacobian","text":"logjoint_true_with_logabsdet_jacobian(model::Model, args...)\n\nReturn a tuple (args_unconstrained, logjoint) of model for args.\n\nUnlike logjoint_true, the returned logjoint computation includes the log-absdet-jacobian adjustment, thus computing logjoint for the unconstrained variables.\n\nNote that args are assumed be in the support of model, while args_unconstrained will be unconstrained.\n\nThis should generally not be implemented directly, instead one should implement logprior_true_with_logabsdet_jacobian for a given model.\n\nSee also: logjoint_true, logprior_true_with_logabsdet_jacobian.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.varnames","page":"API","title":"DynamicPPL.TestUtils.varnames","text":"varnames(model::Model)\n\nReturn the VarNames defined in model, as a Vector.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.posterior_mean","page":"API","title":"DynamicPPL.TestUtils.posterior_mean","text":"posterior_mean(model::Model)\n\nReturn a NamedTuple compatible with varnames(model) where the values represent the posterior mean under model.\n\n\"Compatible\" means that a varname from varnames(model) can be used to extract the corresponding value using e.g. AbstractPPL.getvalue(posterior_mean(model), varname).\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.setup_varinfos","page":"API","title":"DynamicPPL.TestUtils.setup_varinfos","text":"setup_varinfos(model::Model, example_values::NamedTuple, varnames; include_threadsafe::Bool=false)\n\nReturn a tuple of instances for different implementations of AbstractVarInfo with each vi, supposedly, satisfying vi[vn] == get(example_values, vn) for vn in varnames.\n\nIf include_threadsafe is true, then the returned tuple will also include thread-safe versions of the varinfo instances.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.update_values!!","page":"API","title":"DynamicPPL.update_values!!","text":"update_values!!(vi::AbstractVarInfo, vals::NamedTuple, vns)\n\nReturn instance similar to vi but with vns set to values from vals.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.test_values","page":"API","title":"DynamicPPL.TestUtils.test_values","text":"test_values(vi::AbstractVarInfo, vals::NamedTuple, vns)\n\nTest that vi[vn] corresponds to the correct value in vals for every vn in vns.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.DebugUtils.check_model","page":"API","title":"DynamicPPL.DebugUtils.check_model","text":"check_model(model::Model, varinfo::AbstractVarInfo; error_on_failure=false)\n\nCheck that model is valid, warning about any potential issues (or erroring if error_on_failure is true).\n\nReturns\n\nissuccess::Bool: Whether the model check succeeded.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.DebugUtils.check_model_and_trace","page":"API","title":"DynamicPPL.DebugUtils.check_model_and_trace","text":"check_model_and_trace(model::Model, varinfo::AbstractVarInfo; error_on_failure=false)\n\nCheck that evaluating model with the given varinfo is valid, warning about any potential issues.\n\nThis will check the model for the following issues:\n\nRepeated usage of the same varname in a model.\nNaN on the left-hand side of observe statements.\n\nArguments\n\nmodel::Model: The model to check.\nvarinfo::AbstractVarInfo: The varinfo to use when evaluating the model.\n\nKeyword Argument\n\nerror_on_failure::Bool: Whether to throw an error if the model check fails. Default: false.\n\nReturns\n\nissuccess::Bool: Whether the model check succeeded.\ntrace::Vector{Stmt}: The trace of statements executed during the model check.\n\nExamples\n\nCorrect model\n\njulia> using StableRNGs\n\njulia> rng = StableRNG(42);\n\njulia> @model demo_correct() = x ~ Normal()\ndemo_correct (generic function with 2 methods)\n\njulia> model = demo_correct(); varinfo = VarInfo(rng, model);\n\njulia> issuccess, trace = check_model_and_trace(model, varinfo);\n\njulia> issuccess\ntrue\n\njulia> print(trace)\n assume: x ~ Normal{Float64}(μ=0.0, σ=1.0) ⟼ -0.670252\n\njulia> cond_model = model | (x = 1.0,);\n\njulia> issuccess, trace = check_model_and_trace(cond_model, VarInfo(cond_model));\n┌ Warning: The model does not contain any parameters.\n└ @ DynamicPPL.DebugUtils DynamicPPL.jl/src/debug_utils.jl:342\n\njulia> issuccess\ntrue\n\njulia> print(trace)\n observe: x (= 1.0) ~ Normal{Float64}(μ=0.0, σ=1.0)\n\nIncorrect model\n\njulia> @model function demo_incorrect()\n           # (×) Sampling `x` twice will lead to incorrect log-probabilities!\n           x ~ Normal()\n           x ~ Exponential()\n       end\ndemo_incorrect (generic function with 2 methods)\n\njulia> # Notice that VarInfo(model_incorrect) evaluates the model, but doesn't actually\n       # alert us to the issue of `x` being sampled twice.\n       model = demo_incorrect(); varinfo = VarInfo(model);\n\njulia> issuccess, trace = check_model_and_trace(model, varinfo; error_on_failure=true);\nERROR: varname x used multiple times in model\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.DebugUtils.has_static_constraints","page":"API","title":"DynamicPPL.DebugUtils.has_static_constraints","text":"has_static_constraints([rng, ]model::Model; num_evals=5, error_on_failure=false)\n\nReturn true if the model has static constraints, false otherwise.\n\nNote that this is a heuristic check based on sampling from the model multiple times and checking if the model is consistent across runs.\n\nArguments\n\nrng::Random.AbstractRNG: The random number generator to use when evaluating the model.\nmodel::Model: The model to check.\n\nKeyword Arguments\n\nnum_evals::Int: The number of evaluations to perform. Default: 5.\nerror_on_failure::Bool: Whether to throw an error if any of the num_evals model checks fail. Default: false.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.DebugUtils.model_warntype","page":"API","title":"DynamicPPL.DebugUtils.model_warntype","text":"model_warntype(model[, varinfo]; optimize=true)\n\nCheck the type stability of the model's evaluator, warning about any potential issues.\n\nThis simply calls @code_warntype on the model's evaluator, filling in internal arguments where needed.\n\nArguments\n\nmodel::Model: The model to check.\nvarinfo::AbstractVarInfo: The varinfo to use when evaluating the model. Default: VarInfo(model).\n\nKeyword Arguments\n\noptimize::Bool: Whether to generate optimized code. Default: false.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.DebugUtils.model_typed","page":"API","title":"DynamicPPL.DebugUtils.model_typed","text":"model_typed(model[, varinfo]; optimize=true)\n\nReturn the type inference for the model's evaluator.\n\nThis simply calls @code_typed on the model's evaluator, filling in internal arguments where needed.\n\nArguments\n\nmodel::Model: The model to check.\nvarinfo::AbstractVarInfo: The varinfo to use when evaluating the model. Default: VarInfo(model).\n\nKeyword Arguments\n\noptimize::Bool: Whether to generate optimized code. Default: true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.DebugUtils.gen_evaluator_call_with_types","page":"API","title":"DynamicPPL.DebugUtils.gen_evaluator_call_with_types","text":"gen_evaluator_call_with_types(model[, varinfo])\n\nGenerate the evaluator call and the types of the arguments.\n\nArguments\n\nmodel::Model: The model whose evaluator is of interest.\nvarinfo::AbstractVarInfo: The varinfo to use when evaluating the model. Default: VarInfo(model).\n\nReturns\n\nA 2-tuple with the following elements:\n\nf: This is either model.f or Core.kwcall, depending on whether   the model has keyword arguments.\nargtypes::Type{<:Tuple}: The types of the arguments for the evaluator.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.AbstractVarInfo","page":"API","title":"DynamicPPL.AbstractVarInfo","text":"AbstractVarInfo\n\nAbstract supertype for data structures that capture random variables when executing a probabilistic model and accumulate log densities such as the log likelihood or the log joint probability of the model.\n\nSee also: VarInfo\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.VarInfo","page":"API","title":"DynamicPPL.VarInfo","text":"VarInfo{Linked,T<:VarNamedTuple,Accs<:AccumulatorTuple} <: AbstractVarInfo\n\nThe default implementation of AbstractVarInfo, storing variable values and accumulators.\n\nThe Linked type parameter is either true or false to mark that all variables in this VarInfo are linked, or nothing to indicate that some variables may be linked and some not, and a runtime check is needed.\n\nVarInfo is quite a thin wrapper around a VarNamedTuple storing the variable values, and a tuple of accumulators. The only really noteworthy thing about it is that it stores the values of variables vectorised as instances of AbstractTransformedValue. That is, it stores each value as a special vector with a flag indicating whether it is just a vectorised value (VectorValue), or whether it is also linked (LinkedVectorValue). It also stores the size of the actual post-transformation value. These are all accessible via AbstractTransformedValue.\n\nNote that setindex!! and getindex on VarInfo take and return values in the support of the original distribution. To get access to the internal vectorised values, use getindex_internal, setindex_internal!!, and unflatten!!.\n\nThere's also a VarInfo-specific function setindex_with_dist!!, which sets a variable's value with a transformation based on the statistical distribution this value is a sample for.\n\nFor more details on the internal storage, see documentation of AbstractTransformedValue and VarNamedTuple.\n\nFields\n\nvalues::VarNamedTuple\naccs::DynamicPPL.AccumulatorTuple\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.setindex_with_dist!!","page":"API","title":"DynamicPPL.setindex_with_dist!!","text":"setindex_with_dist!!(vi::VarInfo, val, dist::Distribution, vn::VarName)\n\nSet the value of vn in vi to val, applying a transformation based on dist.\n\nval is taken to be the actual value of the variable, and is transformed into the internal (vectorised) representation using a transformation based on dist. If the variable is currently linked in vi, or doesn't exist in vi but all other variables in vi are linked, the linking transformation is used; otherwise, the standard vector transformation is used.\n\nReturns three things:\n\nthe modified vi,\nthe log absolute determinant of the Jacobian of the transformation applied,\nthe AbstractTransformedValue used to store the value.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.is_transformed","page":"API","title":"DynamicPPL.is_transformed","text":"is_transformed(vi::AbstractVarInfo[, vns::Union{VarName, AbstractVector{<:Varname}}])\n\nReturn true if vi is working in unconstrained space, and false if vi is assuming realizations to be in support of the corresponding distributions.\n\nIf vns is provided, then only check if this/these varname(s) are transformed.\n\nwarning: Warning\nNot all implementations of AbstractVarInfo support transforming only a subset of the variables.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.set_transformed!!","page":"API","title":"DynamicPPL.set_transformed!!","text":"set_transformed!!(vi::AbstractVarInfo, trans::Bool[, vn::VarName])\n\nReturn vi with is_transformed(vi, vn) evaluating to true.\n\nIf vn is not specified, then is_transformed(vi) evaluates to true for all variables.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.VarNamedTuples.VarNamedTuple","page":"API","title":"DynamicPPL.VarNamedTuples.VarNamedTuple","text":"VarNamedTuple{names,Values}\n\nA NamedTuple-like structure with VarName keys.\n\nVarNamedTuple is a data structure for storing arbitrary data, keyed by VarNames, in an efficient and type stable manner. It is mainly used through getindex, setindex!!, templated_setindex!!, and haskey, all of which only accept VarNames as keys. Other notable methods are merge and subset.\n\nVarNamedTuple has an ordering to its elements, and two VarNamedTuples with the same keys and values but in different orders are considered different for equality and hashing. Iterations such as keys and values respect this ordering. The ordering is dependent on the order in which elements were inserted into the VarNamedTuple, though isn't always equal to it. More specifically\n\nAny new keys that have a joint parent VarName with an existing key are inserted after that key. For instance, if one first inserts, in order, @varname(a.x), @varname(b), and @varname(a.y), the resulting order will be (@varname(a.x), @varname(a.y), @varname(b)).\nIndex keys, like@varname(a[3])or@varname(b[2,3,4:5]), are always iterated in the same order anArraywith the same indices would be iterated. For instance, if one first inserts, in order,@varname(a[2]),@varname(b), and@varname(a[1]), the resulting order will be(@varname(a[1]), @varname(a[2]), @varname(b))`.\n\nOtherwise insertion order is respected.\n\nsetindex!! and getindex on VarNamedTuple are type stable as long as one does not store heterogeneous data under different indices of the same symbol. That is, if either\n\none sets a[1] and a[2] to be of different types, or\nif a[1] and a[2] both exist, one sets a[1].b without setting a[2].b,\n\nthen getting values for a[1] or a[2] will not be type stable.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.VarNamedTuples.@vnt","page":"API","title":"DynamicPPL.VarNamedTuples.@vnt","text":"@vnt begin ... end\n\nConstruct a VarNamedTuple from a block of assignments. Each assignment should be of the form var := value, where var is a variable name. This is best illustrated by example:\n\njulia> using DynamicPPL\n\njulia> @vnt begin\n           a := 1\n           b := 2\n       end\nVarNamedTuple\n├─ a => 1\n└─ b => 2\n\nYou can set entirely arbitrary variables:\n\njulia> @vnt begin\n           a.b.c.d.e := \"hello\"\n       end\nVarNamedTuple\n└─ a => VarNamedTuple\n        └─ b => VarNamedTuple\n                └─ c => VarNamedTuple\n                        └─ d => VarNamedTuple\n                                └─ e => \"hello\"\n\nFor variables that have indexing, it is often necessary to provide a template, so that the VNT 'knows' what kind of array is being used to store the values, and can set the values in the appropriate places (consider e.g. OffsetArrays where x[1] may not mean what it usually does).\n\nThis is done by inserting a @template macro call in the block. The @template macro accepts whitespace-separated arguments, which must either be\n\na single symbol (e.g. @template x), in which case the template is the value of x (and x must already be defined in the current scope); or\nan assignment of the form y = expr, in which case the template for y is the value of expr. In this case y does not need to be defined in the current scope, but any symbols referenced in expr must be.\n\nFor example:\n\njulia> x = zeros(5); outside_y = zeros(3, 3);\n\njulia> @vnt begin\n            @template x y=outside_y\n            x[1] := 1.0\n            y[1, 1] := 2.0\n       end\nVarNamedTuple\n├─ x => PartialArray size=(5,) data::Vector{Float64}\n│       └─ (1,) => 1.0\n└─ y => PartialArray size=(3, 3) data::Matrix{Float64}\n        └─ (1, 1) => 2.0\n\nnote: Note\nYou can use any expression in @template y=expr, even a function call that is completely contained within the macro (e.g. @template y=zeros(3, 3)). The macro makes sure that expr is only evaluated once, so there is no performance penalty to doing this.\n\nIf no template is provided, the VNT will use a GrowableArray. This can produce correct results in simple cases, but is not recommended for general use. Please see the VarNamedTuple documentation for more details.\n\njulia> @vnt begin\n            # No template provided.\n            x[1] := 1.0\n            y[1, 1] := 2.0\n       end\nVarNamedTuple\n├─ x => PartialArray size=(1,) data::DynamicPPL.VarNamedTuples.GrowableArray{Float64, 1}\n│       └─ (1,) => 1.0\n└─ y => PartialArray size=(1, 1) data::DynamicPPL.VarNamedTuples.GrowableArray{Float64, 2}\n        └─ (1, 1) => 2.0\n\n\n\n\n\n","category":"macro"},{"location":"api/#DynamicPPL.VarNamedTuples.vnt_size","page":"API","title":"DynamicPPL.VarNamedTuples.vnt_size","text":"vnt_size(x)\n\nGet the size of an object x for use in VarNamedTuple and PartialArray.\n\nBy default, this falls back onto Base.size, but can be overloaded for custom types. This notion of type is used to determine whether a value can be set into a PartialArray as a block, see the docstring of PartialArray and ArrayLikeBlock for details.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.VarNamedTuples.apply!!","page":"API","title":"DynamicPPL.VarNamedTuples.apply!!","text":"apply!!(func, vnt::VarNamedTuple, name::VarName)\n\nApply func to the subdata at name in vnt, and set the result back at name.\n\nLike map_values!!, but only for a single VarName.\n\njulia> using DynamicPPL: VarNamedTuple, setindex!!\n\njulia> using DynamicPPL.VarNamedTuples: apply!!\n\njulia> vnt = VarNamedTuple()\nVarNamedTuple()\n\njulia> vnt = setindex!!(vnt, [1, 2, 3], @varname(a))\nVarNamedTuple\n└─ a => [1, 2, 3]\n\njulia> apply!!(x -> x .+ 1, vnt, @varname(a))\nVarNamedTuple\n└─ a => [2, 3, 4]\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.VarNamedTuples.map_pairs!!","page":"API","title":"DynamicPPL.VarNamedTuples.map_pairs!!","text":"map_pairs!!(func, vnt::VarNamedTuple)\n\nApply func to all key => value pairs of vnt, in place if possible.\n\nfunc should accept a pair of VarName and value, and return the new value to be set.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.VarNamedTuples.map_values!!","page":"API","title":"DynamicPPL.VarNamedTuples.map_values!!","text":"map_values!!(func, vnt::VarNamedTuple)\n\nApply func to elements of vnt, in place if possible.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.VarNamedTuples.PartialArray","page":"API","title":"DynamicPPL.VarNamedTuples.PartialArray","text":"PartialArray{\n    ElType,\n    num_dims,\n    D<:AbstractArray{ElType,num_dims},\n    M<:AbstractArray{Bool,num_dims}\n}\n\nAn array-like like structure that may only have some of its elements defined.\n\nOne can set values in a PartialArray either element-by-element, or with ranges like arr[1:3,2] = [5,10,15]. When setting values over a range of indices, the value being set must either be an AbstractArray or otherwise something for which vnt_size(value) or Base.size(value) (which vnt_size falls back onto) is defined, and the size matches the range. If the value is an AbstractArray, the elements are copied individually, but if it is not, the value is stored as a block, that takes up the whole range, e.g. [1:3,2], but is only a single object. Getting such a block-value must be done with the exact same range of indices, otherwise an error is thrown.\n\nIf the element type of a PartialArray is not concrete, any call to setindex!! will check if, after the new value has been set, the element type can be made more concrete. If so, a new PartialArray with a more concrete element type is returned. Thus the element type of any PartialArray should always be as concrete as is allowed by the elements in it.\n\nThe internal implementation of an PartialArray consists of two arrays: one holding the data and the other one being a boolean mask indicating which elements are defined. These internal arrays may need resizing when new elements are set that have index ranges larger than the current internal arrays. To avoid resizing too often, the internal arrays are resized in exponentially increasing steps. This means that most setindex!! calls are very fast, but some may incur substantial overhead due to resizing and copying data. It also means that the largest index set so far determines the memory usage of the PartialArray. PartialArrays are thus well-suited when most values in it will eventually be set. If only a few scattered values are set, a structure like SparseArray may be more appropriate.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.VarNamedTuples.templated_setindex!!","page":"API","title":"DynamicPPL.VarNamedTuples.templated_setindex!!","text":"DynamicPPL.VarNamedTuples.templated_setindex!!(vnt, value, vn, template; allow_new=Val(true))\n\nAssign value to the location in vnt specified by vn.\n\nThe argument template must be provided in order to guide the creation of PartialArrays, as well as to concretise any dynamic indices in vn. It must be an object that has the shape of the top-level symbol in vn. For example:\n\nvnt = VarNamedTuple()\ntemplated_setindex!!(vnt, 10, @varname(x[1]), rand(2, 2))\n\nHere, rand(2, 2) is the template for the top-level symbol x, which tells setindex!! that x should be a PartialArray that is backed by a matrix.\n\nThe actual data inside template is not needed, and template is never mutated by this call.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.VarNamedTuples.NoTemplate","page":"API","title":"DynamicPPL.VarNamedTuples.NoTemplate","text":"NoTemplate\n\nA singleton struct representing the fact that there is no template for a top-level variable. When NoTemplate is used, several things happen:\n\nIf you attempt to call make_leaf with an Index optic, this will error.\nWhen recursing into substructures, NoTemplate will be propagated.\n\nCollectively this means that you can only set values for variables that only have Property optics, unless a template is provided.\n\nIt might seem more idiomatic to use nothing or missing for this. However, this causes a bug with BangBang.setindex!!: https://github.com/JuliaFolds2/BangBang.jl/issues/43 so we use a dedicated struct instead.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.VarNamedTuples.SkipTemplate","page":"API","title":"DynamicPPL.VarNamedTuples.SkipTemplate","text":"SkipTemplate{N}(value)\n\nA struct representing the fact that value is the template for the variable N levels down from the top-level variable. In other words, SkipTemplate{0}(value) is equivalent to just value, and SkipTemplate{1}(value) means that value is the template for a when setting the variable @varname(x.a).\n\n\n\n\n\n","category":"type"},{"location":"api/#Core.NamedTuple-Tuple{VarNamedTuple}","page":"API","title":"Core.NamedTuple","text":"NamedTuple(vnt::VarNamedTuple)\n\nConvert a VarNamedTuple to a standard NamedTuple, provided all keys in the VarNamedTuple are VarNames with top-level symbols. If any key is a VarName with a non-identity optic (e.g., @varname(x.a) or @varname(x[1])), this will throw an ArgumentError.\n\nExamples\n\njulia> using DynamicPPL, BangBang\n\njulia> vnt = VarNamedTuple(); vnt = setindex!!(vnt, 10, @varname(x))\nVarNamedTuple\n└─ x => 10\n\njulia> NamedTuple(vnt)\n(x = 10,)\n\njulia> vnt2 = setindex!!(vnt, 20, @varname(y.a))\nVarNamedTuple\n├─ x => 10\n└─ y => VarNamedTuple\n        └─ a => 20\n\njulia> NamedTuple(vnt2)\nERROR: ArgumentError: Cannot convert VarNamedTuple containing non-identity VarNames to NamedTuple. To create a NamedTuple, all keys in the VarNamedTuple must be top-level symbols.\n[...]\n\n\n\n\n\n","category":"method"},{"location":"api/#DynamicPPL.AbstractAccumulator","page":"API","title":"DynamicPPL.AbstractAccumulator","text":"AbstractAccumulator\n\nAn abstract type for accumulators.\n\nAn accumulator is an object that may change its value at every tildeassume!! or tildeobserve!! call based on the random variable in question. The obvious examples of accumulators are the log prior and log likelihood. Other examples might be a variable that counts the number of observations in a trace, or a list of the names of random variables seen so far.\n\nAn accumulator type T <: AbstractAccumulator must implement the following methods:\n\naccumulator_name(acc::T) or accumulator_name(::Type{T})\naccumulate_observe!!(acc::T, dist, val, vn)\naccumulate_assume!!(acc::T, val, tval, logjac, vn, dist, template)\nreset(acc::T)\nBase.copy(acc::T)\n\nIn these functions:\n\nval is the new value of the random variable sampled from a distribution (always in the original unlinked space), or the value on the left-hand side of an observe statement.\ntval is the original AbstractTransformedValue that was obtained from the initialisation strategy. This is passed through unchanged to accumulate_assume!! since it can be reused for some accumulators (e.g. when storing linked values, if the linked value was already provided, it is faster to reuse it than to re-link val).\ndist is the distribution on the RHS of the tilde statement.\nvn is the VarName that is on the left-hand side of the tilde-statement. If the tilde-statement is a literal observation like 0.0 ~ Normal(), then vn is nothing.\nlogjac is the log determinant of the Jacobian of the link transformation, if the variable is stored as a linked value in the VarInfo. If the variable is stored in its original, unlinked form, then logjac is zero.\ntemplate is a value that conveys the shape of the top-level symbol in vn, and is used specifically for accumulators that carry VarNamedTuples.\n\nTo be able to work with multi-threading, it should also implement:\n\nsplit(acc::T)\ncombine(acc::T, acc2::T)\n\nSee the documentation for each of these functions for more details.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.LogPriorAccumulator","page":"API","title":"DynamicPPL.LogPriorAccumulator","text":"LogPriorAccumulator{T<:Real} <: LogProbAccumulator{T}\n\nAn accumulator that tracks the cumulative log prior during model execution.\n\nNote that the log prior stored in here is always calculated based on unlinked parameters, i.e., the value of logp is independent of whether tha VarInfo is linked or not.\n\nFields\n\nlogp::Real: the scalar log prior value\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.LogJacobianAccumulator","page":"API","title":"DynamicPPL.LogJacobianAccumulator","text":"LogJacobianAccumulator{T<:Real} <: LogProbAccumulator{T}\n\nAn accumulator that tracks the cumulative log Jacobian (technically, log(abs(det(J)))) during model execution. Specifically, J refers to the Jacobian of the link transform, i.e., from the space of the original distribution to unconstrained space.\n\nnote: Note\nThis accumulator is only incremented if the variable is transformed by a link function, i.e., if the VarInfo is linked (for the particular variable that is currently being accumulated). If the variable is not linked, the log Jacobian term will be 0.In general, for the forward Jacobian mathbfJ corresponding to the function mathbfy = f(mathbfx),log(q(mathbfy)) = log(p(mathbfx)) - log (mathbfJ)and correspondingly:getlogjoint_internal(vi) = getlogjoint(vi) - getlogjac(vi)\n\nFields\n\nlogjac::Real: the logabsdet of the link transform Jacobian\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.LogLikelihoodAccumulator","page":"API","title":"DynamicPPL.LogLikelihoodAccumulator","text":"LogLikelihoodAccumulator{T<:Real} <: LogProbAccumulator{T}\n\nAn accumulator that tracks the cumulative log likelihood during model execution.\n\nFields\n\nlogp::Real: the scalar log likelihood value\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.PriorDistributionAccumulator","page":"API","title":"DynamicPPL.PriorDistributionAccumulator","text":"PriorDistributionAccumulator()\n\nAn accumulator that stores the prior distributions of every variable seen in a model.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.VNTAccumulator","page":"API","title":"DynamicPPL.VNTAccumulator","text":"VNTAccumulator{AccName}(f::F, values::VarNamedTuple=VarNamedTuple()) where {AccName,F}\n\nA generic accumulator that applies a function f to values seen during model execution and stores the results in a VarNamedTuple.\n\nAccName is the name of the accumulator, and is exposed to allow users to define and use multiple forms of VNTAccumulator within the same set of accumulators. In theory, each VNTAccumulator with the same function f should use the same accumulator name. This is not enforced.\n\nThe function f should have the signature:\n\nf(val, tval, logjac, vn, dist) -> value_to_store\n\nwhere val, tval, logjac, vn, and dist have their usual meanings in accumulate_assume!! (see its docstring for more details). If a value does not need to be accumulated, this can be signalled by returning DoNotAccumulate() from f.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.DoNotAccumulate","page":"API","title":"DynamicPPL.DoNotAccumulate","text":"DoNotAccumulate()\n\nSentinel value indicating that no accumulation should be performed for a given variable.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.getlogp","page":"API","title":"DynamicPPL.getlogp","text":"getlogp(vi::AbstractVarInfo)\n\nReturn a NamedTuple of the log prior, log Jacobian, and log likelihood probabilities.\n\nThe keys are called logprior, logjac, and loglikelihood. If any of them are not present in vi an error will be thrown.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setlogp!!","page":"API","title":"DynamicPPL.setlogp!!","text":"setlogp!!(vi::AbstractVarInfo, logp::NamedTuple)\n\nSet both the log prior and the log likelihood probabilities in vi.\n\nlogp should have fields logprior and loglikelihood and no other fields.\n\nSee also: setlogprior!!, setloglikelihood!!, getlogp.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.acclogp!!","page":"API","title":"DynamicPPL.acclogp!!","text":"acclogp!!(vi::AbstractVarInfo, logp::NamedTuple; ignore_missing_accumulator::Bool=false)\n\nAdd to both the log prior and the log likelihood probabilities in vi.\n\nlogp should have fields logprior and/or loglikelihood, and no other fields.\n\nBy default if the necessary accumulators are not in vi an error is thrown. If ignore_missing_accumulator is set to true then this is silently ignored instead.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getlogjoint","page":"API","title":"DynamicPPL.getlogjoint","text":"getlogjoint(vi::AbstractVarInfo)\n\nReturn the log of the joint probability of the observed data and parameters in vi.\n\nSee also: getlogprior, getloglikelihood.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getlogjoint_internal","page":"API","title":"DynamicPPL.getlogjoint_internal","text":"getlogjoint_internal(vi::AbstractVarInfo)\n\nReturn the log of the joint probability of the observed data and parameters as they are stored internally in vi, including the log-Jacobian for any linked parameters.\n\nIn general, we have that:\n\ngetlogjoint_internal(vi) == getlogjoint(vi) - getlogjac(vi)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getlogjac","page":"API","title":"DynamicPPL.getlogjac","text":"getlogjac(vi::AbstractVarInfo)\n\nReturn the accumulated log-Jacobian term for any linked parameters in vi. The Jacobian here is taken with respect to the forward (link) transform.\n\nSee also: setlogjac!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setlogjac!!","page":"API","title":"DynamicPPL.setlogjac!!","text":"setlogjac!!(vi::AbstractVarInfo, logjac)\n\nSet the accumulated log-Jacobian term for any linked parameters in vi. The Jacobian here is taken with respect to the forward (link) transform.\n\nSee also: getlogjac, acclogjac!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.acclogjac!!","page":"API","title":"DynamicPPL.acclogjac!!","text":"acclogjac!!(vi::AbstractVarInfo, logjac)\n\nAdd logjac to the value of the log Jacobian in vi.\n\nSee also: getlogjac, setlogjac!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getlogprior","page":"API","title":"DynamicPPL.getlogprior","text":"getlogprior(vi::AbstractVarInfo)\n\nReturn the log of the prior probability of the parameters in vi.\n\nSee also: getlogjoint, getloglikelihood, setlogprior!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getlogprior_internal","page":"API","title":"DynamicPPL.getlogprior_internal","text":"getlogprior_internal(vi::AbstractVarInfo)\n\nReturn the log of the prior probability of the parameters as stored internally in vi. This includes the log-Jacobian for any linked parameters.\n\nIn general, we have that:\n\ngetlogprior_internal(vi) == getlogprior(vi) - getlogjac(vi)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setlogprior!!","page":"API","title":"DynamicPPL.setlogprior!!","text":"setlogprior!!(vi::AbstractVarInfo, logp)\n\nSet the log of the prior probability of the parameters sampled in vi to logp.\n\nSee also: setloglikelihood!!, setlogp!!, getlogprior.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.acclogprior!!","page":"API","title":"DynamicPPL.acclogprior!!","text":"acclogprior!!(vi::AbstractVarInfo, logp)\n\nAdd logp to the value of the log of the prior probability in vi.\n\nSee also: accloglikelihood!!, acclogp!!, getlogprior, setlogprior!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getloglikelihood","page":"API","title":"DynamicPPL.getloglikelihood","text":"getloglikelihood(vi::AbstractVarInfo)\n\nReturn the log of the likelihood probability of the observed data in vi.\n\nSee also: getlogjoint, getlogprior, setloglikelihood!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setloglikelihood!!","page":"API","title":"DynamicPPL.setloglikelihood!!","text":"setloglikelihood!!(vi::AbstractVarInfo, logp)\n\nSet the log of the likelihood probability of the observed data sampled in vi to logp.\n\nSee also: setlogprior!!, setlogp!!, getloglikelihood.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.accloglikelihood!!","page":"API","title":"DynamicPPL.accloglikelihood!!","text":"accloglikelihood!!(vi::AbstractVarInfo, logp)\n\nAdd logp to the value of the log of the likelihood in vi.\n\nSee also: accloglikelihood!!, acclogp!!, getloglikelihood, setloglikelihood!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.keys","page":"API","title":"Base.keys","text":"keys(vi::AbstractVarInfo)\n\nReturn an iterator over all vns in vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.getindex","page":"API","title":"Base.getindex","text":"getindex(vi::AbstractVarInfo, vn::VarName[, dist::Distribution])\ngetindex(vi::AbstractVarInfo, vns::Vector{<:VarName}[, dist::Distribution])\n\nReturn the current value(s) of vn (vns) in vi in the support of its (their) distribution(s).\n\nIf dist is specified, the value(s) will be massaged into the representation expected by dist.\n\n\n\n\n\n","category":"function"},{"location":"api/#BangBang.empty!!","page":"API","title":"BangBang.empty!!","text":"empty!!(vi::AbstractVarInfo)\n\nEmpty vi of variables and reset all accumulators.\n\nThis is useful when using a sampling algorithm that assumes an empty vi, e.g. SMC.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.isempty","page":"API","title":"Base.isempty","text":"isempty(vi::AbstractVarInfo)\n\nReturn true if vi is empty and false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getindex_internal","page":"API","title":"DynamicPPL.getindex_internal","text":"getindex_internal(vi::AbstractVarInfo, vn::VarName)\ngetindex_internal(vi::AbstractVarInfo, vns::Vector{<:VarName})\ngetindex_internal(vi::AbstractVarInfo, ::Colon)\n\nReturn the internal value of the varname vn, varnames vns, or all varnames in vi respectively. The internal value is the value of the variables that is stored in the varinfo object; this may be the actual realisation of the random variable (i.e. the value sampled from the distribution), or it may have been transformed to Euclidean space, depending on whether the varinfo was linked.\n\nSee https://turinglang.org/docs/developers/transforms/dynamicppl/ for more information on how transformed variables are stored in DynamicPPL.\n\nSee also: getindex(vi::AbstractVarInfo, vn::VarName, dist::Distribution)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setindex_internal!!","page":"API","title":"DynamicPPL.setindex_internal!!","text":"setindex_internal!!(vi::VarInfo, val, vn::VarName)\n\nSet the internal (vectorised) value of variable vn in vi to val.\n\nThis does not change the transformation or linked status of the variable.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.AbstractTransformation","page":"API","title":"DynamicPPL.AbstractTransformation","text":"abstract type AbstractTransformation\n\nRepresents a transformation to be used in link!! and invlink!!, amongst others.\n\nA concrete implementation of this should implement the following methods:\n\nlink!!: transforms the AbstractVarInfo to the unconstrained space.\ninvlink!!: transforms the AbstractVarInfo to the constrained space.\n\nAnd potentially:\n\nmaybe_invlink_before_eval!!: hook to decide whether to transform before evaluating the model.\n\nSee also: link!!, invlink!!, maybe_invlink_before_eval!!.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.NoTransformation","page":"API","title":"DynamicPPL.NoTransformation","text":"struct NoTransformation <: DynamicPPL.AbstractTransformation\n\nTransformation which applies the identity function.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.DynamicTransformation","page":"API","title":"DynamicPPL.DynamicTransformation","text":"struct DynamicTransformation <: DynamicPPL.AbstractTransformation\n\nTransformation which transforms the variables on a per-need-basis in the execution of a given Model.\n\nThis is in constrast to StaticTransformation which transforms all variables before the execution of a given Model.\n\nDifferent VarInfo types should implement their own methods for link!! and invlink!! for DynamicTransformation.\n\nSee also: StaticTransformation.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.StaticTransformation","page":"API","title":"DynamicPPL.StaticTransformation","text":"struct StaticTransformation{F} <: DynamicPPL.AbstractTransformation\n\nTransformation which transforms all variables before the execution of a given Model.\n\nThis is done through the maybe_invlink_before_eval!! method.\n\nSee also: DynamicTransformation, maybe_invlink_before_eval!!.\n\nFields\n\nbijector::Any: The function, assumed to implement the Bijectors interface, to be applied to the variables\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.AbstractLinkStrategy","page":"API","title":"DynamicPPL.AbstractLinkStrategy","text":"abstract type AbstractLinkStrategy end\n\nAn abstract type for strategies specifying which variables to link or unlink.\n\nSubtypes in DynamicPPL are LinkAll, UnlinkAll, LinkSome, and UnlinkSome.\n\nFor subtypes of AbstractLinkStrategy, the only method that needs to be overloaded is DynamicPPL.generate_linked_value.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.LinkAll","page":"API","title":"DynamicPPL.LinkAll","text":"LinkAll() <: AbstractLinkStrategy\n\nIndicate that all variables should be linked.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.UnlinkAll","page":"API","title":"DynamicPPL.UnlinkAll","text":"UnlinkAll() <: AbstractLinkStrategy\n\nIndicate that all variables should be unlinked.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.LinkSome","page":"API","title":"DynamicPPL.LinkSome","text":"LinkSome(vns) <: AbstractLinkStrategy\n\nIndicate that the variables in vns must be linked. The link statuses of other variables are preserved. vns should be some iterable collection of VarNames, although there is no strict type requirement.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.UnlinkSome","page":"API","title":"DynamicPPL.UnlinkSome","text":"UnlinkSome(vns}) <: AbstractLinkStrategy\n\nIndicate that the variables in vns must not Be linked. The link statuses of other variables are preserved. vns should be some iterable collection of VarNames, although there is no strict type requirement.\n\n\n\n\n\n","category":"type"},{"location":"api/#Bijectors.link","page":"API","title":"Bijectors.link","text":"link([t::AbstractTransformation, ]vi::AbstractVarInfo, model::Model)\nlink([t::AbstractTransformation, ]vi::AbstractVarInfo, vns::NTuple{N,VarName}, model::Model)\n\nTransform variables in vi to their linked space without mutating vi.\n\nEither transform all variables, or only ones specified in vns.\n\nUse the  transformation t, or default_transformation(model, vi) if one is not provided.\n\nSee also: default_transformation, invlink.\n\n\n\n\n\n","category":"function"},{"location":"api/#Bijectors.invlink","page":"API","title":"Bijectors.invlink","text":"invlink([t::AbstractTransformation, ]vi::AbstractVarInfo, model::Model)\ninvlink([t::AbstractTransformation, ]vi::AbstractVarInfo, vns::NTuple{N,VarName}, model::Model)\n\nTransform variables in vi to their constrained space without mutating vi.\n\nEither transform all variables, or only ones specified in vns.\n\nUse the (inverse of) transformation t, or default_transformation(model, vi) if one is not provided.\n\nSee also: default_transformation, link.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.link!!","page":"API","title":"DynamicPPL.link!!","text":"link!!([t::AbstractTransformation, ]vi::AbstractVarInfo, model::Model)\nlink!!([t::AbstractTransformation, ]vi::AbstractVarInfo, vns::NTuple{N,VarName}, model::Model)\n\nTransform variables in vi to their linked space, mutating vi if possible.\n\nEither transform all variables, or only ones specified in vns.\n\nUse the  transformation t, or default_transformation(model, vi) if one is not provided.\n\nSee also: default_transformation, invlink!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.invlink!!","page":"API","title":"DynamicPPL.invlink!!","text":"invlink!!([t::AbstractTransformation, ]vi::AbstractVarInfo, model::Model)\ninvlink!!([t::AbstractTransformation, ]vi::AbstractVarInfo, vns::NTuple{N,VarName}, model::Model)\n\nTransform variables in vi to their constrained space, mutating vi if possible.\n\nEither transform all variables, or only ones specified in vns.\n\nUse the (inverse of) transformation t, or default_transformation(model, vi) if one is not provided.\n\nSee also: default_transformation, link!!.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.update_link_status!!","page":"API","title":"DynamicPPL.update_link_status!!","text":"DynamicPPL.update_link_status!!(\n    orig_vi::VarInfo, linker::AbstractLinkStrategy, model::Model,\n)::VarInfo\n\nCreate a new VarInfo based on orig_vi, but with the link statuses of variables updated according to linker.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.generate_linked_value","page":"API","title":"DynamicPPL.generate_linked_value","text":"generate_linked_value(linker::AbstractLinkStrategy, vn::VarName)\n\nDetermine whether a variable with name vn should be linked according to the linker strategy. Returns true if the variable should be linked, and false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.transformation","page":"API","title":"DynamicPPL.transformation","text":"transformation(vi::AbstractVarInfo)\n\nReturn the AbstractTransformation related to vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.default_transformation","page":"API","title":"DynamicPPL.default_transformation","text":"default_transformation(model::Model[, vi::AbstractVarInfo])\n\nReturn the AbstractTransformation currently related to model and, potentially, vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.link_transform","page":"API","title":"DynamicPPL.link_transform","text":"link_transform(dist)\n\nReturn the constrained-to-unconstrained bijector for distribution dist.\n\nBy default, this is just Bijectors.bijector(dist).\n\nwarning: Warning\nNote that currently this is not used by Bijectors.logpdf_with_trans, hence that needs to be overloaded separately if the intention is to change behavior of an existing distribution.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.invlink_transform","page":"API","title":"DynamicPPL.invlink_transform","text":"invlink_transform(dist)\n\nReturn the unconstrained-to-constrained bijector for distribution dist.\n\nBy default, this is just inverse(link_transform(dist)).\n\nwarning: Warning\nNote that currently this is not used by Bijectors.logpdf_with_trans, hence that needs to be overloaded separately if the intention is to change behavior of an existing distribution.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.maybe_invlink_before_eval!!","page":"API","title":"DynamicPPL.maybe_invlink_before_eval!!","text":"maybe_invlink_before_eval!!([t::Transformation,] vi, model)\n\nReturn a possibly invlinked version of vi.\n\nThis will be called prior to model evaluation, allowing one to perform a single invlink!! before evaluation rather than lazyily evaluating the transforms on as-we-need basis as is done with DynamicTransformation.\n\nSee also: StaticTransformation, DynamicTransformation.\n\nExamples\n\njulia> using DynamicPPL, Distributions, Bijectors\n\njulia> @model demo() = x ~ Normal()\ndemo (generic function with 2 methods)\n\njulia> # By subtyping `Transform`, we inherit the `(inv)link!!`.\n       struct MyBijector <: Bijectors.Transform end\n\njulia> # Define some dummy `inverse` which will be used in the `link!!` call.\n       Bijectors.inverse(f::MyBijector) = identity\n\njulia> # We need to define `with_logabsdet_jacobian` for `MyBijector`\n       # (`identity` already has `with_logabsdet_jacobian` defined)\n       function Bijectors.with_logabsdet_jacobian(::MyBijector, x)\n           # Just using a large number of the logabsdet-jacobian term\n           # for demonstration purposes.\n           return (x, 1000)\n       end\n\njulia> # Change the `default_transformation` for our model to be a\n       # `StaticTransformation` using `MyBijector`.\n       function DynamicPPL.default_transformation(::Model{typeof(demo)})\n           return DynamicPPL.StaticTransformation(MyBijector())\n       end\n\njulia> model = demo();\n\njulia> vi = setindex!!(VarInfo(), 1.0, @varname(x));\n\njulia> vi[@varname(x)]\n1.0\n\njulia> vi_linked = link!!(vi, model);\n\njulia> # Now performs a single `invlink!!` before model evaluation.\n       logjoint(model, vi_linked)\n-1001.4189385332047\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.merge-Tuple{AbstractVarInfo}","page":"API","title":"Base.merge","text":"merge(varinfo, other_varinfos...)\n\nMerge varinfos into one, giving precedence to the right-most varinfo when sensible.\n\nThis is particularly useful when combined with subset(varinfo, vns).\n\nSee docstring of subset(varinfo, vns) for examples.\n\n\n\n\n\n","category":"method"},{"location":"api/#DynamicPPL.subset","page":"API","title":"DynamicPPL.subset","text":"subset(varinfo::AbstractVarInfo, vns::AbstractVector{<:VarName})\n\nSubset a varinfo to only contain the variables vns.\n\nThe ordering of variables in the return value will be the same as in varinfo.\n\nExamples\n\njulia> @model function demo()\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, sqrt(s))\n           x = Vector{Float64}(undef, 2)\n           x[1] ~ Normal(m, sqrt(s))\n           x[2] ~ Normal(m, sqrt(s))\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo();\n\njulia> vi = VarInfo(model);\n\njulia> keys(vi)\n4-element Vector{VarName}:\n s\n m\n x[1]\n x[2]\n\njulia> for (i, vn) in enumerate(keys(vi))\n           vi = DynamicPPL.setindex!!(vi, Float64(i), vn)\n       end\n\njulia> vi[[@varname(s), @varname(m), @varname(x[1]), @varname(x[2])]]\n4-element Vector{Float64}:\n 1.0\n 2.0\n 3.0\n 4.0\n\njulia> # Extract one with only `m`.\n       vi_subset1 = subset(vi, [@varname(m),]);\n\njulia> keys(vi_subset1)\n1-element Vector{VarName}:\n m\n\njulia> vi_subset1[@varname(m)]\n2.0\n\njulia> # Extract one with both `s` and `x[2]`.\n       vi_subset2 = subset(vi, [@varname(s), @varname(x[2])]);\n\njulia> keys(vi_subset2)\n2-element Vector{VarName}:\n s\n x[2]\n\njulia> vi_subset2[[@varname(s), @varname(x[2])]]\n2-element Vector{Float64}:\n 1.0\n 4.0\n\nsubset is particularly useful when combined with merge(vi::AbstractVarInfo)\n\njulia> # Merge the two.\n       vi_subset_merged = merge(vi_subset1, vi_subset2);\n\njulia> keys(vi_subset_merged)\n3-element Vector{VarName}:\n m\n s\n x[2]\n\njulia> vi_subset_merged[[@varname(s), @varname(m), @varname(x[2])]]\n3-element Vector{Float64}:\n 1.0\n 2.0\n 4.0\n\njulia> # Merge the two with the original.\n       vi_merged = merge(vi, vi_subset_merged);\n\njulia> keys(vi_merged)\n4-element Vector{VarName}:\n s\n m\n x[1]\n x[2]\n\njulia> vi_merged[[@varname(s), @varname(m), @varname(x[1]), @varname(x[2])]]\n4-element Vector{Float64}:\n 1.0\n 2.0\n 3.0\n 4.0\n\nNotes\n\nType-stability\n\nwarning: Warning\nThis function is only type-stable when vns contains only varnames with the same symbol. For example, [@varname(m[1]), @varname(m[2])] will be type-stable, but [@varname(m[1]), @varname(x)] will not be.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.unflatten!!","page":"API","title":"DynamicPPL.unflatten!!","text":"unflatten!!(vi::AbstractVarInfo, x::AbstractVector)\n\nReturn a new instance of vi with the values of x assigned to the variables.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.internal_values_as_vector","page":"API","title":"DynamicPPL.internal_values_as_vector","text":"internal_values_as_vector(vi::AbstractVarInfo)\n\nReturn all internal values stored in vi.values as a flattened Vector.\n\n\n\n\n\n","category":"function"},{"location":"api/#AbstractPPL.evaluate!!","page":"API","title":"AbstractPPL.evaluate!!","text":"evaluate!!(model::Model, varinfo)\n\nEvaluate the model with the given varinfo.\n\nIf the model has been marked as requiring threadsafe evaluation, are available, the varinfo provided will be wrapped in a ThreadSafeVarInfo before evaluation.\n\nReturns a tuple of the model's return value, plus the updated varinfo (unwrapped if necessary).\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.DefaultContext","page":"API","title":"DynamicPPL.DefaultContext","text":"struct DefaultContext <: AbstractContext end\n\nDefaultContext, as the name suggests, is the default context used when instantiating a model.\n\njulia> @model f() = x ~ Normal();\n\njulia> model = f(); model.context\nDefaultContext()\n\nAs an evaluation context, the behaviour of DefaultContext is to require all variables to be present in the AbstractVarInfo used for evaluation. Thus, semantically, evaluating a model with DefaultContext means 'calculating the log-probability associated with the variables in the AbstractVarInfo'.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.InitContext","page":"API","title":"DynamicPPL.InitContext","text":"InitContext(\n        [rng::Random.AbstractRNG=Random.default_rng()],\n        [strategy::AbstractInitStrategy=InitFromPrior()],\n)\n\nA leaf context that indicates that new values for random variables are currently being obtained through sampling. Used e.g. when initialising a fresh VarInfo. Note that, if leafcontext(model.context) isa InitContext, then evaluate!!(model, varinfo) will override all values in the VarInfo.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.tilde_assume!!","page":"API","title":"DynamicPPL.tilde_assume!!","text":"DynamicPPL.tilde_assume!!(\n    context::AbstractContext,\n    right::Distribution,\n    vn::VarName,\n    template::Any,\n    vi::AbstractVarInfo\n)::Tuple{Any,AbstractVarInfo}\n\nHandle assumed variables, i.e. anything which is not observed (see tilde_observe!!). Accumulate the associated log probability, and return the sampled value and updated vi.\n\nvn is the VarName on the left-hand side of the tilde statement.\n\ntemplate is the value of the top-level symbol in vn.\n\nThis function should return a tuple (x, vi), where x is the sampled value (which must be untransformed, i.e., insupport(right, x) must be true!) and vi is the updated VarInfo.\n\n\n\n\n\nDynamicPPL.tilde_assume!!(\n    ::DefaultContext,\n    right::Distribution,\n    vn::VarName,\n    template::Any,\n    vi::AbstractVarInfo\n)\n\nHandle assumed variables. For DefaultContext, this function extracts the value associated with vn from vi, If vi does not contain an appropriate value then this will error.\n\n\n\n\n\nDynamicPPL.tilde_assume!!(\n    context::AbstractContext,\n    right::DynamicPPL.Submodel,\n    vn::VarName,\n    ::Any,\n    vi::AbstractVarInfo\n)\n\nEvaluate the submodel with the given context.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.tilde_observe!!","page":"API","title":"DynamicPPL.tilde_observe!!","text":"DynamicPPL.tilde_observe!!(\n    context::AbstractContext,\n    right::Distribution,\n    left,\n    vn::Union{VarName, Nothing},\n    vi::AbstractVarInfo\n)::Tuple{Any,AbstractVarInfo}\n\nThis function handles observed variables, which may be:\n\nliterals on the left-hand side, e.g., 3.0 ~ Normal()\na model input, e.g. x ~ Normal() in a model @model f(x) ... end\na conditioned or fixed variable, e.g. x ~ Normal() in a model model | (; x = 3.0).\n\nThe relevant log-probability associated with the observation is computed and accumulated in the VarInfo object vi (except for fixed variables, which do not contribute to the log-probability).\n\nleft is the actual value that the left-hand side evaluates to. vn is the VarName on the left-hand side, or nothing if the left-hand side is a literal value.\n\nObservations of submodels are not yet supported in DynamicPPL.\n\nThis function should return a tuple (left, vi), where left is the same as the input, and vi is the updated VarInfo.\n\n\n\n\n\nDynamicPPL.tilde_observe!!(\n    ::DefaultContext,\n    right::Distribution,\n    left,\n    vn::Union{VarName,Nothing},\n    vi::AbstractVarInfo,\n)\n\nHandle observed variables. This just accumulates the log-likelihood for left.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.AbstractParentContext","page":"API","title":"DynamicPPL.AbstractParentContext","text":"AbstractParentContext\n\nAn abstract context that has a child context.\n\nSubtypes of AbstractParentContext must implement the following interface:\n\nDynamicPPL.childcontext(context::AbstractParentContext): Return the child context.\nDynamicPPL.setchildcontext(parent::AbstractParentContext, child::AbstractContext): Reconstruct parent but now using child as its child context.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.childcontext","page":"API","title":"DynamicPPL.childcontext","text":"childcontext(context::AbstractParentContext)\n\nReturn the descendant context of context.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setchildcontext","page":"API","title":"DynamicPPL.setchildcontext","text":"setchildcontext(parent::AbstractParentContext, child::AbstractContext)\n\nReconstruct parent but now using child is its childcontext, effectively updating the child context.\n\nExamples\n\njulia> using DynamicPPL: InitContext, CondFixContext, Condition\n\njulia> ctx = CondFixContext{Condition}(VarNamedTuple(; a = 1));\n\njulia> DynamicPPL.childcontext(ctx)\nDefaultContext()\n\njulia> ctx_prior = DynamicPPL.setchildcontext(ctx, InitContext(MersenneTwister(23), InitFromPrior()));\n\njulia> DynamicPPL.childcontext(ctx_prior)\nInitContext{MersenneTwister, InitFromPrior}(MersenneTwister(23), InitFromPrior())\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.leafcontext","page":"API","title":"DynamicPPL.leafcontext","text":"leafcontext(context::AbstractContext)\n\nReturn the leaf of context, i.e. the first descendant context that is not an AbstractParentContext.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setleafcontext","page":"API","title":"DynamicPPL.setleafcontext","text":"setleafcontext(left::AbstractContext, right::AbstractContext)\n\nReturn left but now with its leaf context replaced by right.\n\nNote that this also works even if right is not a leaf context, in which case effectively append right to left, dropping the original leaf context of left.\n\nExamples\n\njulia> using DynamicPPL: leafcontext, setleafcontext, childcontext, setchildcontext, AbstractContext, InitContext\n\njulia> struct ParentContext{C} <: AbstractParentContext\n           context::C\n       end\n\njulia> DynamicPPL.childcontext(context::ParentContext) = context.context\n\njulia> DynamicPPL.setchildcontext(::ParentContext, child) = ParentContext(child)\n\njulia> Base.show(io::IO, c::ParentContext) = print(io, \"ParentContext(\", childcontext(c), \")\")\n\njulia> ctx = ParentContext(ParentContext(DefaultContext()))\nParentContext(ParentContext(DefaultContext()))\n\njulia> # Replace the leaf context with another leaf.\n       leafcontext(setleafcontext(ctx, InitContext(MersenneTwister(23), InitFromPrior())))\nInitContext{MersenneTwister, InitFromPrior}(MersenneTwister(23), InitFromPrior())\n\njulia> # Append another parent context.\n       setleafcontext(ctx, ParentContext(DefaultContext()))\nParentContext(ParentContext(ParentContext(DefaultContext())))\n\n\n\n\n\nsetleafcontext(model::Model, context::AbstractContext)\n\nReturn a new Model with its leaf context set to context. This is a convenience shortcut for contextualize(model, setleafcontext(model.context, context)).\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.init!!","page":"API","title":"DynamicPPL.init!!","text":"init!!(\n    [rng::Random.AbstractRNG,]\n    model::Model,\n    varinfo::AbstractVarInfo,\n    [init_strategy::AbstractInitStrategy=InitFromPrior()]\n)\n\nEvaluate the model and replace the values of the model's random variables in the given varinfo with new values, using a specified initialisation strategy. If the values in varinfo are not set, they will be added using a specified initialisation strategy.\n\nIf init_strategy is not provided, defaults to InitFromPrior().\n\nReturns a tuple of the model's return value, plus the updated varinfo object.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.InitFromPrior","page":"API","title":"DynamicPPL.InitFromPrior","text":"InitFromPrior()\n\nObtain new values by sampling from the prior distribution.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.InitFromUniform","page":"API","title":"DynamicPPL.InitFromUniform","text":"InitFromUniform()\nInitFromUniform(lower, upper)\n\nObtain new values by first transforming the distribution of the random variable to unconstrained space, then sampling a value uniformly between lower and upper, and transforming that value back to the original space.\n\nIf lower and upper are unspecified, they default to (-2, 2), which mimics Stan's default initialisation strategy.\n\nRequires that lower <= upper.\n\nReferences\n\nStan reference manual page on initialization\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.InitFromParams","page":"API","title":"DynamicPPL.InitFromParams","text":"InitFromParams(\n    params::Any\n    fallback::Union{AbstractInitStrategy,Nothing}=InitFromPrior()\n)\n\nObtain new values by extracting them from the given set of params.\n\nThe most common use case is to provide a NamedTuple or AbstractDict{<:VarName}, which provides a mapping from variable names to values. However, we leave the type of params open in order to allow for custom parameter storage types.\n\nCustom parameter storage types\n\nFor InitFromParams to work correctly with a custom params::P, you need to implement\n\nDynamicPPL.init(rng, vn::VarName, dist::Distribution, p::InitFromParams{P}) where {P}\n\nThis tells you how to obtain values for the random variable vn from p.params. Note that the last argument is InitFromParams(params), not just params itself. Please see the docstring of DynamicPPL.init for more information on the expected behaviour.\n\nIf you only use InitFromParams with DynamicPPL.OnlyAccsVarInfo, as is usually the case, then you will not need to implement anything else. So far, this is the same as you would do for creating any new AbstractInitStrategy subtype.\n\nHowever, to use InitFromParams with a full DynamicPPL.VarInfo, you may also need to implement\n\nDynamicPPL.get_param_eltype(p::InitFromParams{P}) where {P}\n\nSee the docstring of DynamicPPL.get_param_eltype for more information on when this is needed.\n\nThe argument fallback specifies how new values are to be obtained if they cannot be found in params, or they are specified as missing. fallback can either be an initialisation strategy itself, in which case it will be used to obtain new values, or it can be nothing, in which case an error will be thrown. The default for fallback is InitFromPrior().\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.AbstractInitStrategy","page":"API","title":"DynamicPPL.AbstractInitStrategy","text":"AbstractInitStrategy\n\nAbstract type representing the possible ways of initialising new values for the random variables in a model (e.g., when creating a new VarInfo).\n\nAny subtype of AbstractInitStrategy must implement the DynamicPPL.init method, and in some cases, DynamicPPL.get_param_eltype (see its docstring for details).\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.init","page":"API","title":"DynamicPPL.init","text":"init(rng::Random.AbstractRNG, vn::VarName, dist::Distribution, strategy::AbstractInitStrategy)\n\nGenerate a new value for a random variable with the given distribution.\n\nThis function must return an AbstractTransformedValue.\n\nIf strategy provides values that are already untransformed (e.g., a Float64 within (0, 1) for dist::Beta, then you should return an UntransformedValue.\n\nOtherwise, often there are cases where this will return either a VectorValue or a LinkedVectorValue, for example, if the strategy is reading from an existing VarInfo.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.get_param_eltype","page":"API","title":"DynamicPPL.get_param_eltype","text":"DynamicPPL.get_param_eltype(strategy::AbstractInitStrategy)\n\nReturn the element type of the parameters generated from the given initialisation strategy.\n\nThe default implementation returns Any. However, for InitFromParams which provides known parameters for evaluating the model, methods are implemented in order to return more specific types.\n\nIn general, if you are implementing a custom AbstractInitStrategy, correct behaviour can only be guaranteed if you implement this method as well. However, quite often, the default return value of Any will actually suffice. The cases where this does not suffice, and where you do have to manually implement get_param_eltype, are explained in the extended help (see ??DynamicPPL.get_param_eltype in the REPL).\n\nExtended help\n\nThere are a few edge cases in DynamicPPL where the element type is needed. These largely relate to determining the element type of accumulators ahead of time (before evaluation), as well as promoting type parameters in model arguments. The classic case is when evaluating a model with ForwardDiff: the accumulators must be set to Duals, and any Vector{Float64} arguments must be promoted to Vector{Dual}. Other tracer types, for example those in SparseConnectivityTracer.jl, also require similar treatment.\n\nIf the AbstractInitStrategy is never used in combination with tracer types, then it is perfectly safe to return Any. This does not lead to type instability downstream because the actual accumulators will still be created with concrete Float types (the Any is just used to determine whether the float type needs to be modified).\n\nIn case that wasn't enough: in fact, even the above is not always true. Firstly, the accumulator argument is only true when evaluating with ThreadSafeVarInfo. See the comments in DynamicPPL.unflatten!! for more details. For non-threadsafe evaluation, Julia is capable of automatically promoting the types on its own. Secondly, the promotion only matters if you are trying to directly assign into a Vector{Float64} with a ForwardDiff.Dual or similar tracer type, for example using xs[i] = MyDual. This doesn't actually apply to tilde-statements like xs[i] ~ ... because those use Accessors.set under the hood, which also does the promotion for you. For the gory details, see the following issues:\n\nhttps://github.com/TuringLang/DynamicPPL.jl/issues/906 for accumulator types\nhttps://github.com/TuringLang/DynamicPPL.jl/issues/823 for type argument promotion\n\n\n\n\n\nget_param_eltype(varinfo::AbstractVarInfo, context::AbstractContext)\n\nGet the element type of the parameters being used to evaluate a model, using a varinfo under the given context. For example, when evaluating a model with ForwardDiff AD, this should return ForwardDiff.Dual.\n\nBy default, this uses eltype(varinfo) which is slightly cursed. This relies on the fact that typically, before evaluation, the parameters will have been inserted into the VarInfo's metadata field.\n\nFor InitContext, it's quite different: because InitContext is responsible for supplying the parameters, we can avoid using eltype(varinfo) and instead query the parameters inside it. See the docstring of get_param_eltype(strategy::AbstractInitStrategy) for more explanation.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.AbstractTransformedValue","page":"API","title":"DynamicPPL.AbstractTransformedValue","text":"AbstractTransformedValue\n\nAn abstract type for values that enter the DynamicPPL tilde-pipeline.\n\nThese values are generated by an AbstractInitStrategy: the function DynamicPPL.init should return an AbstractTransformedValue.\n\nEach AbstractTransformedValue contains some version of the actual variable's value, together with a transformation that can be used to convert the internal value back to the original space.\n\nCurrent subtypes are VectorValue, LinkedVectorValue, and UntransformedValue. DynamicPPL's VarInfo type stores either VectorValues or LinkedVectorValues internally, depending on the link status of the VarInfo.\n\nwarning: Warning\nEven though the subtypes listed above are public, this abstract type is not itself part of the public API and should not be subtyped by end users. Much of DynamicPPL's model evaluation methods depends on these subtypes having predictable behaviour, i.e., their transforms should always be from_linked_vec_transform(dist), from_vec_transform(dist), or their inverse. If you create a new subtype of AbstractTransformedValue and use it, DynamicPPL will not know how to handle it and may either error or silently give incorrect results.In principle, it should be possible to subtype this and allow for custom transformations to be used (not just the 'default' ones). However, this is not currently implemented.\n\nSubtypes of this should implement the following functions:\n\nDynamicPPL.get_transform(tv::AbstractTransformedValue): Get the transformation that converts the internal value back to the original space.\nDynamicPPL.get_internal_value(tv::AbstractTransformedValue): Get the internal value stored in tv.\nDynamicPPL.set_internal_value(tv::AbstractTransformedValue, new_val): Create a new AbstractTransformedValue with the same transformation as tv, but with internal value new_val.\nDynamicPPL.VarNamedTuples.vnt_size(tv::AbstractTransformedValue): Get the size of the original value before transformation.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.VectorValue","page":"API","title":"DynamicPPL.VectorValue","text":"VectorValue{V<:AbstractVector,T,S}\n\nA transformed value that stores its internal value as a vectorised form. This is what VarInfo sees as an \"unlinked value\".\n\nThese values can be generated when using InitFromParams with a VarInfo's internal values.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.LinkedVectorValue","page":"API","title":"DynamicPPL.LinkedVectorValue","text":"LinkedVectorValue{V<:AbstractVector,T,S}\n\nA transformed value that stores its internal value as a linked andvectorised form. This is what VarInfo sees as a \"linked value\".\n\nThese values can be generated when using InitFromParams with a VarInfo's internal values.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.UntransformedValue","page":"API","title":"DynamicPPL.UntransformedValue","text":"UntransformedValue{V}\n\nA raw, untransformed, value.\n\nThese values can be generated from initialisation strategies such as InitFromPrior, InitFromUniform, and InitFromParams on a standard container type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.get_transform","page":"API","title":"DynamicPPL.get_transform","text":"get_transform(tv::AbstractTransformedValue)\n\nGet the transformation that converts the internal value back to the raw value.\n\nwarning: Warning\nIf the distribution associated with the variable has changed since this AbstractTransformedValue was created, this transform may be inaccurate. This can happen e.g. if unflatten!! has been called on a VarInfo containing this.Consequently, when the distribution on the right-hand side of a tilde-statement is available, you should always prefer regenerating the transform from that distribution rather than using this function.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.get_internal_value","page":"API","title":"DynamicPPL.get_internal_value","text":"get_internal_value(tv::AbstractTransformedValue)\n\nGet the internal value stored in tv.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.set_internal_value","page":"API","title":"DynamicPPL.set_internal_value","text":"set_internal_value(tv::AbstractTransformedValue, new_val)\n\nCreate a new AbstractTransformedValue with the same transformation as tv, but with internal value new_val.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.ParamsWithStats","page":"API","title":"DynamicPPL.ParamsWithStats","text":"ParamsWithStats\n\nA struct which contains parameter values extracted from a VarInfo, along with any statistics associated with the VarInfo. The statistics are provided as a NamedTuple and are optional.\n\n\n\n\n\n","category":"type"},{"location":"api/#AbstractMCMC.from_samples-Tuple{Type{Chains}, AbstractMatrix{<:ParamsWithStats}}","page":"API","title":"AbstractMCMC.from_samples","text":"AbstractMCMC.from_samples(\n    ::Type{MCMCChains.Chains},\n    params_and_stats::AbstractMatrix{<:DynamicPPL.ParamsWithStats}\n)\n\nConvert an array of DynamicPPL.ParamsWithStats to an MCMCChains.Chains object.\n\n\n\n\n\n","category":"method"},{"location":"api/#AbstractMCMC.to_samples-Tuple{Type{ParamsWithStats}, Chains}","page":"API","title":"AbstractMCMC.to_samples","text":"AbstractMCMC.to_samples(\n    ::Type{DynamicPPL.ParamsWithStats},\n    chain::MCMCChains.Chains,\n)\n\nConvert an MCMCChains.Chains object to an array of DynamicPPL.ParamsWithStats.\n\nFor this to work, chain must contain the varname_to_symbol mapping in its info field.\n\n\n\n\n\n","category":"method"},{"location":"vnt/design/#Design","page":"Design","title":"Design","text":"There are two aspects to the design of VarNamedTuples: property access, and indexing. VarNamedTuple consists of recursively nested NamedTuples and PartialArrays which together support both kinds of access.","category":"section"},{"location":"vnt/design/#Property-access","page":"Design","title":"Property access","text":"Let's first talk about the NamedTuple part. In a VarNamedTuple each level of a Property optic corresponds to a level of nested NamedTuples, with the Symbols of the lenses as keys. For instance, the VarNamedTuple mapping @varname(x) => 1, @varname(y.z) => 2 would be stored as\n\nVarNamedTuple(; x=1, y=VarNamedTuple(; z=2))\n\nwhere VarNamedTuple(; x=a, y=b) is just a thin wrapper around the NamedTuple (; x=a, y=b). In fact, if vnt is a VarNamedTuple, then vnt.data is exactly that underlying NamedTuple.\n\nIt's often handy to think of this as a tree, with each node being a VarNamedTuple, like so:\n\n   VNT\nx /   \\ y\n 1     VNT\n         \\ z\n          2\n\nBy virtue of these being NamedTuple, all variable access is completely type-stable.\n\nIf all VarNames consisted of only Propertyes we would be done designing the data structure. Sadly, that isn't the case!","category":"section"},{"location":"vnt/design/#Indexing-and-PartialArrays","page":"Design","title":"Indexing and PartialArrays","text":"Indexing is much more complicated to handle than property access, for a number of reasons.\n\nLet's start by talking about the most obvious issue: only some parts of an array may be set. For example, the user may set x[1] and x[10] but not the ones in the middle. This is accomplished using a PartialArray, which is a wrapper around an AbstractArray that holds the data of interest, together with a mask saying which elements have been set.\n\nThe array type and size of the mask is always the same as the data array (this is done using Base.similar).\n\ninfo: Info\nCurrently this is not enforced in an inner constructor, because that sometimes leads to extra allocations. It would be nice to investigate if this invariant can be enforced.\n\nIf pa.mask[i] is true, then pa.data[i] has been set; otherwise, pa.data[i] may contain some value, but it is not valid to index into that part of the array.\n\nHere is an example:\n\nusing DynamicPPL.VarNamedTuples: PartialArray\n\ndata = randn(3)\nmask = similar(data, Bool)\nfill!(mask, false)\npa = PartialArray(data, mask)\n\nThe main way of interacting with a PartialArray is to use BangBang.setindex!!. This sets one or more elements of the PartialArray's data, and marks the corresponding elements in the mask as true.\n\nusing BangBang: setindex!!\n\nsetindex!!(pa, 12.0, 2)\npa.data, pa.mask\n\nWhen printed, pa shows only the elements that are set:\n\npa\n\nIt is invalid to index into the unset elements:\n\npa[1]\n\nbut you can access the set elements:\n\npa[2]\n\nIt follows from this, that because the PartialArray is actually backed by a regular Array, it is constructive. The call to getindex will return the values stored in pa.data, as long as all the elements in pa.mask are set. For example:\n\nsetindex!!(pa, 11.0, 1)\npa[1:2]\n\nYou can even get the entirety of the array, once you have set all three elements. In this case, the PartialArray is (morally) equivalent to a single Array.\n\nsetindex!!(pa, 13.0, 3)\npa[:]\n\nAll Index optics in VarNames correspond to PartialArrays in VarNamedTuples. For example, let's say we want to store the mappings @varname(x[1].a) => 1.0, and y.b[2,3] => 2.0. The corresponding VarNamedTuple would look like this:\n\n         VNT\n        /   \\y  \n      x/     \\    b\n      /     VNT------PA[[ _, _, _  ],\n     /                  [ _, _, 2.0]]\n    PA [VNT]\n         |\n        a|\n         |\n        1.0\n\nwhere _ indicates masked elements in a PartialArray. To demonstrate:\n\nusing DynamicPPL\n\nvnt = VarNamedTuple()\nvnt = setindex!!(vnt, 1.0, @varname(x[1].a))\nvnt = setindex!!(vnt, 2.0, @varname(y.b[2, 3]))\n\nvnt.data.x  # This is a PartialArray\n\nvnt.data.x.data[1]   # This is a VNT\n\nvnt.data.x.data[1].data.a  # This is 1.0\n\nvnt.data.y  # This is a VNT\n\nvnt.data.y.data.b  # This is a PartialArray\n\nvnt.data.y.data.b.data[2, 3]  # This is 2.0\n\nThis illustrates the fundamental structure of VarNamedTuples. From this example, one can see that getting data from a VarNamedTuple is as type-stable as possible:\n\nAll property accesses are NamedTuple accesses, which are type-stable.\nAll indexing is done into PartialArrays: as long as indexing into the underlying data is type-stable (i.e., the element type of the data array is concrete), indexing into the PartialArray is type-stable as well.\n\ninfo: Info\nIn fact, the underlying data need not all have the same (concrete) type: all that is needed is that the unmasked elements have the same (concrete) type. The function _concretise_eltype!! is an attempt to force this to be the case: if the element type is abstract, but all the set elements have the same concrete type, the entire data array's element type will be changed to that concrete type (with junk in the unset elements).\n\nOne immediate question here is: how do we know what kind of array the PartialArray should use for its data and mask?","category":"section"},{"location":"vnt/design/#GrowableArrays","page":"Design","title":"GrowableArrays","text":"It's not obvious in the code above, but in the example above, we are implicitly making an assumption based on the indices that we see in the VarNames. For example, for @varname(x[1].a), based on the index 1 we assume that x should be a vector with a length of at least 1. Similarly, for @varname(y.b[2,3]), we assume that y.b should be a matrix with at least 2 rows and 3 columns.\n\nWe can inspect this by looking into the PartialArrays:\n\nvnt.data.x.data\n\nvnt.data.y.data.b.data\n\nSo, these PartialArrays are backed by something called GrowableArray. A GrowableArray is an array type, defined in DynamicPPL, that can grow in size as needed when setindex!! is called with indices outside of its current bounds (with other arrays that would error). The reason for such an array type is that you may want to do something like\n\nbegin\n    local vnt = VarNamedTuple()\n    for i in 1:5\n        vnt = setindex!!(vnt, i, @varname(x[i]))\n    end\n    vnt\nend\n\nand we don't have the ability to know in advance that x will eventually need to be at least of size 5. So, every call to setindex!! here will cause the underlying GrowableArray to grow in size as needed.\n\nThe problem with this is that it makes a huge number of implicit assumptions about what kind of array x actually is, and consequently it forbids a huge number of indexing operations in Julia.\n\nThese include, for example, linear indexing. In this example, the first call will create a GrowableArray with one dimension (i.e., a vector); and the second call will fail since we can't index a vector with two indices.\n\nvnt = setindex!!(VarNamedTuple(), 10.0, @varname(x[1]))\nvnt = setindex!!(vnt, 20.0, @varname(x[2, 2]))\n\nColons also don't work.\n\nvnt = setindex!!(VarNamedTuple(), randn(2), @varname(x[:]))\n\nOther things like OffsetArrays don't work (because x[11] would create a length-11 GrowableArray, which might not be appropriate; and x[-1] will just straight-up error). DimArrays will also fail if you use an index that isn't an integer.\n\nFinally, we don't know how large the final size of the array should be. If you try to access the entire array after setting some elements, it will work, but it will warn you:\n\nvnt = setindex!!(VarNamedTuple(), 10.0, @varname(x[1]))\nvnt[@varname(x)]","category":"section"},{"location":"vnt/design/#Templated-arrays","page":"Design","title":"Templated arrays","text":"The general solution to this problem is for the user to provide a template for the array x in advance, so that we know what kind of array to create when we see @varname(x[...]).\n\nAt a low level, this is done using the DynamicPPL.templated_setindex!! function, which takes an extra argument that specifies the shape of the top-level symbol in the VarName.\n\nFor example, the linear-indexing example above now works if you tell the function that x is a 2-by-2 matrix.\n\nusing DynamicPPL: templated_setindex!!\n\nx = zeros(2, 2)\nvnt = VarNamedTuple()\nvnt = templated_setindex!!(VarNamedTuple(), 10.0, @varname(x[1]), x)\nvnt = setindex!!(vnt, 20.0, @varname(x[2, 2]))\n\n(The second call can also be templated_setindex!!, but it isn't necessary since the first call already establishes the shape of x, and indeed in such a case the template will be ignored.) Notice that the PartialArray is now backed by the correct Array:\n\nvnt.data.x.data\n\nIt is no longer growable, so if you try to set an out-of-bounds index, it will error:\n\nvnt = setindex!!(vnt, 30.0, @varname(x[3, 1]))\n\nThis mechanism makes it far more flexible to work with arrays in DynamicPPL models. Fundamentally, this resolves the inconsistency between indexing semantics in the model, and indexing semantics inside the VarNamedTuple.\n\nFor example, you can use DimArrays:\n\nimport DimensionalData as DD\n\nx = DD.DimArray(zeros(2, 3), (DD.X, DD.Y))\n\nvnt = VarNamedTuple()\nvnt = templated_setindex!!(vnt, 1.0, @varname(x[DD.X(1), DD.Y(2)]), x)\n\nvnt.data.x.data\n\nYou can access the data back again in any way you like, for example using linear indexing here:\n\ngetindex(vnt, @varname(x[3]))\n\ninfo: Info\nNote that support for such arrays is contingent on the provider of the array type, as well as BangBang.jl. There may be bugs that prevent some array types from fully working correctly. For example, BangBang.setindex!! does not accept keyword arguments, which precludes the use of keyword indices in DimArrays. However, DynamicPPL itself does not inherently prevent you from using such arrays. We would definitely like to fix upstream issues like these, but we don't always have the time to do so: help is very greatly appreciated!","category":"section"},{"location":"vnt/design/#How-do-we-provide-the-template?","page":"Design","title":"How do we provide the template?","text":"At this point, it would seem like a major faff for users to have to provide templates any time they wanted to use a VarNamedTuple. The good news is, within a DynamicPPL model, the template always exists. For example, consider:\n\nusing Distributions\n@model function bad_index()\n    return x[1] ~ Normal()\nend\nnothing # hide\n\nIf you were to attempt to execute this model, even without any interaction with VarNamedTuples, this would error, because there is no array x to set the first element in. It would be like writing a function that does x[1] = 10 without ever defining y:\n\nfunction bad_index_not_model()\n    return x[1] = 10\nend\nbad_index_not_model()\n\nThe model can only work if x is already provided, e.g. as an argument or a variable inside the model:\n\n@model function ok_index1(x::AbstractArray)\n    return x[1] ~ Normal()\nend\n\n@model function ok_index2()\n    x = Vector{Float64}(undef, 10)\n    return x[1] ~ Normal()\nend\nnothing # hide\n\nIn both cases, we do have access to the template for x. Thus, this is just a matter of plumbing this information through to DynamicPPL.tilde_assume!! so that it can be used when setting values in the VarNamedTuple. In the macro output below, you can see that x is passed as one of the arguments to tilde_assume!!.\n\n@macroexpand @model function bad_index()\n    return x[1] ~ Normal()\nend\n\nWhat this means is that in the core use case of VarNamedTuple (i.e., for storing random variables in DynamicPPL models), templates will always be provided. There are, for the most part, only two places where templates are unavailable, and we have to fall back on the GrowableArray approach:\n\nLoading data from chains.\nProviding conditioned or fixed values.\n\nThe first of these can be fixed by rerunning the model once to pick up the templates. The second cannot be truly fixed, but the DynamicPPL.@vnt macro allows users to manually provide templates themselves in cases where they are really needed.\n\n","category":"section"},{"location":"#DynamicPPL.jl","page":"Home","title":"DynamicPPL.jl","text":"A domain-specific language and backend for probabilistic programming languages, used by Turing.jl.\n\n","category":"section"}]
}
