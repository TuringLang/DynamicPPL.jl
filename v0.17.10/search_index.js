var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Part of the API of DynamicPPL is defined in the more lightweight interface package AbstractPPL.jl and reexported here.","category":"page"},{"location":"api/#Model","page":"API","title":"Model","text":"","category":"section"},{"location":"api/#Macros","page":"API","title":"Macros","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"A core component of DynamicPPL is the @model macro. It can be used to define probabilistic models in an intuitive way by specifying random variables and their distributions with ~ statements. These statements are rewritten by @model as calls of internal functions for sampling the variables and computing their log densities.","category":"page"},{"location":"api/","page":"API","title":"API","text":"@model","category":"page"},{"location":"api/#DynamicPPL.@model","page":"API","title":"DynamicPPL.@model","text":"@model(expr[, warn = false])\n\nMacro to specify a probabilistic model.\n\nIf warn is true, a warning is displayed if internal variable names are used in the model definition.\n\nExamples\n\nModel definition:\n\n@model function model(x, y = 42)\n    ...\nend\n\nTo generate a Model, call model(xvalue) or model(xvalue, yvalue).\n\n\n\n\n\n","category":"macro"},{"location":"api/","page":"API","title":"API","text":"One can nest models and call another model inside the model function with @submodel.","category":"page"},{"location":"api/","page":"API","title":"API","text":"@submodel","category":"page"},{"location":"api/#DynamicPPL.@submodel","page":"API","title":"DynamicPPL.@submodel","text":"@submodel model\n@submodel ... = model\n\nRun a Turing model nested inside of a Turing model.\n\nExamples\n\njulia> @model function demo1(x)\n           x ~ Normal()\n           return 1 + abs(x)\n       end;\n\njulia> @model function demo2(x, y)\n            @submodel a = demo1(x)\n            return y ~ Uniform(0, a)\n       end;\n\nWhen we sample from the model demo2(missing, 0.4) random variable x will be sampled:\n\njulia> vi = VarInfo(demo2(missing, 0.4));\n\njulia> @varname(x) in keys(vi)\ntrue\n\nVariable a is not tracked since it can be computed from the random variable x that was tracked when running demo1:\n\njulia> @varname(a) in keys(vi)\nfalse\n\nWe can check that the log joint probability of the model accumulated in vi is correct:\n\njulia> x = vi[@varname(x)];\n\njulia> getlogp(vi) ≈ logpdf(Normal(), x) + logpdf(Uniform(0, 1 + abs(x)), 0.4)\ntrue\n\n\n\n\n\n@submodel prefix=... model\n@submodel prefix=... ... = model\n\nRun a Turing model nested inside of a Turing model and add \"prefix.\" as a prefix to all random variables inside of the model.\n\nValid expressions for prefix=... are:\n\nprefix=false: no prefix is used.\nprefix=true: attempt to automatically determine the prefix from the left-hand side ... = model by first converting into a VarName, and then calling Symbol on this.\nprefix=expression: results in the prefix Symbol(expression).\n\nThe prefix makes it possible to run the same Turing model multiple times while keeping track of all random variables correctly.\n\nExamples\n\nExample models\n\njulia> @model function demo1(x)\n           x ~ Normal()\n           return 1 + abs(x)\n       end;\n\njulia> @model function demo2(x, y, z)\n            @submodel prefix=\"sub1\" a = demo1(x)\n            @submodel prefix=\"sub2\" b = demo1(y)\n            return z ~ Uniform(-a, b)\n       end;\n\nWhen we sample from the model demo2(missing, missing, 0.4) random variables sub1.x and sub2.x will be sampled:\n\njulia> vi = VarInfo(demo2(missing, missing, 0.4));\n\njulia> @varname(var\"sub1.x\") in keys(vi)\ntrue\n\njulia> @varname(var\"sub2.x\") in keys(vi)\ntrue\n\nVariables a and b are not tracked since they can be computed from the random variables sub1.x and sub2.x that were tracked when running demo1:\n\njulia> @varname(a) in keys(vi)\nfalse\n\njulia> @varname(b) in keys(vi)\nfalse\n\nWe can check that the log joint probability of the model accumulated in vi is correct:\n\njulia> sub1_x = vi[@varname(var\"sub1.x\")];\n\njulia> sub2_x = vi[@varname(var\"sub2.x\")];\n\njulia> logprior = logpdf(Normal(), sub1_x) + logpdf(Normal(), sub2_x);\n\njulia> loglikelihood = logpdf(Uniform(-1 - abs(sub1_x), 1 + abs(sub2_x)), 0.4);\n\njulia> getlogp(vi) ≈ logprior + loglikelihood\ntrue\n\nDifferent ways of setting the prefix\n\njulia> @model inner() = x ~ Normal()\ninner (generic function with 2 methods)\n\njulia> # When `prefix` is unspecified, no prefix is used.\n       @model outer() = @submodel a = inner()\nouter (generic function with 2 methods)\n\njulia> @varname(x) in keys(VarInfo(outer()))\ntrue\n\njulia> # Explicitely don't use any prefix.\n       @model outer() = @submodel prefix=false a = inner()\nouter (generic function with 2 methods)\n\njulia> @varname(x) in keys(VarInfo(outer()))\ntrue\n\njulia> # Automatically determined from `a`.\n       @model outer() = @submodel prefix=true a = inner()\nouter (generic function with 2 methods)\n\njulia> @varname(var\"a.x\") in keys(VarInfo(outer()))\ntrue\n\njulia> # Using a static string.\n       @model outer() = @submodel prefix=\"my prefix\" a = inner()\nouter (generic function with 2 methods)\n\njulia> @varname(var\"my prefix.x\") in keys(VarInfo(outer()))\ntrue\n\njulia> # Using string interpolation.\n       @model outer() = @submodel prefix=\"$(inner().name)\" a = inner()\nouter (generic function with 2 methods)\n\njulia> @varname(var\"inner.x\") in keys(VarInfo(outer()))\ntrue\n\njulia> # Or using some arbitrary expression.\n       @model outer() = @submodel prefix=1 + 2 a = inner()\nouter (generic function with 2 methods)\n\njulia> @varname(var\"3.x\") in keys(VarInfo(outer()))\ntrue\n\njulia> # (×) Automatic prefixing without a left-hand side expression does not work!\n       @model outer() = @submodel prefix=true inner()\nERROR: LoadError: cannot automatically prefix with no left-hand side\n[...]\n\nNotes\n\nThe choice prefix=expression means that the prefixing will incur a runtime cost. This is also the case for prefix=true, depending on whether the expression on the the right-hand side of ... = model requires runtime-information or not, e.g. x = model will result in the static prefix x, while x[i] = model will be resolved at runtime.\n\n\n\n\n\n","category":"macro"},{"location":"api/#Type","page":"API","title":"Type","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"A Model can be created by calling the model function, as defined by @model.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Model","category":"page"},{"location":"api/#DynamicPPL.Model","page":"API","title":"DynamicPPL.Model","text":"struct Model{F,argnames,defaultnames,missings,Targs,Tdefaults}\n    name::Symbol\n    f::F\n    args::NamedTuple{argnames,Targs}\n    defaults::NamedTuple{defaultnames,Tdefaults}\nend\n\nA Model struct with model evaluation function of type F, arguments of names argnames types Targs, default arguments of names defaultnames with types Tdefaults, and missing arguments missings.\n\nHere argnames, defaultargnames, and missings are tuples of symbols, e.g. (:a, :b).\n\nAn argument with a type of Missing will be in missings by default. However, in non-traditional use-cases missings can be defined differently. All variables in missings are treated as random variables rather than observations.\n\nThe default arguments are used internally when constructing instances of the same model with different arguments.\n\nExamples\n\njulia> Model(f, (x = 1.0, y = 2.0))\nModel{typeof(f),(:x, :y),(),(),Tuple{Float64,Float64},Tuple{}}(f, (x = 1.0, y = 2.0), NamedTuple())\n\njulia> Model(f, (x = 1.0, y = 2.0), (x = 42,))\nModel{typeof(f),(:x, :y),(:x,),(),Tuple{Float64,Float64},Tuple{Int64}}(f, (x = 1.0, y = 2.0), (x = 42,))\n\njulia> Model{(:y,)}(f, (x = 1.0, y = 2.0), (x = 42,)) # with special definition of missings\nModel{typeof(f),(:x, :y),(:x,),(:y,),Tuple{Float64,Float64},Tuple{Int64}}(f, (x = 1.0, y = 2.0), (x = 42,))\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"Models are callable structs.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Model()","category":"page"},{"location":"api/#DynamicPPL.Model-Tuple{}","page":"API","title":"DynamicPPL.Model","text":"(model::Model)([rng, varinfo, sampler, context])\n\nSample from the model using the sampler with random number generator rng and the context, and store the sample and log joint probability in varinfo.\n\nThe method resets the log joint probability of varinfo and increases the evaluation number of sampler.\n\n\n\n\n\n","category":"method"},{"location":"api/","page":"API","title":"API","text":"Basic properties of a model can be accessed with getargnames, getmissings, and nameof.","category":"page"},{"location":"api/","page":"API","title":"API","text":"nameof(::Model)\ngetargnames\ngetmissings","category":"page"},{"location":"api/#Base.nameof-Tuple{Model}","page":"API","title":"Base.nameof","text":"nameof(model::Model)\n\nGet the name of the model as Symbol.\n\n\n\n\n\n","category":"method"},{"location":"api/#DynamicPPL.getargnames","page":"API","title":"DynamicPPL.getargnames","text":"getargnames(model::Model)\n\nGet a tuple of the argument names of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.getmissings","page":"API","title":"DynamicPPL.getmissings","text":"getmissings(model::Model)\n\nGet a tuple of the names of the missing arguments of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/#Evaluation","page":"API","title":"Evaluation","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"With rand one can draw samples from the prior distribution of a Model.","category":"page"},{"location":"api/","page":"API","title":"API","text":"rand","category":"page"},{"location":"api/#Base.rand","page":"API","title":"Base.rand","text":"rand([rng=Random.GLOBAL_RNG], [T=NamedTuple], model::Model)\n\nGenerate a sample of type T from the prior distribution of the model.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"One can also evaluate the log prior, log likelihood, and log joint probability.","category":"page"},{"location":"api/","page":"API","title":"API","text":"logprior\nloglikelihood\nlogjoint","category":"page"},{"location":"api/#DynamicPPL.logprior","page":"API","title":"DynamicPPL.logprior","text":"logprior(model::Model, varinfo::AbstractVarInfo)\n\nReturn the log prior probability of variables varinfo for the probabilistic model.\n\nSee also logjoint and loglikelihood.\n\n\n\n\n\nlogprior(model::Model, θ)\n\nReturn the log prior probability of variables θ for the probabilistic model.\n\nSee also logjoint and loglikelihood.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       logprior(demo([1.0]), (m = 100.0, ))\n-5000.918938533205\n\njulia> # Using a `Dict`.\n       logprior(demo([1.0]), Dict(@varname(m) => 100.0))\n-5000.918938533205\n\njulia> # Truth.\n       logpdf(Normal(), 100.0)\n-5000.918938533205\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.loglikelihood","page":"API","title":"StatsAPI.loglikelihood","text":"loglikelihood(model::Model, varinfo::AbstractVarInfo)\n\nReturn the log likelihood of variables varinfo for the probabilistic model.\n\nSee also logjoint and logprior.\n\n\n\n\n\nloglikelihood(model::Model, θ)\n\nReturn the log likelihood of variables θ for the probabilistic model.\n\nSee also logjoint and logprior.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       loglikelihood(demo([1.0]), (m = 100.0, ))\n-4901.418938533205\n\njulia> # Using a `Dict`.\n       loglikelihood(demo([1.0]), Dict(@varname(m) => 100.0))\n-4901.418938533205\n\njulia> # Truth.\n       logpdf(Normal(100.0, 1.0), 1.0)\n-4901.418938533205\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.logjoint","page":"API","title":"DynamicPPL.logjoint","text":"logjoint(model::Model, varinfo::AbstractVarInfo)\n\nReturn the log joint probability of variables varinfo for the probabilistic model.\n\nSee logjoint and loglikelihood.\n\n\n\n\n\nlogjoint(model::Model, θ)\n\nReturn the log joint probability of variables θ for the probabilistic model.\n\nSee logjoint and loglikelihood.\n\nExamples\n\njulia> @model function demo(x)\n           m ~ Normal()\n           for i in eachindex(x)\n               x[i] ~ Normal(m, 1.0)\n           end\n       end\ndemo (generic function with 2 methods)\n\njulia> # Using a `NamedTuple`.\n       logjoint(demo([1.0]), (m = 100.0, ))\n-9902.33787706641\n\njulia> # Using a `Dict`.\n       logjoint(demo([1.0]), Dict(@varname(m) => 100.0))\n-9902.33787706641\n\njulia> # Truth.\n       logpdf(Normal(100.0, 1.0), 1.0) + logpdf(Normal(), 100.0)\n-9902.33787706641\n\n\n\n\n\n","category":"function"},{"location":"api/#Condition-and-decondition","page":"API","title":"Condition and decondition","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"A Model can be conditioned on a set of observations with AbstractPPL.condition or its alias |.","category":"page"},{"location":"api/","page":"API","title":"API","text":"|(::Model, ::Any)\ncondition\nDynamicPPL.conditioned","category":"page"},{"location":"api/#Base.:|-Tuple{Model, Any}","page":"API","title":"Base.:|","text":"model | (x = 1.0, ...)\n\nReturn a Model which now treats variables on the right-hand side as observations.\n\nSee condition for more information and examples.\n\n\n\n\n\n","category":"method"},{"location":"api/#AbstractPPL.condition","page":"API","title":"AbstractPPL.condition","text":"condition(model::Model; values...)\ncondition(model::Model, values::NamedTuple)\n\nReturn a Model which now treats the variables in values as observations.\n\nSee also: decondition, conditioned\n\nLimitations\n\nThis does currently not work with variables that are provided to the model as arguments, e.g. @model function demo(x) ... end means that condition will not affect the variable x.\n\nTherefore if one wants to make use of condition and decondition one should not be specifying any random variables as arguments.\n\nThis is done for the sake of backwards compatibility.\n\nExamples\n\nSimple univariate model\n\njulia> using Distributions; using StableRNGs; rng = StableRNG(42); # For reproducibility.\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo();\n\njulia> model(rng)\n(m = -0.6702516921145671, x = -0.22312984965118443)\n\njulia> # Create a new instance which treats `x` as observed\n       # with value `100.0`, and similarly for `m=1.0`.\n       conditioned_model = condition(model, x=100.0, m=1.0);\n\njulia> conditioned_model(rng)\n(m = 1.0, x = 100.0)\n\njulia> # Let's only condition on `x = 100.0`.\n       conditioned_model = condition(model, x = 100.0);\n\njulia> conditioned_model(rng)\n(m = 1.3736306979834252, x = 100.0)\n\njulia> # We can also use the nicer `|` syntax.\n       conditioned_model = model | (x = 100.0, );\n\njulia> conditioned_model(rng)\n(m = 1.3095394956381083, x = 100.0)\n\nCondition only a part of a multivariate variable\n\nNot only can be condition on multivariate random variables, but we can also use the standard mechanism of setting something to missing in the call to condition to only condition on a part of the variable.\n\njulia> @model function demo_mv(::Type{TV}=Float64) where {TV}\n           m = Vector{TV}(undef, 2)\n           m[1] ~ Normal()\n           m[2] ~ Normal()\n           return m\n       end\ndemo_mv (generic function with 3 methods)\n\njulia> model = demo_mv();\n\njulia> conditioned_model = condition(model, m = [missing, 1.0]);\n\njulia> conditioned_model(rng) # (✓) `m[1]` sampled, `m[2]` is fixed\n2-element Vector{Float64}:\n 0.12607002180931043\n 1.0\n\nIntuitively one might also expect to be able to write model | (x[1] = 1.0, ). Unfortunately this is not supported due to performance.\n\njulia> condition(model, var\"x[2]\" = 1.0)(rng) # (×) `x[2]` is not set to 1.0.\n2-element Vector{Float64}:\n  0.683947930996541\n -1.019202452456547\n\nWe will likely provide some syntactic sugar for this in the future.\n\nNested models\n\ncondition of course also supports the use of nested models through the use of @submodel.\n\njulia> @model demo_inner() = m ~ Normal()\ndemo_inner (generic function with 2 methods)\n\njulia> @model function demo_outer()\n           @submodel m = demo_inner()\n           return m\n       end\ndemo_outer (generic function with 2 methods)\n\njulia> model = demo_outer();\n\njulia> model(rng)\n-0.7935128416361353\n\njulia> conditioned_model = model | (m = 1.0, );\n\njulia> conditioned_model(rng)\n1.0\n\nBut one needs to be careful when prefixing variables in the nested models:\n\njulia> @model function demo_outer_prefix()\n           @submodel prefix=\"inner\" m = demo_inner()\n           return m\n       end\ndemo_outer_prefix (generic function with 2 methods)\n\njulia> # This doesn't work now!\n       conditioned_model = demo_outer_prefix() | (m = 1.0, );\n\njulia> conditioned_model(rng)\n1.7747246334368165\n\njulia> # `m` in `demo_inner` is referred to as `inner.m` internally, so we do:\n       conditioned_model = demo_outer_prefix() | (var\"inner.m\" = 1.0, );\n\njulia> conditioned_model(rng)\n1.0\n\njulia> # Note that the above `var\"...\"` is just standard Julia syntax:\n       keys((var\"inner.m\" = 1.0, ))\n(Symbol(\"inner.m\"),)\n\nThe difference is maybe more obvious once we look at how these different in their trace/VarInfo:\n\njulia> keys(VarInfo(demo_outer()))\n1-element Vector{VarName{:m, Setfield.IdentityLens}}:\n m\n\njulia> keys(VarInfo(demo_outer_prefix()))\n1-element Vector{VarName{Symbol(\"inner.m\"), Setfield.IdentityLens}}:\n inner.m\n\nFrom this we can tell what the correct way to condition m within demo_inner is in the two different models.\n\n\n\n\n\ncondition([context::AbstractContext,] values::NamedTuple)\ncondition([context::AbstractContext]; values...)\n\nReturn ConditionContext with values and context if values is non-empty, otherwise return context which is DefaultContext by default.\n\nSee also: decondition\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.conditioned","page":"API","title":"DynamicPPL.conditioned","text":"conditioned(model::Model)\n\nReturn NamedTuple of values that are conditioned on under model.\n\nExamples\n\njulia> using Distributions\n\njulia> using DynamicPPL: conditioned, contextualize\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n       end\ndemo (generic function with 2 methods)\n\njulia> m = demo();\n\njulia> # Returns all the variables we have conditioned on + their values.\n       conditioned(condition(m, x=100.0, m=1.0))\n(x = 100.0, m = 1.0)\n\njulia> # Nested ones also work (note that `PrefixContext` does nothing to the result).\n       cm = condition(contextualize(m, PrefixContext{:a}(condition(m=1.0))), x=100.0);\n\njulia> conditioned(cm)\n(x = 100.0, m = 1.0)\n\njulia> # Since we conditioned on `m`, not `a.m` as it will appear after prefixed,\n       # `a.m` is treated as a random variable.\n       keys(VarInfo(cm))\n1-element Vector{VarName{Symbol(\"a.m\"), Setfield.IdentityLens}}:\n a.m\n\njulia> # If we instead condition on `a.m`, `m` in the model will be considered an observation.\n       cm = condition(contextualize(m, PrefixContext{:a}(condition(var\"a.m\"=1.0))), x=100.0);\n\njulia> conditioned(cm).x\n100.0\n\njulia> conditioned(cm).var\"a.m\"\n1.0\n\njulia> keys(VarInfo(cm)) # <= no variables are sampled\nAny[]\n\n\n\n\n\nconditioned(context::AbstractContext)\n\nReturn NamedTuple of values that are conditioned on under context`.\n\nNote that this will recursively traverse the context stack and return a merged version of the condition values.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"Similarly, one can specify with AbstractPPL.decondition that certain, or all, random variables are not observed.","category":"page"},{"location":"api/","page":"API","title":"API","text":"decondition","category":"page"},{"location":"api/#AbstractPPL.decondition","page":"API","title":"AbstractPPL.decondition","text":"decondition(model::Model)\ndecondition(model::Model, syms...)\n\nReturn a Model for which syms... are not considered observations. If no syms are provided, then all variables currently considered observations will no longer be.\n\nThis is essentially the inverse of condition. This also means that it suffers from the same limitiations.\n\nExamples\n\njulia> using Distributions; using StableRNGs; rng = StableRNG(42); # For reproducibility.\n\njulia> @model function demo()\n           m ~ Normal()\n           x ~ Normal(m, 1)\n           return (; m=m, x=x)\n       end\ndemo (generic function with 2 methods)\n\njulia> conditioned_model = condition(demo(), m = 1.0, x = 10.0);\n\njulia> conditioned_model(rng)\n(m = 1.0, x = 10.0)\n\njulia> model = decondition(conditioned_model, :m);\n\njulia> model(rng)\n(m = -0.6702516921145671, x = 10.0)\n\njulia> # `decondition` multiple at once:\n       decondition(model, :m, :x)(rng)\n(m = 0.4471218424633827, x = 1.820752540446808)\n\njulia> # `decondition` without any symbols will `decondition` all variables.\n       decondition(model)(rng)\n(m = 1.3095394956381083, x = 1.4356095174474188)\n\njulia> # Usage of `Val` to perform `decondition` at compile-time if possible\n       # is also supported.\n       model = decondition(conditioned_model, Val{:m}());\n\njulia> model(rng)\n(m = 0.683947930996541, x = 10.0)\n\n\n\n\n\ndecondition(context::AbstractContext, syms...)\n\nReturn context but with syms no longer conditioned on.\n\nNote that this recursively traverses contexts, deconditioning all along the way.\n\nSee also: condition\n\n\n\n\n\n","category":"function"},{"location":"api/#Utilities","page":"API","title":"Utilities","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"It is possible to manually increase (or decrease) the accumulated log density from within a model function.","category":"page"},{"location":"api/","page":"API","title":"API","text":"@addlogprob!","category":"page"},{"location":"api/#DynamicPPL.@addlogprob!","page":"API","title":"DynamicPPL.@addlogprob!","text":"@addlogprob!(ex)\n\nAdd the result of the evaluation of ex to the joint log probability.\n\nExamples\n\nThis macro allows you to include arbitrary terms in the likelihood\n\njulia> myloglikelihood(x, μ) = loglikelihood(Normal(μ, 1), x);\n\njulia> @model function demo(x)\n           μ ~ Normal()\n           @addlogprob! myloglikelihood(x, μ)\n       end;\n\njulia> x = [1.3, -2.1];\n\njulia> loglikelihood(demo(x), (μ=0.2,)) ≈ myloglikelihood(x, 0.2)\ntrue\n\nand to reject samples:\n\njulia> @model function demo(x)\n           m ~ MvNormal(zero(x), I)\n           if dot(m, x) < 0\n               @addlogprob! -Inf\n               # Exit the model evaluation early\n               return\n           end\n           x ~ MvNormal(m, I)\n           return\n       end;\n\njulia> logjoint(demo([-2.1]), (m=[0.2],)) == -Inf\ntrue\n\nnote: Note\nThe @addlogprob! macro increases the accumulated log probability regardless of the evaluation context, i.e., regardless of whether you evaluate the log prior, the log likelihood or the log joint density. If you would like to avoid this behaviour you should check the evaluation context. It can be accessed with the internal variable __context__. For instance, in the following example the log density is not accumulated when only the log prior is computed:  julia> myloglikelihood(x, μ) = loglikelihood(Normal(μ, 1), x);\n\njulia> @model function demo(x)\n           μ ~ Normal()\n           if DynamicPPL.leafcontext(__context__) !== PriorContext()\n               @addlogprob! myloglikelihood(x, μ)\n           end\n       end;\n\njulia> x = [1.3, -2.1];\n\njulia> logprior(demo(x), (μ=0.2,)) ≈ logpdf(Normal(), 0.2)\ntrue\n\njulia> loglikelihood(demo(x), (μ=0.2,)) ≈ myloglikelihood(x, 0.2)\ntrue\n\n\n\n\n\n","category":"macro"},{"location":"api/","page":"API","title":"API","text":"Return values of the model function for a collection of samples can be obtained with generated_quantities.","category":"page"},{"location":"api/","page":"API","title":"API","text":"generated_quantities","category":"page"},{"location":"api/#DynamicPPL.generated_quantities","page":"API","title":"DynamicPPL.generated_quantities","text":"generated_quantities(model::Model, chain::AbstractChains)\n\nExecute model for each of the samples in chain and return an array of the values returned by the model for each sample.\n\nExamples\n\nGeneral\n\nOften you might have additional quantities computed inside the model that you want to inspect, e.g.\n\n@model function demo(x)\n    # sample and observe\n    θ ~ Prior()\n    x ~ Likelihood()\n    return interesting_quantity(θ, x)\nend\nm = demo(data)\nchain = sample(m, alg, n)\n# To inspect the `interesting_quantity(θ, x)` where `θ` is replaced by samples\n# from the posterior/`chain`:\ngenerated_quantities(m, chain) # <= results in a `Vector` of returned values\n                               #    from `interesting_quantity(θ, x)`\n\nConcrete (and simple)\n\njulia> using DynamicPPL, Turing\n\njulia> @model function demo(xs)\n           s ~ InverseGamma(2, 3)\n           m_shifted ~ Normal(10, √s)\n           m = m_shifted - 10\n\n           for i in eachindex(xs)\n               xs[i] ~ Normal(m, √s)\n           end\n\n           return (m, )\n       end\ndemo (generic function with 1 method)\n\njulia> model = demo(randn(10));\n\njulia> chain = sample(model, MH(), 10);\n\njulia> generated_quantities(model, chain)\n10×1 Array{Tuple{Float64},2}:\n (2.1964758025119338,)\n (2.1964758025119338,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.09270081916291417,)\n (0.043088571494005024,)\n (-0.16489786710222099,)\n (-0.16489786710222099,)\n\n\n\n\n\ngenerated_quantities(model::Model, parameters::NamedTuple)\ngenerated_quantities(model::Model, values, keys)\ngenerated_quantities(model::Model, values, keys)\n\nExecute model with variables keys set to values and return the values returned by the model.\n\nIf a NamedTuple is given, keys=keys(parameters) and values=values(parameters).\n\nExample\n\njulia> using DynamicPPL, Distributions\n\njulia> @model function demo(xs)\n           s ~ InverseGamma(2, 3)\n           m_shifted ~ Normal(10, √s)\n           m = m_shifted - 10\n           for i in eachindex(xs)\n               xs[i] ~ Normal(m, √s)\n           end\n           return (m, )\n       end\ndemo (generic function with 2 methods)\n\njulia> model = demo(randn(10));\n\njulia> parameters = (; s = 1.0, m_shifted=10);\n\njulia> generated_quantities(model, parameters)\n(0.0,)\n\njulia> generated_quantities(model, values(parameters), keys(parameters))\n(0.0,)\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"For a chain of samples, one can compute the pointwise log-likelihoods of each observed random variable with pointwise_loglikelihoods.","category":"page"},{"location":"api/","page":"API","title":"API","text":"pointwise_loglikelihoods","category":"page"},{"location":"api/#DynamicPPL.pointwise_loglikelihoods","page":"API","title":"DynamicPPL.pointwise_loglikelihoods","text":"pointwise_loglikelihoods(model::Model, chain::Chains, keytype = String)\n\nRuns model on each sample in chain returning a Dict{String, Matrix{Float64}} with keys corresponding to symbols of the observations, and values being matrices of shape (num_chains, num_samples).\n\nkeytype specifies what the type of the keys used in the returned Dict are. Currently, only String and VarName are supported.\n\nNotes\n\nSay y is a Vector of n i.i.d. Normal(μ, σ) variables, with μ and σ both being <:Real. Then the observe (i.e. when the left-hand side is an observation) statements can be implemented in three ways:\n\nusing a for loop:\n\nfor i in eachindex(y)\n    y[i] ~ Normal(μ, σ)\nend\n\nusing .~:\n\ny .~ Normal(μ, σ)\n\nusing MvNormal:\n\ny ~ MvNormal(fill(μ, n), σ^2 * I)\n\nIn (1) and (2), y will be treated as a collection of n i.i.d. 1-dimensional variables, while in (3) y will be treated as a single n-dimensional observation.\n\nThis is important to keep in mind, in particular if the computation is used for downstream computations.\n\nExamples\n\nFrom chain\n\njulia> using DynamicPPL, Turing\n\njulia> @model function demo(xs, y)\n           s ~ InverseGamma(2, 3)\n           m ~ Normal(0, √s)\n           for i in eachindex(xs)\n               xs[i] ~ Normal(m, √s)\n           end\n\n           y ~ Normal(m, √s)\n       end\ndemo (generic function with 1 method)\n\njulia> model = demo(randn(3), randn());\n\njulia> chain = sample(model, MH(), 10);\n\njulia> pointwise_loglikelihoods(model, chain)\nDict{String,Array{Float64,2}} with 4 entries:\n  \"xs[3]\" => [-1.42862; -2.67573; … ; -1.66251; -1.66251]\n  \"xs[1]\" => [-1.42932; -2.68123; … ; -1.66333; -1.66333]\n  \"xs[2]\" => [-1.6724; -0.861339; … ; -1.62359; -1.62359]\n  \"y\"     => [-1.51265; -0.914129; … ; -1.5499; -1.5499]\n\njulia> pointwise_loglikelihoods(model, chain, String)\nDict{String,Array{Float64,2}} with 4 entries:\n  \"xs[3]\" => [-1.42862; -2.67573; … ; -1.66251; -1.66251]\n  \"xs[1]\" => [-1.42932; -2.68123; … ; -1.66333; -1.66333]\n  \"xs[2]\" => [-1.6724; -0.861339; … ; -1.62359; -1.62359]\n  \"y\"     => [-1.51265; -0.914129; … ; -1.5499; -1.5499]\n\njulia> pointwise_loglikelihoods(model, chain, VarName)\nDict{VarName,Array{Float64,2}} with 4 entries:\n  xs[2] => [-1.6724; -0.861339; … ; -1.62359; -1.62359]\n  y     => [-1.51265; -0.914129; … ; -1.5499; -1.5499]\n  xs[1] => [-1.42932; -2.68123; … ; -1.66333; -1.66333]\n  xs[3] => [-1.42862; -2.67573; … ; -1.66251; -1.66251]\n\nBroadcasting\n\nNote that x .~ Dist() will treat x as a collection of independent observations rather than as a single observation.\n\njulia> @model function demo(x)\n           x .~ Normal()\n       end;\n\njulia> m = demo([1.0, ]);\n\njulia> ℓ = pointwise_loglikelihoods(m, VarInfo(m)); first(ℓ[@varname(x[1])])\n-1.4189385332046727\n\njulia> m = demo([1.0; 1.0]);\n\njulia> ℓ = pointwise_loglikelihoods(m, VarInfo(m)); first.((ℓ[@varname(x[1])], ℓ[@varname(x[2])]))\n(-1.4189385332046727, -1.4189385332046727)\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"NamedDist","category":"page"},{"location":"api/#DynamicPPL.NamedDist","page":"API","title":"DynamicPPL.NamedDist","text":"A named distribution that carries the name of the random variable with it.\n\n\n\n\n\n","category":"type"},{"location":"api/#Testing-Utilities","page":"API","title":"Testing Utilities","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"DynamicPPL provides several demo models and helpers for testing samplers in the DynamicPPL.TestUtils submodule.","category":"page"},{"location":"api/","page":"API","title":"API","text":"DynamicPPL.TestUtils.test_sampler_demo_models\nDynamicPPL.TestUtils.test_sampler_continuous","category":"page"},{"location":"api/#DynamicPPL.TestUtils.test_sampler_demo_models","page":"API","title":"DynamicPPL.TestUtils.test_sampler_demo_models","text":"test_sampler_demo_models(meanfunction, sampler, args...; kwargs...)\n\nTest that sampler produces the correct marginal posterior means on all models in demo_models.\n\nIn short, this method iterators through demo_models, calls AbstractMCMC.sample on the model and sampler to produce a chain, and then checks meanfunction(chain) against target provided in kwargs....\n\nArguments\n\nmeanfunction: A callable which computes the mean of the marginal means from the chain resulting from the sample call.\nsampler: The AbstractMCMC.AbstractSampler to test.\nargs...: Arguments forwarded to sample.\n\nKeyword arguments\n\ntarget: Value to compare result of meanfunction(chain) to.\natol=1e-1: Absolute tolerance used in @test.\nrtol=1e-3: Relative tolerance used in @test.\nkwargs...: Keyword arguments forwarded to sample.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.test_sampler_continuous","page":"API","title":"DynamicPPL.TestUtils.test_sampler_continuous","text":"test_sampler_continuous([meanfunction, ]sampler, args...; kwargs...)\n\nTest that sampler produces the correct marginal posterior means on all models in demo_models.\n\nAs of right now, this is just an alias for test_sampler_demo_models.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"For every demo model, one can define the true log prior, log likelihood, and log joint probabilities.","category":"page"},{"location":"api/","page":"API","title":"API","text":"DynamicPPL.TestUtils.logprior_true\nDynamicPPL.TestUtils.loglikelihood_true\nDynamicPPL.TestUtils.logjoint_true","category":"page"},{"location":"api/#DynamicPPL.TestUtils.logprior_true","page":"API","title":"DynamicPPL.TestUtils.logprior_true","text":"logprior_true(model, θ)\n\nReturn the logprior of model for θ.\n\nThis should generally be implemented by hand for every specific model.\n\nSee also: logjoint_true, loglikelihood_true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.loglikelihood_true","page":"API","title":"DynamicPPL.TestUtils.loglikelihood_true","text":"loglikelihood_true(model, θ)\n\nReturn the loglikelihood of model for θ.\n\nThis should generally be implemented by hand for every specific model.\n\nSee also: logjoint_true, logprior_true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.TestUtils.logjoint_true","page":"API","title":"DynamicPPL.TestUtils.logjoint_true","text":"logjoint_true(model, θ)\n\nReturn the logjoint of model for θ.\n\nDefaults to logprior_true(model, θ) + loglikelihood_true(model, θ).\n\nThis should generally be implemented by hand for every specific model so that the returned value can be used as a ground-truth for testing things like:\n\nValidity of evaluation of model using a particular implementation of AbstractVarInfo.\nValidity of a sampler when combined with DynamicPPL by running the sampler twice: once targeting ground-truth functions, e.g. logjoint_true, and once targeting model.\n\nAnd more.\n\nSee also: logprior_true, loglikelihood_true.\n\n\n\n\n\n","category":"function"},{"location":"api/#Advanced","page":"API","title":"Advanced","text":"","category":"section"},{"location":"api/#Variable-names","page":"API","title":"Variable names","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Names and possibly nested indices of variables are described with AbstractPPL.VarName. They can be defined with AbstractPPL.@varname. Please see the documentation of AbstractPPL.jl for further information.","category":"page"},{"location":"api/#Data-Structures-of-Variables","page":"API","title":"Data Structures of Variables","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"DynamicPPL provides different data structures for samples from the model and their log density. All of them are subtypes of AbstractVarInfo.","category":"page"},{"location":"api/","page":"API","title":"API","text":"AbstractVarInfo","category":"page"},{"location":"api/#DynamicPPL.AbstractVarInfo","page":"API","title":"DynamicPPL.AbstractVarInfo","text":"AbstractVarInfo\n\nAbstract supertype for data structures that capture random variables when executing a probabilistic model and accumulate log densities such as the log likelihood or the log joint probability of the model.\n\nSee also: VarInfo\n\n\n\n\n\n","category":"type"},{"location":"api/#Common-API","page":"API","title":"Common API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"getlogp\nsetlogp!!\nacclogp!!\nresetlogp!!","category":"page"},{"location":"api/#DynamicPPL.getlogp","page":"API","title":"DynamicPPL.getlogp","text":"getlogp(vi::VarInfo)\n\nReturn the log of the joint probability of the observed data and parameters sampled in vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setlogp!!","page":"API","title":"DynamicPPL.setlogp!!","text":"setlogp!!(vi::VarInfo, logp)\n\nSet the log of the joint probability of the observed data and parameters sampled in vi to logp, mutating if it makes sense.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.acclogp!!","page":"API","title":"DynamicPPL.acclogp!!","text":"acclogp!!(vi::VarInfo, logp)\n\nAdd logp to the value of the log of the joint probability of the observed data and parameters sampled in vi, mutating if it makes sense.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.resetlogp!!","page":"API","title":"DynamicPPL.resetlogp!!","text":"resetlogp!!(vi::AbstractVarInfo)\n\nReset the value of the log of the joint probability of the observed data and parameters sampled in vi to 0, mutating if it makes sense.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"getindex\npush!!\nempty!!","category":"page"},{"location":"api/#Base.getindex","page":"API","title":"Base.getindex","text":"getindex(vi::VarInfo, vn::VarName)\ngetindex(vi::VarInfo, vns::Vector{<:VarName})\n\nReturn the current value(s) of vn (vns) in vi in the support of its (their) distribution(s).\n\nIf the value(s) is (are) transformed to the Euclidean space, it is (they are) transformed back.\n\n\n\n\n\ngetindex(vi::VarInfo, spl::Union{SampleFromPrior, Sampler})\n\nReturn the current value(s) of the random variables sampled by spl in vi.\n\nThe value(s) may or may not be transformed to Euclidean space.\n\n\n\n\n\n","category":"function"},{"location":"api/#BangBang.push!!","page":"API","title":"BangBang.push!!","text":"push!!(vi::VarInfo, vn::VarName, r, dist::Distribution)\n\nPush a new random variable vn with a sampled value r from a distribution dist to the VarInfo vi, mutating if it makes sense.\n\n\n\n\n\npush!!(vi::VarInfo, vn::VarName, r, dist::Distribution, spl::AbstractSampler)\n\nPush a new random variable vn with a sampled value r sampled with a sampler spl from a distribution dist to VarInfo vi, if it makes sense.\n\nThe sampler is passed here to invalidate its cache where defined.\n\n\n\n\n\npush!!(vi::VarInfo, vn::VarName, r, dist::Distribution, gid::Selector)\n\nPush a new random variable vn with a sampled value r sampled with a sampler of selector gid from a distribution dist to VarInfo vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#BangBang.empty!!","page":"API","title":"BangBang.empty!!","text":"empty!!(vi::VarInfo)\n\nEmpty the fields of vi.metadata and reset vi.logp[] and vi.num_produce[] to zeros.\n\nThis is useful when using a sampling algorithm that assumes an empty vi, e.g. SMC.\n\n\n\n\n\n","category":"function"},{"location":"api/#SimpleVarInfo","page":"API","title":"SimpleVarInfo","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"SimpleVarInfo","category":"page"},{"location":"api/#DynamicPPL.SimpleVarInfo","page":"API","title":"DynamicPPL.SimpleVarInfo","text":"SimpleVarInfo{NT,T} <: AbstractVarInfo\n\nA simple wrapper of the parameters with a logp field for accumulation of the logdensity.\n\nCurrently only implemented for NT<:NamedTuple and NT<:Dict.\n\nNotes\n\nThe major differences between this and TypedVarInfo are:\n\nSimpleVarInfo does not require linearization.\nSimpleVarInfo can use more efficient bijectors.\nSimpleVarInfo is only type-stable if NT<:NamedTuple and either a) no indexing is used in tilde-statements, or b) the values have been specified with the correct shapes.\n\nExamples\n\nGeneral usage\n\njulia> using StableRNGs\n\njulia> @model function demo()\n           m ~ Normal()\n           x = Vector{Float64}(undef, 2)\n           for i in eachindex(x)\n               x[i] ~ Normal()\n           end\n           return x\n       end\ndemo (generic function with 2 methods)\n\njulia> m = demo();\n\njulia> rng = StableRNG(42);\n\njulia> ### Sampling ###\n       ctx = SamplingContext(rng, SampleFromPrior(), DefaultContext());\n\njulia> # In the `NamedTuple` version we need to provide the place-holder values for\n       # the variables which are using \"containers\", e.g. `Array`.\n       # In this case, this means that we need to specify `x` but not `m`.\n       _, vi = DynamicPPL.evaluate!!(m, SimpleVarInfo((x = ones(2), )), ctx);\n\njulia> # (✓) Vroom, vroom! FAST!!!\n       vi[@varname(x[1])]\n0.4471218424633827\n\njulia> # We can also access arbitrary varnames pointing to `x`, e.g.\n       vi[@varname(x)]\n2-element Vector{Float64}:\n 0.4471218424633827\n 1.3736306979834252\n\njulia> vi[@varname(x[1:2])]\n2-element Vector{Float64}:\n 0.4471218424633827\n 1.3736306979834252\n\njulia> # (×) If we don't provide the container...\n       _, vi = DynamicPPL.evaluate!!(m, SimpleVarInfo(), ctx); vi\nERROR: type NamedTuple has no field x\n[...]\n\njulia> # If one does not know the varnames, we can use a `Dict` instead.\n       _, vi = DynamicPPL.evaluate!!(m, SimpleVarInfo{Float64}(Dict()), ctx);\n\njulia> # (✓) Sort of fast, but only possible at runtime.\n       vi[@varname(x[1])]\n-1.019202452456547\n\njulia> # In addtion, we can only access varnames as they appear in the model!\n       vi[@varname(x)]\nERROR: KeyError: key x not found\n[...]\n\njulia> vi[@varname(x[1:2])]\nERROR: KeyError: key x[1:2] not found\n[...]\n\nIndexing\n\nUsing NamedTuple as underlying storage.\n\njulia> svi_nt = SimpleVarInfo((m = (a = [1.0], ), ));\n\njulia> svi_nt[@varname(m)]\n(a = [1.0],)\n\njulia> svi_nt[@varname(m.a)]\n1-element Vector{Float64}:\n 1.0\n\njulia> svi_nt[@varname(m.a[1])]\n1.0\n\njulia> svi_nt[@varname(m.a[2])]\nERROR: BoundsError: attempt to access 1-element Vector{Float64} at index [2]\n[...]\n\njulia> svi_nt[@varname(m.b)]\nERROR: type NamedTuple has no field b\n[...]\n\nUsing Dict as underlying storage.\n\njulia> svi_dict = SimpleVarInfo(Dict(@varname(m) => (a = [1.0], )));\n\njulia> svi_dict[@varname(m)]\n(a = [1.0],)\n\njulia> svi_dict[@varname(m.a)]\n1-element Vector{Float64}:\n 1.0\n\njulia> svi_dict[@varname(m.a[1])]\n1.0\n\njulia> svi_dict[@varname(m.a[2])]\nERROR: BoundsError: attempt to access 1-element Vector{Float64} at index [2]\n[...]\n\njulia> svi_dict[@varname(m.b)]\nERROR: type NamedTuple has no field b\n[...]\n\n\n\n\n\n","category":"type"},{"location":"api/#VarInfo","page":"API","title":"VarInfo","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Another data structure is VarInfo.","category":"page"},{"location":"api/","page":"API","title":"API","text":"VarInfo\nTypedVarInfo","category":"page"},{"location":"api/#DynamicPPL.VarInfo","page":"API","title":"DynamicPPL.VarInfo","text":"struct VarInfo{Tmeta, Tlogp} <: AbstractVarInfo\n    metadata::Tmeta\n    logp::Base.RefValue{Tlogp}\n    num_produce::Base.RefValue{Int}\nend\n\nA light wrapper over one or more instances of Metadata. Let vi be an instance of VarInfo. If vi isa VarInfo{<:Metadata}, then only one Metadata instance is used for all the sybmols. VarInfo{<:Metadata} is aliased UntypedVarInfo. If vi isa VarInfo{<:NamedTuple}, then vi.metadata is a NamedTuple that maps each symbol used on the LHS of ~ in the model to its Metadata instance. The latter allows for the type specialization of vi after the first sampling iteration when all the symbols have been observed. VarInfo{<:NamedTuple} is aliased TypedVarInfo.\n\nNote: It is the user's responsibility to ensure that each \"symbol\" is visited at least once whenever the model is called, regardless of any stochastic branching. Each symbol refers to a Julia variable and can be a hierarchical array of many random variables, e.g. x[1] ~ ... and x[2] ~ ... both have the same symbol x.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.TypedVarInfo","page":"API","title":"DynamicPPL.TypedVarInfo","text":"TypedVarInfo(vi::UntypedVarInfo)\n\nThis function finds all the unique syms from the instances of VarName{sym} found in vi.metadata.vns. It then extracts the metadata associated with each symbol from the global vi.metadata field. Finally, a new VarInfo is created with a new metadata as a NamedTuple mapping from symbols to type-stable Metadata instances, one for each symbol.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"One main characteristic of VarInfo is that samples are stored in a linearized form.","category":"page"},{"location":"api/","page":"API","title":"API","text":"tonamedtuple\nlink!\ninvlink!\nistrans","category":"page"},{"location":"api/#DynamicPPL.tonamedtuple","page":"API","title":"DynamicPPL.tonamedtuple","text":"tonamedtuple(vi::VarInfo)\n\nConvert a vi into a NamedTuple where each variable symbol maps to the values and  indexing string of the variable.\n\nFor example, a model that had a vector of vector-valued variables x would return\n\n(x = ([1.5, 2.0], [3.0, 1.0], [\"x[1]\", \"x[2]\"]), )\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.link!","page":"API","title":"DynamicPPL.link!","text":"link!(vi::VarInfo, spl::Sampler)\n\nTransform the values of the random variables sampled by spl in vi from the support of their distributions to the Euclidean space and set their corresponding \"trans\" flag values to true.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.invlink!","page":"API","title":"DynamicPPL.invlink!","text":"invlink!(vi::VarInfo, spl::AbstractSampler)\n\nTransform the values of the random variables sampled by spl in vi from the Euclidean space back to the support of their distributions and sets their corresponding \"trans\" flag values to false.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.istrans","page":"API","title":"DynamicPPL.istrans","text":"istrans(vi::VarInfo, vn::VarName)\n\nReturn true if vn's values in vi are transformed to Euclidean space, and false if they are in the support of vn's distribution.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"set_flag!\nunset_flag!\nis_flagged","category":"page"},{"location":"api/#DynamicPPL.set_flag!","page":"API","title":"DynamicPPL.set_flag!","text":"set_flag!(vi::VarInfo, vn::VarName, flag::String)\n\nSet vn's value for flag to true in vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.unset_flag!","page":"API","title":"DynamicPPL.unset_flag!","text":"unset_flag!(vi::VarInfo, vn::VarName, flag::String)\n\nSet vn's value for flag to false in vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.is_flagged","page":"API","title":"DynamicPPL.is_flagged","text":"is_flagged(vi::VarInfo, vn::VarName, flag::String)\n\nCheck whether vn has a true value for flag in vi.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"For Gibbs sampling the following functions were added.","category":"page"},{"location":"api/","page":"API","title":"API","text":"setgid!\nupdategid!","category":"page"},{"location":"api/#DynamicPPL.setgid!","page":"API","title":"DynamicPPL.setgid!","text":"setgid!(vi::VarInfo, gid::Selector, vn::VarName)\n\nAdd gid to the set of sampler selectors associated with vn in vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.updategid!","page":"API","title":"DynamicPPL.updategid!","text":"updategid!(vi::VarInfo, vn::VarName, spl::Sampler)\n\nSet vn's gid to Set([spl.selector]), if vn does not have a sampler selector linked and vn's symbol is in the space of spl.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"The following functions were used for sequential Monte Carlo methods.","category":"page"},{"location":"api/","page":"API","title":"API","text":"get_num_produce\nset_num_produce!\nincrement_num_produce!\nreset_num_produce!\nsetorder!\nset_retained_vns_del_by_spl!","category":"page"},{"location":"api/#DynamicPPL.get_num_produce","page":"API","title":"DynamicPPL.get_num_produce","text":"get_num_produce(vi::VarInfo)\n\nReturn the num_produce of vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.set_num_produce!","page":"API","title":"DynamicPPL.set_num_produce!","text":"set_num_produce!(vi::VarInfo, n::Int)\n\nSet the num_produce field of vi to n.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.increment_num_produce!","page":"API","title":"DynamicPPL.increment_num_produce!","text":"increment_num_produce!(vi::VarInfo)\n\nAdd 1 to num_produce in vi.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.reset_num_produce!","page":"API","title":"DynamicPPL.reset_num_produce!","text":"reset_num_produce!(vi::AbstractVarInfo)\n\nReset the value of num_produce the log of the joint probability of the observed data and parameters sampled in vi to 0.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.setorder!","page":"API","title":"DynamicPPL.setorder!","text":"setorder!(vi::VarInfo, vn::VarName, index::Int)\n\nSet the order of vn in vi to index, where order is the number of observe statements run before samplingvn`.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.set_retained_vns_del_by_spl!","page":"API","title":"DynamicPPL.set_retained_vns_del_by_spl!","text":"set_retained_vns_del_by_spl!(vi::VarInfo, spl::Sampler)\n\nSet the \"del\" flag of variables in vi with order > vi.num_produce[] to true.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"Base.empty!","category":"page"},{"location":"api/#Base.empty!","page":"API","title":"Base.empty!","text":"empty!(meta::Metadata)\n\nEmpty the fields of meta.\n\nThis is useful when using a sampling algorithm that assumes an empty meta, e.g. SMC.\n\n\n\n\n\n","category":"function"},{"location":"api/#Evaluation-Contexts","page":"API","title":"Evaluation Contexts","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Internally, both sampling and evaluation of log densities are performed with AbstractPPL.evaluate!!.","category":"page"},{"location":"api/","page":"API","title":"API","text":"AbstractPPL.evaluate!!","category":"page"},{"location":"api/#AbstractPPL.evaluate!!","page":"API","title":"AbstractPPL.evaluate!!","text":"evaluate!!(model::Model[, rng, varinfo, sampler, context])\n\nSample from the model using the sampler with random number generator rng and the context, and store the sample and log joint probability in varinfo.\n\nReturns both the return-value of the original model, and the resulting varinfo.\n\nThe method resets the log joint probability of varinfo and increases the evaluation number of sampler.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"The behaviour of a model execution can be changed with evaluation contexts that are passed as additional argument to the model function. Contexts are subtypes of AbstractPPL.AbstractContext.","category":"page"},{"location":"api/","page":"API","title":"API","text":"SamplingContext\nDefaultContext\nLikelihoodContext\nPriorContext\nMiniBatchContext\nPrefixContext","category":"page"},{"location":"api/#DynamicPPL.SamplingContext","page":"API","title":"DynamicPPL.SamplingContext","text":"SamplingContext(\n        [rng::Random.AbstractRNG=Random.GLOBAL_RNG],\n        [sampler::AbstractSampler=SampleFromPrior()],\n        [context::AbstractContext=DefaultContext()],\n)\n\nCreate a context that allows you to sample parameters with the sampler when running the model. The context determines how the returned log density is computed when running the model.\n\nSee also: DefaultContext, LikelihoodContext, PriorContext\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.DefaultContext","page":"API","title":"DynamicPPL.DefaultContext","text":"struct DefaultContext <: AbstractContext end\n\nThe DefaultContext is used by default to compute log the joint probability of the data  and parameters when running the model.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.LikelihoodContext","page":"API","title":"DynamicPPL.LikelihoodContext","text":"struct LikelihoodContext{Tvars} <: AbstractContext\n    vars::Tvars\nend\n\nThe LikelihoodContext enables the computation of the log likelihood of the parameters when  running the model. vars can be used to evaluate the log likelihood for specific values  of the model's parameters. If vars is nothing, the parameter values inside the VarInfo will be used by default.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.PriorContext","page":"API","title":"DynamicPPL.PriorContext","text":"struct PriorContext{Tvars} <: AbstractContext\n    vars::Tvars\nend\n\nThe PriorContext enables the computation of the log prior of the parameters vars when  running the model.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.MiniBatchContext","page":"API","title":"DynamicPPL.MiniBatchContext","text":"struct MiniBatchContext{Tctx, T} <: AbstractContext\n    context::Tctx\n    loglike_scalar::T\nend\n\nThe MiniBatchContext enables the computation of  log(prior) + s * log(likelihood of a batch) when running the model, where s is the  loglike_scalar field, typically equal to the number of data points / batch size.  This is useful in batch-based stochastic gradient descent algorithms to be optimizing  log(prior) + log(likelihood of all the data points) in the expectation.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.PrefixContext","page":"API","title":"DynamicPPL.PrefixContext","text":"PrefixContext{Prefix}(context)\n\nCreate a context that allows you to use the wrapped context when running the model and adds the Prefix to all parameters.\n\nThis context is useful in nested models to ensure that the names of the parameters are unique.\n\nSee also: @submodel\n\n\n\n\n\n","category":"type"},{"location":"api/#Samplers","page":"API","title":"Samplers","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"In DynamicPPL two samplers are defined that are used to initialize unobserved random variables: SampleFromPrior which samples from the prior distribution, and SampleFromUniform which samples from a uniform distribution.","category":"page"},{"location":"api/","page":"API","title":"API","text":"SampleFromPrior\nSampleFromUniform","category":"page"},{"location":"api/#DynamicPPL.SampleFromPrior","page":"API","title":"DynamicPPL.SampleFromPrior","text":"SampleFromPrior\n\nSampling algorithm that samples unobserved random variables from their prior distribution.\n\n\n\n\n\n","category":"type"},{"location":"api/#DynamicPPL.SampleFromUniform","page":"API","title":"DynamicPPL.SampleFromUniform","text":"SampleFromUniform\n\nSampling algorithm that samples unobserved random variables from a uniform distribution.\n\nReferences\n\nStan reference manual\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"Additionally, a generic sampler for inference is implemented.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Sampler","category":"page"},{"location":"api/#DynamicPPL.Sampler","page":"API","title":"DynamicPPL.Sampler","text":"Sampler{T}\n\nGeneric sampler type for inference algorithms of type T in DynamicPPL.\n\nSampler should implement the AbstractMCMC interface, and in particular AbstractMCMC.step. A default implementation of the initial sampling step is provided that supports resuming sampling from a previous state and setting initial parameter values. It requires to overload loadstate and initialstep for loading previous states and actually performing the initial sampling step, respectively. Additionally, sometimes one might want to implement initialsampler that specifies how the initial parameter values are sampled if they are not provided. By default, values are sampled from the prior.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"The default implementation of Sampler uses the following unexported functions.","category":"page"},{"location":"api/","page":"API","title":"API","text":"DynamicPPL.initialstep\nDynamicPPL.loadstate\nDynamicPPL.initialsampler","category":"page"},{"location":"api/#DynamicPPL.initialstep","page":"API","title":"DynamicPPL.initialstep","text":"initialstep(rng, model, sampler, varinfo; kwargs...)\n\nPerform the initial sampling step of the sampler for the model.\n\nThe varinfo contains the initial samples, which can be provided by the user or sampled randomly.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.loadstate","page":"API","title":"DynamicPPL.loadstate","text":"loadstate(data)\n\nLoad sampler state from data.\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.initialsampler","page":"API","title":"DynamicPPL.initialsampler","text":"initialsampler(sampler::Sampler)\n\nReturn the sampler that is used for generating the initial parameters when sampling with sampler.\n\nBy default, it returns an instance of SampleFromPrior.\n\n\n\n\n\n","category":"function"},{"location":"api/#model_internal","page":"API","title":"Model-Internal Functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"tilde_assume\ndot_tilde_assume","category":"page"},{"location":"api/#DynamicPPL.tilde_assume","page":"API","title":"DynamicPPL.tilde_assume","text":"tilde_assume(context::SamplingContext, right, vn, vi)\n\nHandle assumed variables, e.g., x ~ Normal() (where x does occur in the model inputs), accumulate the log probability, and return the sampled value with a context associated with a sampler.\n\nFalls back to\n\ntilde_assume(context.rng, context.context, context.sampler, right, vn, vi)\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.dot_tilde_assume","page":"API","title":"DynamicPPL.dot_tilde_assume","text":"dot_tilde_assume(context::SamplingContext, right, left, vn, vi)\n\nHandle broadcasted assumed variables, e.g., x .~ MvNormal() (where x does not occur in the model inputs), accumulate the log probability, and return the sampled value for a context associated with a sampler.\n\nFalls back to\n\ndot_tilde_assume(context.rng, context.context, context.sampler, right, left, vn, vi)\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"tilde_observe\ndot_tilde_observe","category":"page"},{"location":"api/#DynamicPPL.tilde_observe","page":"API","title":"DynamicPPL.tilde_observe","text":"tilde_observe(context::SamplingContext, right, left, vi)\n\nHandle observed constants with a context associated with a sampler.\n\nFalls back to tilde_observe(context.context, context.sampler, right, left, vi).\n\n\n\n\n\n","category":"function"},{"location":"api/#DynamicPPL.dot_tilde_observe","page":"API","title":"DynamicPPL.dot_tilde_observe","text":"dot_tilde_observe(context::SamplingContext, right, left, vi)\n\nHandle broadcasted observed constants, e.g., [1.0] .~ MvNormal(), accumulate the log probability, and return the observed value for a context associated with a sampler.\n\nFalls back to dot_tilde_observe(context.context, context.sampler, right, left, vi).\n\n\n\n\n\n","category":"function"},{"location":"#DynamicPPL.jl","page":"Home","title":"DynamicPPL.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A domain-specific language and backend for probabilistic programming languages, used by Turing.jl.","category":"page"}]
}
